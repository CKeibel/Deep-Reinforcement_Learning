{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIlX3bscb_8H"
   },
   "source": [
    "# TODO:\n",
    "\n",
    "*  Wrapper for reward clipping to [-1, 1] (same reason like image normalization)\n",
    "* action repeat Wrapper (4 Times)\n",
    "* better reward handling for different games\n",
    "* Explanations\n",
    "* Adding results to a Dataframe and save to hard drive (to compare with other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q9xfV_VJakaI"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hxwx0hgyS9l_"
   },
   "source": [
    "# **Auswahl des Spiels**\n",
    "\n",
    "[Hier](https://gym.openai.com/envs/#atari) ist eine vollständige Liste der verfügbaren Spiele zu finden. Um ein Environment zu erstellen muss der vollständige Name des Spiels als String übergeben werden.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "```python\n",
    "game = \"MsPacman-v0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zW8iwvvZUBxy"
   },
   "outputs": [],
   "source": [
    "# Hier kann das Spiel übergeben werden\n",
    "game = \"Breakout-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkVT49we0eiY"
   },
   "source": [
    "# **Preprocessing**\n",
    "[Stable Baselines](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oHRVfJL9TxH"
   },
   "source": [
    "### Fire Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GxYChLgl0aQu"
   },
   "outputs": [],
   "source": [
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env) \n",
    "        self.env.reset()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        observation, _, _, _ = self.env.step(env.unwrapped.get_action_meanings().index('FIRE'))\n",
    "\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episodic Life Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
    "            # so it's important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip Reward Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULrSsx2f6-qS"
   },
   "source": [
    "### Resize & Grayscale Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HXr6gB0F7AwT"
   },
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import cv2\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        :param env: (Gym Environment) the environment\n",
    "        \"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1),\n",
    "                                            dtype=env.observation_space.dtype)\n",
    "        \n",
    "    def observation(self, frame):\n",
    "        \"\"\"\n",
    "        returns the current observation from a frame\n",
    "        :param frame: ([int] or [float]) environment frame\n",
    "        :return: ([int] or [float]) the observation\n",
    "        \"\"\"\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "_KJgqyxF7FRx",
    "outputId": "66a13e33-38f1-4b8b-9156-0f46ca7b3c35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def WarpFrameEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    return env\n",
    "\n",
    "normal_env = gym.make(game)\n",
    "wrapped_env = WarpFrameEnv(game)\n",
    "\n",
    "normal_env.reset()\n",
    "wrapped_env.reset()\n",
    "action = normal_env.action_space.sample()\n",
    "\n",
    "normal_state, _, _, _ = normal_env.step(action)\n",
    "wrapped_state, _, _, _ = wrapped_env.step(action)\n",
    "\n",
    "wrapped_state = wrapped_state[: , :, 0]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.suptitle('Warp Frame', fontsize=20)\n",
    "axs[0].imshow(normal_state)\n",
    "axs[0].set_title(\"Normal\", fontsize=16)\n",
    "axs[1].imshow(wrapped_state, cmap=\"gray\")\n",
    "axs[1].set_title(\"Warp Frame\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6m9sMMgAIL_"
   },
   "source": [
    "### Frame Stack Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9odKR1WDAJP9"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.frames = deque(maxlen=4)\n",
    "        low = np.repeat(self.observation_space.low[np.newaxis, ...], repeats=4, axis=0)\n",
    "        high = np.repeat(self.observation_space.high[np.newaxis, ...], repeats=4, axis=0)\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=self.observation_space.dtype)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        for _ in range(4):\n",
    "            self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "QcNdmvOnAVvb",
    "outputId": "e14a2bbf-ff06-4397-f7e0-fdbf244494e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def FrameStackEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = FrameStackEnv(game)\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1, 5):\n",
    "  # Führe eine zufällige Aktion aus\n",
    "  state, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Stack umformen, damit das Plotten der vier Bilder gelingt\n",
    "state = state.reshape(84, 84,4)\n",
    "\n",
    "# Frame Stack plotten\n",
    "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
    "fig.suptitle('Frame Stack', fontsize=20)\n",
    "for i in range(state.shape[2]):\n",
    "    axs[i].imshow(state[:, :, i], cmap=\"gray\")\n",
    "    axs[i].set_title(\"Frame \"+str(i+1), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg-MI4P9AadK"
   },
   "source": [
    "### Erstellen des Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8eSU0VDOAcML"
   },
   "outputs": [],
   "source": [
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    #env = EpisodicLifeEnv(env)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    env = NoopResetEnv(env)\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = make_env(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8HSZBWkHkbJ"
   },
   "source": [
    "# **Deep Q-Network und Target Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeLvxPIvLxE8"
   },
   "source": [
    " *\\\"The input to\n",
    "the neural network consists of an 84x84x4 image produced by the preprocessing\n",
    "map **--w-- (falsche Darstellung)**. The first hidden layer convolves 32 filters of 8x8 with stride 4 with the\n",
    "input image and applies a rectifier nonlinearity. The second hidden layer convolves\n",
    "64 filters of 4x4 with stride 2, again followed by a rectifier nonlinearity.\n",
    "This is followed by a third convolutional layer that convolves 64 filters of 333 with\n",
    "stride 1 followed by a rectifier. The final hidden layer is fully-connected and consists\n",
    "of 512 rectifier units. The output layer is a fully-connected linear layer with a\n",
    "single output for each valid action. The number of valid actions varied between 4\n",
    "and 18 on the games we considered.\"*\n",
    "\n",
    "\n",
    "[Mnih, V., Kavukcuoglu, K., Silver, D. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015).](https://www.nature.com/articles/nature14236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IinnQRAzHhcb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "# Tell TF to not use all GPU RAM\n",
    "config = tf.compat.v1.ConfigProto\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = .2\n",
    "session = tf.Session(config=config)\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# DQN und Tagret Net Parameters\n",
    "INPUT_SHAPE = (84, 84, 4) # (Höhe, Breite, Frames)\n",
    "OUTPUT_SHAPE = env.action_space.n # Anzahl der möglichen Aktionen\n",
    "LOSS_FUNCTION = \"mean_squared_error\"#Huber()################################################################### MSE probieren\n",
    "OPTIMIZER = Adam(lr=0.00005)#RMSprop(learning_rate=0.00025, rho=0.95, epsilon=0.01) # Adam probieren mit 0.00005#############################\n",
    "\n",
    "# Funktion zum erstellen eines neuronalen Netzes\n",
    "def build_neural_net(INPUT_SHAPE, OUTPUT_SHAPE, LOSS_FUNCTION, OPTIMIZER):\n",
    "    net_input = Input(shape=INPUT_SHAPE)\n",
    "    x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    net_output = Dense(OUTPUT_SHAPE)(x)\n",
    "\n",
    "    model = Model(inputs=net_input, outputs=net_output)\n",
    "    model.compile(loss=LOSS_FUNCTION, optimizer=OPTIMIZER)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Deep Q-Network\n",
    "DQN = build_neural_net(INPUT_SHAPE, OUTPUT_SHAPE, LOSS_FUNCTION, OPTIMIZER)\n",
    "# Target Network\n",
    "TARGET = build_neural_net(INPUT_SHAPE, OUTPUT_SHAPE, LOSS_FUNCTION, OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VobCYZ0N45l",
    "outputId": "2d95fd9f-17c4-4b27-cdee-18e9109dc8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,045,476\n",
      "Trainable params: 4,045,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,045,476\n",
      "Trainable params: 4,045,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DQN.summary()\n",
    "TARGET.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGwUt_ERhMuQ"
   },
   "source": [
    "# **Memory Buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "z601UsvHjzyz"
   },
   "outputs": [],
   "source": [
    "MEMORY_SIZE = 25000#1000000\n",
    "MEMORY_BUFFER = deque(maxlen=MEMORY_SIZE)\n",
    "TRAIN_START = 32#50000\n",
    "\n",
    "# Speichert Transition von einem State in einen Folgestate\n",
    "def save_transition(state, action, reward, next_state, done):\n",
    "    MEMORY_BUFFER.append([state, action, reward, next_state, done])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQZvvDESM0QB"
   },
   "source": [
    "# **Experience Replay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9v5SDTFMoZM2"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "MINIBATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "\n",
    "def replay():\n",
    "\n",
    "    # Ziehe 32 (MINIBATCH_SIZE) zufällige Transitionen aus dem Buffer in einen Minibatch\n",
    "    minibatch = random.sample(MEMORY_BUFFER, MINIBATCH_SIZE)\n",
    "    states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "\n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "\n",
    "    q_values = DQN.predict(states)\n",
    "    q_values_next = TARGET.predict(next_states)\n",
    "\n",
    "    # Q-Values Update\n",
    "    for i in range(MINIBATCH_SIZE):\n",
    "        a = actions[i]\n",
    "        done = dones[i]\n",
    "        if done:\n",
    "            q_values[i][a] = rewards[i]\n",
    "        else:\n",
    "            q_values[i][a] = rewards[i] + GAMMA * np.max(q_values_next[i])\n",
    "\n",
    "    DQN.fit(states, q_values, batch_size=MINIBATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2JdsqGQf_wn"
   },
   "source": [
    "# **Aktion wählen**\n",
    "Exploration & Exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(epsilon, decay, epsilon_min, decay_step):\n",
    "    return epsilon - decay\n",
    "\n",
    "def exponential(epsilon, decay, epsilon_min, decay_step):\n",
    "    epsilon = 1\n",
    "    return epsilon_min + (epsilon - epsilon_min) * np.exp(-decay * decay_step)\n",
    "\n",
    "def epsilon_decay(mode, epsilon, decay, epsilon_min, decay_step):\n",
    "    decay_strategy = {\n",
    "        \"linear\": linear,\n",
    "        \"exponential\": exponential\n",
    "    }\n",
    "    strategy = decay_strategy.get(mode)\n",
    "    return strategy(epsilon, decay, epsilon_min, decay_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QH18a8XDf5ui"
   },
   "outputs": [],
   "source": [
    "EPSILON = 1.0\n",
    "EPSILON_MIN = 0.02 #0.1\n",
    "#EPSILON_STEPS = 1000000\n",
    "EPSILON_DECAY = 0.00002 #0.0000009\n",
    "\n",
    "def get_action(state):\n",
    "    if np.random.rand() <= EPSILON:\n",
    "        return np.random.randint(env.action_space.n)\n",
    "    else:\n",
    "        return np.argmax(DQN(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Mean Reward -> Mean Reward kann nich auf 0 gesetzt werden (Pong -21)\n",
    "INITIAL_MEAN_REWARD = 0.0\n",
    "env.reset()\n",
    "while True:\n",
    "    _, reward, done, _ = env.step(env.action_space.sample())\n",
    "    INITIAL_MEAN_REWARD += reward\n",
    "    if done:\n",
    "        break\n",
    "INITIAL_MEAN_REWARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJQNx-7JhrWw"
   },
   "source": [
    "# **Training des Agenten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BujPrlhAhqhc",
    "outputId": "3724df14-34a2-4edd-a2fb-b5b99fe533bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020178289360403615\n",
      "Episode: 2 \tReward: 7.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020177822853670035\n",
      "Episode: 3 \tReward: 6.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020177435622084818\n",
      "Episode: 4 \tReward: 10.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017689703685801\n",
      "Episode: 5 \tReward: 16.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017603940299724\n",
      "Episode: 6 \tReward: 17.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017512287154186\n",
      "Episode: 7 \tReward: 6.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020174692598730413\n",
      "Episode: 8 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020174012624407163\n",
      "Episode: 9 \tReward: 18.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020173065104561\n",
      "Episode: 10 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017172388216779\n",
      "Episode: 11 \tReward: 16.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017087424056529\n",
      "Episode: 12 \tReward: 10.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02017029425468209\n",
      "Episode: 13 \tReward: 10.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020169651757484114\n",
      "Episode: 14 \tReward: 10.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016895085108548\n",
      "Episode: 15 \tReward: 11.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016833362119023\n",
      "Episode: 16 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016769181339064\n",
      "Episode: 17 \tReward: 7.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016729987329606\n",
      "Episode: 18 \tReward: 5.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020166935556821513\n",
      "Episode: 19 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020166192682080173\n",
      "Episode: 20 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020165413409200177\n",
      "Episode: 21 \tReward: 11.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020164799214428517\n",
      "Episode: 22 \tReward: 12.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016421357228668\n",
      "Episode: 23 \tReward: 9.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020163711846786992\n",
      "Episode: 24 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020163185542445075\n",
      "Episode: 25 \tReward: 10.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020162667436644927\n",
      "Episode: 26 \tReward: 13.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016199862550296\n",
      "Episode: 27 \tReward: 16.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02016127772044649\n",
      "Episode: 28 \tReward: 10.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020160743166265552\n",
      "Episode: 29 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020160226405701184\n",
      "Episode: 30 \tReward: 15.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020156326669121167\n",
      "Episode: 31 \tReward: 11.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02015571195382917\n",
      "Episode: 32 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02015519584735327\n",
      "Episode: 33 \tReward: 6.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020154854791787774\n",
      "Episode: 34 \tReward: 15.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020153633185782168\n",
      "Episode: 35 \tReward: 13.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0201529923393677\n",
      "Episode: 36 \tReward: 14.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020152345025124738\n",
      "Episode: 37 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020151846152041443\n",
      "Episode: 38 \tReward: 6.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020151164379495972\n",
      "Episode: 39 \tReward: 16.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02015045557391026\n",
      "Episode: 40 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020149872937329394\n",
      "Episode: 41 \tReward: 10.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02014938215941074\n",
      "Episode: 42 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020148818560720767\n",
      "Episode: 43 \tReward: 15.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020148132604748643\n",
      "Episode: 44 \tReward: 6.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020147810027407342\n",
      "Episode: 45 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020147222912631674\n",
      "Episode: 46 \tReward: 8.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020146767228278194\n",
      "Episode: 47 \tReward: 13.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02014617548480262\n",
      "Episode: 48 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020145632722163576\n",
      "Episode: 49 \tReward: 5.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020145120996147722\n",
      "Episode: 50 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020144524327624758\n",
      "Episode: 51 \tReward: 9.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020143838026517726\n",
      "Episode: 52 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020143226579830895\n",
      "Episode: 53 \tReward: 8.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020142848960337193\n",
      "Episode: 54 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020142378335725783\n",
      "Episode: 55 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020141512471448797\n",
      "Episode: 56 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02014095037113405\n",
      "Episode: 57 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02014006797642274\n",
      "Episode: 58 \tReward: 9.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020139589762155886\n",
      "Episode: 59 \tReward: 7.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02013922173119841\n",
      "Episode: 60 \tReward: 8.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020138851893495634\n",
      "Episode: 61 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02013831142570823\n",
      "Episode: 62 \tReward: 11.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020137817156074735\n",
      "Episode: 63 \tReward: 6.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020137525293187828\n",
      "Episode: 64 \tReward: 9.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020137107851129953\n",
      "Episode: 65 \tReward: 12.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020136546859758485\n",
      "Episode: 66 \tReward: 7.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020136211367308383\n",
      "Episode: 67 \tReward: 6.0 \tMean: 8.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020135901159162587\n",
      "Episode: 68 \tReward: 11.0 \tMean: 8.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020135393838109042\n",
      "Episode: 69 \tReward: 9.0 \tMean: 8.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020134974767106562\n",
      "Episode: 70 \tReward: 9.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020134543538186077\n",
      "Episode: 71 \tReward: 12.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02013402520116272\n",
      "Episode: 72 \tReward: 7.0 \tMean: 8.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020133685209124445\n",
      "Episode: 73 \tReward: 8.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02013266774578576\n",
      "Episode: 74 \tReward: 9.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020132251822405436\n",
      "Episode: 75 \tReward: 12.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02013177920736691\n",
      "Episode: 76 \tReward: 11.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020131303029039017\n",
      "Episode: 77 \tReward: 13.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020130708264424445\n",
      "Episode: 78 \tReward: 10.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020130295878222224\n",
      "Episode: 79 \tReward: 15.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020129552713276797\n",
      "Episode: 80 \tReward: 11.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020129102653392992\n",
      "Episode: 81 \tReward: 11.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020128636146674313\n",
      "Episode: 82 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020127856411698855\n",
      "Episode: 83 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020127368931885402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 84 \tReward: 8.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02012704074358609\n",
      "Episode: 85 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020126688060775166\n",
      "Episode: 86 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020126184844358214\n",
      "Episode: 87 \tReward: 10.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020125736424972396\n",
      "Episode: 88 \tReward: 7.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020125414951386224\n",
      "Episode: 89 \tReward: 6.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020125124325954865\n",
      "Episode: 90 \tReward: 8.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020124776963386392\n",
      "Episode: 91 \tReward: 9.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020124403193431492\n",
      "Episode: 92 \tReward: 13.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020123852067657266\n",
      "Episode: 93 \tReward: 10.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020123394661729722\n",
      "Episode: 94 \tReward: 15.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02012287503344405\n",
      "Episode: 95 \tReward: 6.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020122578035375725\n",
      "Episode: 96 \tReward: 15.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02012201059078111\n",
      "Episode: 97 \tReward: 15.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020121348655264288\n",
      "Episode: 98 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02012081831045722\n",
      "Episode: 99 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020120405817600297\n",
      "Episode: 100 \tReward: 22.0 \tMean: 13.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011857762989023\n",
      "Episode: 101 \tReward: 12.0 \tMean: 13.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020118137340552945\n",
      "Episode: 102 \tReward: 11.0 \tMean: 13.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020117479969962288\n",
      "Episode: 103 \tReward: 13.0 \tMean: 13.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011654387955669\n",
      "Episode: 104 \tReward: 8.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011622266193334\n",
      "Episode: 105 \tReward: 12.0 \tMean: 13.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020115798064477986\n",
      "Episode: 106 \tReward: 16.0 \tMean: 13.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020115225128134902\n",
      "Episode: 107 \tReward: 14.0 \tMean: 13.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011475137720404\n",
      "Episode: 108 \tReward: 7.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020114457989375046\n",
      "Episode: 109 \tReward: 12.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020113994232002684\n",
      "Episode: 110 \tReward: 10.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020113614126397512\n",
      "Episode: 111 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020113282857037076\n",
      "Episode: 112 \tReward: 14.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020112805810656196\n",
      "Episode: 113 \tReward: 9.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020112449906918586\n",
      "Episode: 114 \tReward: 10.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020112086158810313\n",
      "Episode: 115 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011172358733873\n",
      "Episode: 116 \tReward: 6.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020111424568988224\n",
      "Episode: 117 \tReward: 12.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020111035264676724\n",
      "Episode: 118 \tReward: 20.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02011039312414926\n",
      "Episode: 119 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020109928246746567\n",
      "Episode: 120 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020109533216539285\n",
      "Episode: 121 \tReward: 6.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020109290322510694\n",
      "Episode: 122 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020108921544806018\n",
      "Episode: 123 \tReward: 11.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020108538814967998\n",
      "Episode: 124 \tReward: 12.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010812931269431\n",
      "Episode: 125 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010779463084984\n",
      "Episode: 126 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020107372903023484\n",
      "Episode: 127 \tReward: 13.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010676261843966\n",
      "Episode: 128 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020106372581459243\n",
      "Episode: 129 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010594582204292\n",
      "Episode: 130 \tReward: 2.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020105810298144504\n",
      "Episode: 131 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020105381579222353\n",
      "Episode: 132 \tReward: 14.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020104925214196958\n",
      "Episode: 133 \tReward: 13.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010453352680784\n",
      "Episode: 134 \tReward: 15.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020104005923125223\n",
      "Episode: 135 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020103232925803596\n",
      "Episode: 136 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010280231278194\n",
      "Episode: 137 \tReward: 14.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010238987703583\n",
      "Episode: 138 \tReward: 11.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020102017855373605\n",
      "Episode: 139 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020101687852415676\n",
      "Episode: 140 \tReward: 9.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020101362971374843\n",
      "Episode: 141 \tReward: 12.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020101014881810625\n",
      "Episode: 142 \tReward: 13.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02010059955665488\n",
      "Episode: 143 \tReward: 5.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020100364428899068\n",
      "Episode: 144 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009947713817183\n",
      "Episode: 145 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020099105788531753\n",
      "Episode: 146 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009875359919356\n",
      "Episode: 147 \tReward: 8.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009847353684862\n",
      "Episode: 148 \tReward: 8.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020098196232657385\n",
      "Episode: 149 \tReward: 10.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009788250694174\n",
      "Episode: 150 \tReward: 7.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020097622485455168\n",
      "Episode: 151 \tReward: 18.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009711810844477\n",
      "Episode: 152 \tReward: 7.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200968639920385\n",
      "Episode: 153 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020096506257485\n",
      "Episode: 154 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009621717255675\n",
      "Episode: 155 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020095844573237348\n",
      "Episode: 156 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020095553648164868\n",
      "Episode: 157 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020095217890603315\n",
      "Episode: 158 \tReward: 15.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020094756254339742\n",
      "Episode: 159 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020094344016402563\n",
      "Episode: 160 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020094033194286997\n",
      "Episode: 161 \tReward: 13.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009365968594837\n",
      "Episode: 162 \tReward: 10.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009335671963636\n",
      "Episode: 163 \tReward: 9.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009306403928533\n",
      "Episode: 164 \tReward: 11.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020092707358639602\n",
      "Episode: 165 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009235758631012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 166 \tReward: 12.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020091638166582493\n",
      "Episode: 167 \tReward: 12.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020091286950788715\n",
      "Episode: 168 \tReward: 10.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020090898895522926\n",
      "Episode: 169 \tReward: 15.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02009047629210052\n",
      "Episode: 170 \tReward: 6.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020090230530972662\n",
      "Episode: 171 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020089877519645492\n",
      "Episode: 172 \tReward: 13.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020089361313234005\n",
      "Episode: 173 \tReward: 10.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020089077595608035\n",
      "Episode: 174 \tReward: 17.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020088656366905544\n",
      "Episode: 175 \tReward: 6.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020088443846751167\n",
      "Episode: 176 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020087974574856483\n",
      "Episode: 177 \tReward: 13.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008760936079701\n",
      "Episode: 178 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008725438787481\n",
      "Episode: 179 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020086716818557854\n",
      "Episode: 180 \tReward: 9.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008642939610552\n",
      "Episode: 181 \tReward: 16.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020086065432557174\n",
      "Episode: 182 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020085744149014137\n",
      "Episode: 183 \tReward: 5.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020085554008137788\n",
      "Episode: 184 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020085248272382193\n",
      "Episode: 185 \tReward: 7.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020085018412497244\n",
      "Episode: 186 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020084479411234642\n",
      "Episode: 187 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008423814529326\n",
      "Episode: 188 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008396397607824\n",
      "Episode: 189 \tReward: 14.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020083602034059234\n",
      "Episode: 190 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020083364941113846\n",
      "Episode: 191 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020083035468732906\n",
      "Episode: 192 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020082702336193633\n",
      "Episode: 193 \tReward: 10.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008243811170247\n",
      "Episode: 194 \tReward: 11.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020082171444454774\n",
      "Episode: 195 \tReward: 13.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020081853236972008\n",
      "Episode: 196 \tReward: 10.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020081570514164596\n",
      "Episode: 197 \tReward: 10.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020081324542815502\n",
      "Episode: 198 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020081006374624746\n",
      "Episode: 199 \tReward: 9.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020080754028600416\n",
      "Episode: 200 \tReward: 10.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020080487979528445\n",
      "Episode: 201 \tReward: 9.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02008024848237744\n",
      "Episode: 202 \tReward: 7.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020080033704375742\n",
      "Episode: 203 \tReward: 13.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02007970942626598\n",
      "Episode: 204 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020079445229779617\n",
      "Episode: 205 \tReward: 12.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020079148659552258\n",
      "Episode: 206 \tReward: 6.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020078958930535223\n",
      "Episode: 207 \tReward: 12.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020078430105364673\n",
      "Episode: 208 \tReward: 17.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02007758296273087\n",
      "Episode: 209 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020077318082202214\n",
      "Episode: 210 \tReward: 9.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020077063353065187\n",
      "Episode: 211 \tReward: 14.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020076028468117863\n",
      "Episode: 212 \tReward: 7.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020075832567490594\n",
      "Episode: 213 \tReward: 11.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020075563083516414\n",
      "Episode: 214 \tReward: 6.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020075336733959958\n",
      "Episode: 215 \tReward: 11.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020075076519291433\n",
      "Episode: 216 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020074748403235657\n",
      "Episode: 217 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020074452984873255\n",
      "Episode: 218 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020074066834213755\n",
      "Episode: 219 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020073607568302617\n",
      "Episode: 220 \tReward: 9.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020073365063679918\n",
      "Episode: 221 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02007293202556047\n",
      "Episode: 222 \tReward: 25.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02007246530174288\n",
      "Episode: 223 \tReward: 6.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020072310391809896\n",
      "Episode: 224 \tReward: 11.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020071127059681816\n",
      "Episode: 225 \tReward: 14.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200708459534831\n",
      "Episode: 226 \tReward: 9.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02007054902446589\n",
      "Episode: 227 \tReward: 14.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020069625289111402\n",
      "Episode: 228 \tReward: 10.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020069413949631274\n",
      "Episode: 229 \tReward: 13.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006894767272907\n",
      "Episode: 230 \tReward: 5.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020068801658492664\n",
      "Episode: 231 \tReward: 7.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020068610655499225\n",
      "Episode: 232 \tReward: 17.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200682629971691\n",
      "Episode: 233 \tReward: 7.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006807076668945\n",
      "Episode: 234 \tReward: 12.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006778546901386\n",
      "Episode: 235 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006637681678061\n",
      "Episode: 236 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020066122418561354\n",
      "Episode: 237 \tReward: 8.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020065937534747513\n",
      "Episode: 238 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020065575873785733\n",
      "Episode: 239 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020065346759411528\n",
      "Episode: 240 \tReward: 7.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020064954553643703\n",
      "Episode: 241 \tReward: 7.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020064787186891253\n",
      "Episode: 242 \tReward: 11.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020064523393672835\n",
      "Episode: 243 \tReward: 14.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020064072025604802\n",
      "Episode: 244 \tReward: 18.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020063744815207125\n",
      "Episode: 245 \tReward: 10.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020063536074734763\n",
      "Episode: 246 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020063295095800723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 247 \tReward: 11.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006297437204213\n",
      "Episode: 248 \tReward: 9.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020062785732027504\n",
      "Episode: 249 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020062587642260966\n",
      "Episode: 250 \tReward: 10.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020062385186455554\n",
      "Episode: 251 \tReward: 7.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020062228173704844\n",
      "Episode: 252 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020061976039498382\n",
      "Episode: 253 \tReward: 17.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020061674333187774\n",
      "Episode: 254 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020061452704758828\n",
      "Episode: 255 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020061226974403913\n",
      "Episode: 256 \tReward: 11.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020061017935811193\n",
      "Episode: 257 \tReward: 8.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020060852192538826\n",
      "Episode: 258 \tReward: 6.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006070146607939\n",
      "Episode: 259 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02006050027138001\n",
      "Episode: 260 \tReward: 9.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020060290096352264\n",
      "Episode: 261 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020060111901525512\n",
      "Episode: 262 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020059885107448595\n",
      "Episode: 263 \tReward: 7.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020059737971136138\n",
      "Episode: 264 \tReward: 10.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020059536397644802\n",
      "Episode: 265 \tReward: 11.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020059326011400497\n",
      "Episode: 266 \tReward: 15.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020059069094424124\n",
      "Episode: 267 \tReward: 9.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020058893330541\n",
      "Episode: 268 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020058708695511795\n",
      "Episode: 269 \tReward: 5.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005856562091674\n",
      "Episode: 270 \tReward: 11.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005837033804681\n",
      "Episode: 271 \tReward: 15.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005794462717498\n",
      "Episode: 272 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020057711003119545\n",
      "Episode: 273 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005745648338873\n",
      "Episode: 274 \tReward: 5.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005710820780039\n",
      "Episode: 275 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020056880231226305\n",
      "Episode: 276 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020056674697030607\n",
      "Episode: 277 \tReward: 7.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005652866477488\n",
      "Episode: 278 \tReward: 16.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020056274857278563\n",
      "Episode: 279 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020056051328464\n",
      "Episode: 280 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020055864429322244\n",
      "Episode: 281 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005547696284164\n",
      "Episode: 282 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020055278710398278\n",
      "Episode: 283 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020055100999219342\n",
      "Episode: 284 \tReward: 14.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020054867865575244\n",
      "Episode: 285 \tReward: 11.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005467725725388\n",
      "Episode: 286 \tReward: 14.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020054442649815176\n",
      "Episode: 287 \tReward: 14.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020054204712472157\n",
      "Episode: 288 \tReward: 12.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020053553858617484\n",
      "Episode: 289 \tReward: 9.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005339877740394\n",
      "Episode: 290 \tReward: 16.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020053143077443252\n",
      "Episode: 291 \tReward: 10.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020052955283540425\n",
      "Episode: 292 \tReward: 11.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200527565455359\n",
      "Episode: 293 \tReward: 7.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005114515930351\n",
      "Episode: 294 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02005094608163601\n",
      "Episode: 295 \tReward: 8.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020050516895801243\n",
      "Episode: 296 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020050333348559168\n",
      "Episode: 297 \tReward: 9.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020050098338839594\n",
      "Episode: 298 \tReward: 18.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020049614734227075\n",
      "Episode: 299 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020049425567480846\n",
      "Episode: 300 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020049070981436556\n",
      "Episode: 301 \tReward: 8.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020048940626075425\n",
      "Episode: 302 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004876865791317\n",
      "Episode: 303 \tReward: 8.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020048282436000726\n",
      "Episode: 304 \tReward: 14.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020048085844980235\n",
      "Episode: 305 \tReward: 6.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020047973455649782\n",
      "Episode: 306 \tReward: 14.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004776570200377\n",
      "Episode: 307 \tReward: 6.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004766359269741\n",
      "Episode: 308 \tReward: 12.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020047479016267574\n",
      "Episode: 309 \tReward: 8.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004733679266085\n",
      "Episode: 310 \tReward: 11.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004717234692393\n",
      "Episode: 311 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004701505411043\n",
      "Episode: 312 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020046840483012696\n",
      "Episode: 313 \tReward: 9.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020046666560113047\n",
      "Episode: 314 \tReward: 10.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020046371630038175\n",
      "Episode: 315 \tReward: 15.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004605184608689\n",
      "Episode: 316 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020045776362288215\n",
      "Episode: 317 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004561186365917\n",
      "Episode: 318 \tReward: 9.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004546250183367\n",
      "Episode: 319 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020045179699084443\n",
      "Episode: 320 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020045047065835545\n",
      "Episode: 321 \tReward: 10.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004488698339698\n",
      "Episode: 322 \tReward: 16.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020044661322144695\n",
      "Episode: 323 \tReward: 15.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020044410141283657\n",
      "Episode: 324 \tReward: 11.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020044246127373752\n",
      "Episode: 325 \tReward: 11.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004407831114251\n",
      "Episode: 326 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020043960339421366\n",
      "Episode: 327 \tReward: 15.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004375683593964\n",
      "Episode: 328 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004360133855327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 329 \tReward: 9.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020043465514372884\n",
      "Episode: 330 \tReward: 13.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020043303256959626\n",
      "Episode: 331 \tReward: 12.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020043126939603223\n",
      "Episode: 332 \tReward: 15.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004292557708171\n",
      "Episode: 333 \tReward: 4.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020042844095916872\n",
      "Episode: 334 \tReward: 12.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004268245093579\n",
      "Episode: 335 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020042528219790204\n",
      "Episode: 336 \tReward: 20.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004228057880214\n",
      "Episode: 337 \tReward: 12.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020042117690344936\n",
      "Episode: 338 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020041970536098876\n",
      "Episode: 339 \tReward: 12.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020041808842099718\n",
      "Episode: 340 \tReward: 11.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004165193602171\n",
      "Episode: 341 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02004150889952562\n",
      "Episode: 342 \tReward: 6.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020041208636189817\n",
      "Episode: 343 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020041048235493342\n",
      "Episode: 344 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040881917511202\n",
      "Episode: 345 \tReward: 16.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040647927498476\n",
      "Episode: 346 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040495378263367\n",
      "Episode: 347 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040363578280925\n",
      "Episode: 348 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040207271029356\n",
      "Episode: 349 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020040061182605044\n",
      "Episode: 350 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020039922011986906\n",
      "Episode: 351 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020039734024090768\n",
      "Episode: 352 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003961658527465\n",
      "Episode: 353 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020039447388628784\n",
      "Episode: 354 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003928755690889\n",
      "Episode: 355 \tReward: 7.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020038997902032597\n",
      "Episode: 356 \tReward: 9.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020038878750846666\n",
      "Episode: 357 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200387498874255\n",
      "Episode: 358 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003864308519109\n",
      "Episode: 359 \tReward: 6.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020038535035892164\n",
      "Episode: 360 \tReward: 11.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020038386577362913\n",
      "Episode: 361 \tReward: 10.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020038252459185862\n",
      "Episode: 362 \tReward: 13.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003809137393703\n",
      "Episode: 363 \tReward: 7.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003800006425503\n",
      "Episode: 364 \tReward: 15.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020037799196683737\n",
      "Episode: 365 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003767014423655\n",
      "Episode: 366 \tReward: 12.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020037522766320582\n",
      "Episode: 367 \tReward: 16.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003734458236714\n",
      "Episode: 368 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020037219315137186\n",
      "Episode: 369 \tReward: 11.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020037078891693476\n",
      "Episode: 370 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020036937520518064\n",
      "Episode: 371 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020036695269512912\n",
      "Episode: 372 \tReward: 15.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003653562641269\n",
      "Episode: 373 \tReward: 12.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020036394870727975\n",
      "Episode: 374 \tReward: 12.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020036250307015096\n",
      "Episode: 375 \tReward: 8.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020036147502195116\n",
      "Episode: 376 \tReward: 5.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020035998160885842\n",
      "Episode: 377 \tReward: 15.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020035519713444364\n",
      "Episode: 378 \tReward: 9.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200354005674845\n",
      "Episode: 379 \tReward: 8.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020035287466726275\n",
      "Episode: 380 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003517191344639\n",
      "Episode: 381 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003503501011896\n",
      "Episode: 382 \tReward: 12.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003489863967471\n",
      "Episode: 383 \tReward: 12.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020034732222231618\n",
      "Episode: 384 \tReward: 13.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200343880063389\n",
      "Episode: 385 \tReward: 8.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020034292540440358\n",
      "Episode: 386 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020034176143789297\n",
      "Episode: 387 \tReward: 8.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020034078539658495\n",
      "Episode: 388 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003394792899917\n",
      "Episode: 389 \tReward: 20.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020033757001600986\n",
      "Episode: 390 \tReward: 8.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020033663287459546\n",
      "Episode: 391 \tReward: 16.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003346525882246\n",
      "Episode: 392 \tReward: 15.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020033321000726186\n",
      "Episode: 393 \tReward: 8.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003322716787065\n",
      "Episode: 394 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020033108427282145\n",
      "Episode: 395 \tReward: 9.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020033007930495717\n",
      "Episode: 396 \tReward: 13.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032862357396472\n",
      "Episode: 397 \tReward: 9.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032754090355934\n",
      "Episode: 398 \tReward: 7.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003267230740133\n",
      "Episode: 399 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032512604686258\n",
      "Episode: 400 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032386700192743\n",
      "Episode: 401 \tReward: 13.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032257412140462\n",
      "Episode: 402 \tReward: 5.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032194249532242\n",
      "Episode: 403 \tReward: 13.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020032055470353118\n",
      "Episode: 404 \tReward: 9.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031891127957283\n",
      "Episode: 405 \tReward: 9.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031793054393992\n",
      "Episode: 406 \tReward: 9.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031700988096902\n",
      "Episode: 407 \tReward: 11.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031578858145296\n",
      "Episode: 408 \tReward: 14.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031442731722884\n",
      "Episode: 409 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020031314080438175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 410 \tReward: 15.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020030899742503435\n",
      "Episode: 411 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003078500899795\n",
      "Episode: 412 \tReward: 14.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020030646787688657\n",
      "Episode: 413 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02003054276554836\n",
      "Episode: 414 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020030425097718355\n",
      "Episode: 415 \tReward: 8.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020030326073397137\n",
      "Episode: 416 \tReward: 3.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020030276984930626\n",
      "Episode: 417 \tReward: 20.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200300459492225\n",
      "Episode: 418 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029941571042577\n",
      "Episode: 419 \tReward: 7.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002986143506236\n",
      "Episode: 420 \tReward: 22.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029605727837897\n",
      "Episode: 421 \tReward: 11.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029486951711955\n",
      "Episode: 422 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029365128080786\n",
      "Episode: 423 \tReward: 9.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029274822628083\n",
      "Episode: 424 \tReward: 7.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002919763902353\n",
      "Episode: 425 \tReward: 6.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029134640186477\n",
      "Episode: 426 \tReward: 6.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020029068870247684\n",
      "Episode: 427 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028955722435366\n",
      "Episode: 428 \tReward: 13.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002884416878382\n",
      "Episode: 429 \tReward: 9.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002875431522166\n",
      "Episode: 430 \tReward: 5.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028638954904063\n",
      "Episode: 431 \tReward: 10.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028540606156026\n",
      "Episode: 432 \tReward: 10.0 \tMean: 8.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002842894597683\n",
      "Episode: 433 \tReward: 22.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028254927033393\n",
      "Episode: 434 \tReward: 15.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028133129021734\n",
      "Episode: 435 \tReward: 13.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020028016338298135\n",
      "Episode: 436 \tReward: 8.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027939678602943\n",
      "Episode: 437 \tReward: 4.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027883855087858\n",
      "Episode: 438 \tReward: 13.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027773097897623\n",
      "Episode: 439 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027651717745412\n",
      "Episode: 440 \tReward: 12.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027546289679437\n",
      "Episode: 441 \tReward: 10.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200272443960562\n",
      "Episode: 442 \tReward: 17.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200271199020312\n",
      "Episode: 443 \tReward: 6.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020027056515651433\n",
      "Episode: 444 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026955513275074\n",
      "Episode: 445 \tReward: 14.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002683180266655\n",
      "Episode: 446 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002672201748902\n",
      "Episode: 447 \tReward: 9.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026569603867502\n",
      "Episode: 448 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026489484704653\n",
      "Episode: 449 \tReward: 8.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026401685442854\n",
      "Episode: 450 \tReward: 7.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026336817117418\n",
      "Episode: 451 \tReward: 18.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026196029425746\n",
      "Episode: 452 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020026078933704183\n",
      "Episode: 453 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002597742393545\n",
      "Episode: 454 \tReward: 11.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020025888732893717\n",
      "Episode: 455 \tReward: 18.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020025697863358585\n",
      "Episode: 456 \tReward: 17.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020025565092599534\n",
      "Episode: 457 \tReward: 9.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002548902202504\n",
      "Episode: 458 \tReward: 12.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020025391839697326\n",
      "Episode: 459 \tReward: 9.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002531476571645\n",
      "Episode: 460 \tReward: 14.0 \tMean: 13.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020025199593177744\n",
      "Episode: 461 \tReward: 12.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002510702909722\n",
      "Episode: 462 \tReward: 10.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002502331150624\n",
      "Episode: 463 \tReward: 6.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024963327568143\n",
      "Episode: 464 \tReward: 13.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024864170976927\n",
      "Episode: 465 \tReward: 9.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024791177667\n",
      "Episode: 466 \tReward: 10.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024669998029\n",
      "Episode: 467 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024580854084026\n",
      "Episode: 468 \tReward: 9.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024498401013037\n",
      "Episode: 469 \tReward: 11.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002441427129962\n",
      "Episode: 470 \tReward: 11.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024326537937745\n",
      "Episode: 471 \tReward: 15.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002421731445418\n",
      "Episode: 472 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020024115332719986\n",
      "Episode: 473 \tReward: 4.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002407437148128\n",
      "Episode: 474 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002399265761054\n",
      "Episode: 475 \tReward: 8.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023869651746306\n",
      "Episode: 476 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023780545980422\n",
      "Episode: 477 \tReward: 12.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023689877581675\n",
      "Episode: 478 \tReward: 9.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023622221326354\n",
      "Episode: 479 \tReward: 12.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023471991297667\n",
      "Episode: 480 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002339559719608\n",
      "Episode: 481 \tReward: 18.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023272393985585\n",
      "Episode: 482 \tReward: 12.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002318690896463\n",
      "Episode: 483 \tReward: 6.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023130864486104\n",
      "Episode: 484 \tReward: 12.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020023050047971804\n",
      "Episode: 485 \tReward: 7.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022992494823286\n",
      "Episode: 486 \tReward: 11.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022803815094\n",
      "Episode: 487 \tReward: 9.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022727777405214\n",
      "Episode: 488 \tReward: 15.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022586397637827\n",
      "Episode: 489 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022498032268368\n",
      "Episode: 490 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022411805485835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 491 \tReward: 14.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002230939411776\n",
      "Episode: 492 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022218557223036\n",
      "Episode: 493 \tReward: 10.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020022144471034717\n",
      "Episode: 494 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002206048172554\n",
      "Episode: 495 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021978569185306\n",
      "Episode: 496 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021898712620594\n",
      "Episode: 497 \tReward: 10.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021822201099687\n",
      "Episode: 498 \tReward: 14.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021708586003335\n",
      "Episode: 499 \tReward: 16.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021599449983666\n",
      "Episode: 500 \tReward: 10.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021528719848553\n",
      "Episode: 501 \tReward: 8.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021317916100616\n",
      "Episode: 502 \tReward: 6.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021273195449923\n",
      "Episode: 503 \tReward: 22.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002112184579565\n",
      "Episode: 504 \tReward: 12.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020021035844227306\n",
      "Episode: 505 \tReward: 6.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002098122207189\n",
      "Episode: 506 \tReward: 7.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200208878541866\n",
      "Episode: 507 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020800725182582\n",
      "Episode: 508 \tReward: 7.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020726391722712\n",
      "Episode: 509 \tReward: 13.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020646954994628\n",
      "Episode: 510 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002056535472801\n",
      "Episode: 511 \tReward: 9.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002050006077239\n",
      "Episode: 512 \tReward: 14.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020400672186925\n",
      "Episode: 513 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020322890277203\n",
      "Episode: 514 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020257960970615\n",
      "Episode: 515 \tReward: 15.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020020164988351116\n",
      "Episode: 516 \tReward: 13.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002008448950274\n",
      "Episode: 517 \tReward: 8.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02002002672938746\n",
      "Episode: 518 \tReward: 10.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019954762779284\n",
      "Episode: 519 \tReward: 9.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019890213973414\n",
      "Episode: 520 \tReward: 14.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001978705331093\n",
      "Episode: 521 \tReward: 19.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001968127843509\n",
      "Episode: 522 \tReward: 8.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019626247934123\n",
      "Episode: 523 \tReward: 8.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019567848773248\n",
      "Episode: 524 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001951625778256\n",
      "Episode: 525 \tReward: 9.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019452738375076\n",
      "Episode: 526 \tReward: 8.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019398734862057\n",
      "Episode: 527 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019334437854405\n",
      "Episode: 528 \tReward: 4.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019301597232492\n",
      "Episode: 529 \tReward: 6.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001925494384056\n",
      "Episode: 530 \tReward: 11.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019183832186038\n",
      "Episode: 531 \tReward: 11.0 \tMean: 8.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001911298315848\n",
      "Episode: 532 \tReward: 7.0 \tMean: 8.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019061066482973\n",
      "Episode: 533 \tReward: 9.0 \tMean: 8.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020019003588897036\n",
      "Episode: 534 \tReward: 14.0 \tMean: 8.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018919778391774\n",
      "Episode: 535 \tReward: 8.0 \tMean: 8.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018867631798814\n",
      "Episode: 536 \tReward: 11.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001873002498941\n",
      "Episode: 537 \tReward: 9.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018444898914266\n",
      "Episode: 538 \tReward: 9.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018386705028462\n",
      "Episode: 539 \tReward: 11.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018319166301434\n",
      "Episode: 540 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001821905183428\n",
      "Episode: 541 \tReward: 11.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020018150676824956\n",
      "Episode: 542 \tReward: 10.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001808075025751\n",
      "Episode: 543 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001783080983509\n",
      "Episode: 544 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017767089663043\n",
      "Episode: 545 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001769828691879\n",
      "Episode: 546 \tReward: 12.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017636098464728\n",
      "Episode: 547 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001756534366134\n",
      "Episode: 548 \tReward: 7.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017523587852547\n",
      "Episode: 549 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017461664021397\n",
      "Episode: 550 \tReward: 7.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017414929414168\n",
      "Episode: 551 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017363457439204\n",
      "Episode: 552 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017305214125772\n",
      "Episode: 553 \tReward: 11.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001723371863707\n",
      "Episode: 554 \tReward: 9.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017177971747412\n",
      "Episode: 555 \tReward: 13.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001710255471088\n",
      "Episode: 556 \tReward: 17.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020017017595711912\n",
      "Episode: 557 \tReward: 8.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001696763745514\n",
      "Episode: 558 \tReward: 17.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016884024021332\n",
      "Episode: 559 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016823014348508\n",
      "Episode: 560 \tReward: 11.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016761219428095\n",
      "Episode: 561 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016705998568515\n",
      "Episode: 562 \tReward: 8.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016658287671713\n",
      "Episode: 563 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016613370959845\n",
      "Episode: 564 \tReward: 9.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001654076352141\n",
      "Episode: 565 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016480994205194\n",
      "Episode: 566 \tReward: 6.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020016443789215764\n",
      "Episode: 567 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001638469800259\n",
      "Episode: 568 \tReward: 11.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001632288075235\n",
      "Episode: 569 \tReward: 13.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001625609394777\n",
      "Episode: 570 \tReward: 13.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001618019317444\n",
      "Episode: 571 \tReward: 13.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001611560167087\n",
      "Episode: 572 \tReward: 9.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001606668463336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 573 \tReward: 17.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015809133626654\n",
      "Episode: 574 \tReward: 14.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015732802290742\n",
      "Episode: 575 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015678460859707\n",
      "Episode: 576 \tReward: 12.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015533016428347\n",
      "Episode: 577 \tReward: 9.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001548400956805\n",
      "Episode: 578 \tReward: 12.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015329634502865\n",
      "Episode: 579 \tReward: 16.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015258364593943\n",
      "Episode: 580 \tReward: 7.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001521752692375\n",
      "Episode: 581 \tReward: 13.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015094159043057\n",
      "Episode: 582 \tReward: 13.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020015034805060554\n",
      "Episode: 583 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001490456960223\n",
      "Episode: 584 \tReward: 19.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014820448026913\n",
      "Episode: 585 \tReward: 8.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014781373645003\n",
      "Episode: 586 \tReward: 10.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014735622337868\n",
      "Episode: 587 \tReward: 14.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001466036876504\n",
      "Episode: 588 \tReward: 17.0 \tMean: 12.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014358869726186\n",
      "Episode: 589 \tReward: 14.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014294114093004\n",
      "Episode: 590 \tReward: 14.0 \tMean: 13.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014229650494788\n",
      "Episode: 591 \tReward: 11.0 \tMean: 13.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014179933773073\n",
      "Episode: 592 \tReward: 13.0 \tMean: 13.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014119938134508\n",
      "Episode: 593 \tReward: 11.0 \tMean: 13.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014070604734847\n",
      "Episode: 594 \tReward: 7.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020014035752869284\n",
      "Episode: 595 \tReward: 14.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001397524919891\n",
      "Episode: 596 \tReward: 13.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013924471762826\n",
      "Episode: 597 \tReward: 12.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013837853588786\n",
      "Episode: 598 \tReward: 10.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013780407688177\n",
      "Episode: 599 \tReward: 7.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013717163386225\n",
      "Episode: 600 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001366568369436\n",
      "Episode: 601 \tReward: 7.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013628563541008\n",
      "Episode: 602 \tReward: 15.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001356194692366\n",
      "Episode: 603 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013505646410717\n",
      "Episode: 604 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013447965768705\n",
      "Episode: 605 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001340151621122\n",
      "Episode: 606 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013331475932063\n",
      "Episode: 607 \tReward: 8.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001329579540982\n",
      "Episode: 608 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013247221742657\n",
      "Episode: 609 \tReward: 13.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013193547055726\n",
      "Episode: 610 \tReward: 14.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013134834861373\n",
      "Episode: 611 \tReward: 14.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001307716854691\n",
      "Episode: 612 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020013022620068127\n",
      "Episode: 613 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012978158779636\n",
      "Episode: 614 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012944459394992\n",
      "Episode: 615 \tReward: 16.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012883763183664\n",
      "Episode: 616 \tReward: 14.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001282617302288\n",
      "Episode: 617 \tReward: 10.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001278084864187\n",
      "Episode: 618 \tReward: 8.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200127216828749\n",
      "Episode: 619 \tReward: 10.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200126812921786\n",
      "Episode: 620 \tReward: 10.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012644063931936\n",
      "Episode: 621 \tReward: 8.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001260946661673\n",
      "Episode: 622 \tReward: 12.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012544067575196\n",
      "Episode: 623 \tReward: 12.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012497490331203\n",
      "Episode: 624 \tReward: 10.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001245606746331\n",
      "Episode: 625 \tReward: 12.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012406094584895\n",
      "Episode: 626 \tReward: 16.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200123471818981\n",
      "Episode: 627 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012297399910554\n",
      "Episode: 628 \tReward: 6.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012265958828542\n",
      "Episode: 629 \tReward: 15.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012208688258887\n",
      "Episode: 630 \tReward: 13.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001214415337961\n",
      "Episode: 631 \tReward: 2.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012129346546493\n",
      "Episode: 632 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012092771176528\n",
      "Episode: 633 \tReward: 18.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020012027405657325\n",
      "Episode: 634 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011981548610436\n",
      "Episode: 635 \tReward: 20.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011917976024845\n",
      "Episode: 636 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001187514844705\n",
      "Episode: 637 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011840523590476\n",
      "Episode: 638 \tReward: 11.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011797974340155\n",
      "Episode: 639 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011753932326026\n",
      "Episode: 640 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011706776365063\n",
      "Episode: 641 \tReward: 11.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001164582621074\n",
      "Episode: 642 \tReward: 7.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011612566731504\n",
      "Episode: 643 \tReward: 11.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001156967962467\n",
      "Episode: 644 \tReward: 10.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011526950906935\n",
      "Episode: 645 \tReward: 7.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011495870117434\n",
      "Episode: 646 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011419562010503\n",
      "Episode: 647 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001137488495167\n",
      "Episode: 648 \tReward: 12.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001132856996788\n",
      "Episode: 649 \tReward: 5.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011308649220138\n",
      "Episode: 650 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011261027273408\n",
      "Episode: 651 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011226621198093\n",
      "Episode: 652 \tReward: 7.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001119769384773\n",
      "Episode: 653 \tReward: 8.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011166384158976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 654 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001113182196716\n",
      "Episode: 655 \tReward: 9.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020011096922866446\n",
      "Episode: 656 \tReward: 11.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001102061765439\n",
      "Episode: 657 \tReward: 11.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010978379631502\n",
      "Episode: 658 \tReward: 15.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001091707252568\n",
      "Episode: 659 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010880452717723\n",
      "Episode: 660 \tReward: 12.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010802826908286\n",
      "Episode: 661 \tReward: 9.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010769174613214\n",
      "Episode: 662 \tReward: 13.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200107261839534\n",
      "Episode: 663 \tReward: 10.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010687852868428\n",
      "Episode: 664 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001065775558046\n",
      "Episode: 665 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010603751468695\n",
      "Episode: 666 \tReward: 5.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010580448857732\n",
      "Episode: 667 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010548544102613\n",
      "Episode: 668 \tReward: 14.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010500342237152\n",
      "Episode: 669 \tReward: 10.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010466585512643\n",
      "Episode: 670 \tReward: 13.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010425636809326\n",
      "Episode: 671 \tReward: 8.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001039315951341\n",
      "Episode: 672 \tReward: 11.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010355604291933\n",
      "Episode: 673 \tReward: 8.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001032954102263\n",
      "Episode: 674 \tReward: 9.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010292421530122\n",
      "Episode: 675 \tReward: 11.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001025769187154\n",
      "Episode: 676 \tReward: 7.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001020734797507\n",
      "Episode: 677 \tReward: 12.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010166600133182\n",
      "Episode: 678 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010121965361106\n",
      "Episode: 679 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001009285603841\n",
      "Episode: 680 \tReward: 8.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020010057190493296\n",
      "Episode: 681 \tReward: 10.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02001002606147767\n",
      "Episode: 682 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009942592988134\n",
      "Episode: 683 \tReward: 9.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009911422209883\n",
      "Episode: 684 \tReward: 6.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009888849909445\n",
      "Episode: 685 \tReward: 10.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009856073366913\n",
      "Episode: 686 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009822423170634\n",
      "Episode: 687 \tReward: 7.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009770306632278\n",
      "Episode: 688 \tReward: 13.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009685092528876\n",
      "Episode: 689 \tReward: 11.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000965106093392\n",
      "Episode: 690 \tReward: 12.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009612918304873\n",
      "Episode: 691 \tReward: 13.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009573394556286\n",
      "Episode: 692 \tReward: 12.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009539183078857\n",
      "Episode: 693 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009510608413054\n",
      "Episode: 694 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000947586320877\n",
      "Episode: 695 \tReward: 6.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009452770287362\n",
      "Episode: 696 \tReward: 10.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009424077500823\n",
      "Episode: 697 \tReward: 8.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000939847883998\n",
      "Episode: 698 \tReward: 8.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000936976345168\n",
      "Episode: 699 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009342069958455\n",
      "Episode: 700 \tReward: 11.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009312781865154\n",
      "Episode: 701 \tReward: 10.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000928302859381\n",
      "Episode: 702 \tReward: 9.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009253740522977\n",
      "Episode: 703 \tReward: 9.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009222884587726\n",
      "Episode: 704 \tReward: 9.0 \tMean: 9.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009194337915707\n",
      "Episode: 705 \tReward: 8.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009171197353515\n",
      "Episode: 706 \tReward: 10.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009140616652554\n",
      "Episode: 707 \tReward: 8.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200091165172498\n",
      "Episode: 708 \tReward: 13.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020009002909930122\n",
      "Episode: 709 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008972890371526\n",
      "Episode: 710 \tReward: 12.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008939036869348\n",
      "Episode: 711 \tReward: 15.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000886071845135\n",
      "Episode: 712 \tReward: 10.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008832056181522\n",
      "Episode: 713 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200087987340277\n",
      "Episode: 714 \tReward: 6.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008778169060472\n",
      "Episode: 715 \tReward: 15.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008735086538606\n",
      "Episode: 716 \tReward: 7.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008701434095565\n",
      "Episode: 717 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008665138012707\n",
      "Episode: 718 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008594890086228\n",
      "Episode: 719 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000856314775244\n",
      "Episode: 720 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008531522648275\n",
      "Episode: 721 \tReward: 6.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008512092934926\n",
      "Episode: 722 \tReward: 11.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200084813348642\n",
      "Episode: 723 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008451194992886\n",
      "Episode: 724 \tReward: 8.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000842874468635\n",
      "Episode: 725 \tReward: 8.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000840467291559\n",
      "Episode: 726 \tReward: 14.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008369447314885\n",
      "Episode: 727 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000834087269552\n",
      "Episode: 728 \tReward: 9.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008315388635567\n",
      "Episode: 729 \tReward: 9.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000827209540054\n",
      "Episode: 730 \tReward: 9.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000821570733503\n",
      "Episode: 731 \tReward: 11.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000816933778114\n",
      "Episode: 732 \tReward: 12.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008137702163337\n",
      "Episode: 733 \tReward: 10.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020008110892007283\n",
      "Episode: 734 \tReward: 10.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000808417017893\n",
      "Episode: 735 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000805463619623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 736 \tReward: 9.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000802761803454\n",
      "Episode: 737 \tReward: 9.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000798342766063\n",
      "Episode: 738 \tReward: 14.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000794821877932\n",
      "Episode: 739 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007918706332645\n",
      "Episode: 740 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007860795819742\n",
      "Episode: 741 \tReward: 14.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007811116025603\n",
      "Episode: 742 \tReward: 11.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007781490109594\n",
      "Episode: 743 \tReward: 14.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007747016880708\n",
      "Episode: 744 \tReward: 20.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200076662520905\n",
      "Episode: 745 \tReward: 9.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000764206496967\n",
      "Episode: 746 \tReward: 9.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007618106520117\n",
      "Episode: 747 \tReward: 14.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007585115579946\n",
      "Episode: 748 \tReward: 12.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007558614080094\n",
      "Episode: 749 \tReward: 8.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000753672585253\n",
      "Episode: 750 \tReward: 15.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007502436621506\n",
      "Episode: 751 \tReward: 11.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007469349029087\n",
      "Episode: 752 \tReward: 13.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007438638617973\n",
      "Episode: 753 \tReward: 9.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007416059494233\n",
      "Episode: 754 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007388079704463\n",
      "Episode: 755 \tReward: 13.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007355643565598\n",
      "Episode: 756 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007331409949293\n",
      "Episode: 757 \tReward: 16.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007293823182892\n",
      "Episode: 758 \tReward: 7.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007274301906956\n",
      "Episode: 759 \tReward: 13.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000724468321839\n",
      "Episode: 760 \tReward: 10.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000721633964986\n",
      "Episode: 761 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007190695154994\n",
      "Episode: 762 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007167721707617\n",
      "Episode: 763 \tReward: 14.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007116441780992\n",
      "Episode: 764 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000709583399556\n",
      "Episode: 765 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007072597788268\n",
      "Episode: 766 \tReward: 15.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020007042814312932\n",
      "Episode: 767 \tReward: 8.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000702199840531\n",
      "Episode: 768 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006994805839187\n",
      "Episode: 769 \tReward: 9.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006972597686298\n",
      "Episode: 770 \tReward: 13.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000694337418832\n",
      "Episode: 771 \tReward: 7.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000692700714594\n",
      "Episode: 772 \tReward: 15.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006893423565413\n",
      "Episode: 773 \tReward: 6.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000687827470343\n",
      "Episode: 774 \tReward: 13.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006850405520856\n",
      "Episode: 775 \tReward: 19.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006792831402807\n",
      "Episode: 776 \tReward: 14.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000676327912866\n",
      "Episode: 777 \tReward: 8.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000674585235871\n",
      "Episode: 778 \tReward: 7.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006728874212214\n",
      "Episode: 779 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006706571392995\n",
      "Episode: 780 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006683540423384\n",
      "Episode: 781 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006660721757295\n",
      "Episode: 782 \tReward: 6.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006647280679406\n",
      "Episode: 783 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006623790907226\n",
      "Episode: 784 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006602232508153\n",
      "Episode: 785 \tReward: 18.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006569697906193\n",
      "Episode: 786 \tReward: 11.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006547791718884\n",
      "Episode: 787 \tReward: 14.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006519957455237\n",
      "Episode: 788 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000640416045751\n",
      "Episode: 789 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006382933900373\n",
      "Episode: 790 \tReward: 10.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000636177769855\n",
      "Episode: 791 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000633600124271\n",
      "Episode: 792 \tReward: 9.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006317779810587\n",
      "Episode: 793 \tReward: 18.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006286395478978\n",
      "Episode: 794 \tReward: 12.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006262803013607\n",
      "Episode: 795 \tReward: 8.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006241545641373\n",
      "Episode: 796 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006218992092702\n",
      "Episode: 797 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006195033053918\n",
      "Episode: 798 \tReward: 10.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006174252673446\n",
      "Episode: 799 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006152680562304\n",
      "Episode: 800 \tReward: 16.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006121871501324\n",
      "Episode: 801 \tReward: 13.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006096335485904\n",
      "Episode: 802 \tReward: 15.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020006066900512248\n",
      "Episode: 803 \tReward: 8.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000604775936557\n",
      "Episode: 804 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000602289385511\n",
      "Episode: 805 \tReward: 12.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000599885039866\n",
      "Episode: 806 \tReward: 10.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005980641584868\n",
      "Episode: 807 \tReward: 13.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005955218241885\n",
      "Episode: 808 \tReward: 10.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005937260612464\n",
      "Episode: 809 \tReward: 13.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000591308593903\n",
      "Episode: 810 \tReward: 8.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005895491172158\n",
      "Episode: 811 \tReward: 9.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005878654155814\n",
      "Episode: 812 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000585998972777\n",
      "Episode: 813 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005843721579528\n",
      "Episode: 814 \tReward: 7.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005828431068306\n",
      "Episode: 815 \tReward: 10.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000580911276329\n",
      "Episode: 816 \tReward: 11.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005786848544937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 817 \tReward: 12.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005764208502117\n",
      "Episode: 818 \tReward: 6.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000574889608205\n",
      "Episode: 819 \tReward: 5.0 \tMean: 8.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000573591824738\n",
      "Episode: 820 \tReward: 10.0 \tMean: 8.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005715763308653\n",
      "Episode: 821 \tReward: 14.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000568975876339\n",
      "Episode: 822 \tReward: 19.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000565809832426\n",
      "Episode: 823 \tReward: 2.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000565142570586\n",
      "Episode: 824 \tReward: 11.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005632018201477\n",
      "Episode: 825 \tReward: 7.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005617393973888\n",
      "Episode: 826 \tReward: 12.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000558446061628\n",
      "Episode: 827 \tReward: 6.0 \tMean: 9.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000557174255018\n",
      "Episode: 828 \tReward: 9.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200055546079839\n",
      "Episode: 829 \tReward: 14.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000553000019417\n",
      "Episode: 830 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000551464814287\n",
      "Episode: 831 \tReward: 7.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000550010867232\n",
      "Episode: 832 \tReward: 15.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005473224060915\n",
      "Episode: 833 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005453010549946\n",
      "Episode: 834 \tReward: 13.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005429287178477\n",
      "Episode: 835 \tReward: 8.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000538430290323\n",
      "Episode: 836 \tReward: 6.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005369784893524\n",
      "Episode: 837 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005348027763718\n",
      "Episode: 838 \tReward: 5.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005335954868482\n",
      "Episode: 839 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005247374470462\n",
      "Episode: 840 \tReward: 12.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000522956369274\n",
      "Episode: 841 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000521358568666\n",
      "Episode: 842 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005195577851704\n",
      "Episode: 843 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005175561577458\n",
      "Episode: 844 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000515881989412\n",
      "Episode: 845 \tReward: 8.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005121400058758\n",
      "Episode: 846 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005101159417442\n",
      "Episode: 847 \tReward: 9.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000508526860262\n",
      "Episode: 848 \tReward: 14.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000506334762566\n",
      "Episode: 849 \tReward: 13.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005043437285142\n",
      "Episode: 850 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020005026519773202\n",
      "Episode: 851 \tReward: 13.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000500715480531\n",
      "Episode: 852 \tReward: 10.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200049923555408\n",
      "Episode: 853 \tReward: 9.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000497670412998\n",
      "Episode: 854 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000495544935397\n",
      "Episode: 855 \tReward: 9.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004939320892753\n",
      "Episode: 856 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200049218666091\n",
      "Episode: 857 \tReward: 11.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004905356889157\n",
      "Episode: 858 \tReward: 12.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004885579225105\n",
      "Episode: 859 \tReward: 12.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004868801706446\n",
      "Episode: 860 \tReward: 9.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004853149378724\n",
      "Episode: 861 \tReward: 14.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000483251893641\n",
      "Episode: 862 \tReward: 15.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004762095729458\n",
      "Episode: 863 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004746406714662\n",
      "Episode: 864 \tReward: 11.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200047291612001\n",
      "Episode: 865 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004714240637614\n",
      "Episode: 866 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004694857921997\n",
      "Episode: 867 \tReward: 13.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004676022477758\n",
      "Episode: 868 \tReward: 10.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000465931224645\n",
      "Episode: 869 \tReward: 9.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004644147620296\n",
      "Episode: 870 \tReward: 9.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004627828958368\n",
      "Episode: 871 \tReward: 7.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004616089188635\n",
      "Episode: 872 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000460014511919\n",
      "Episode: 873 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004580865026225\n",
      "Episode: 874 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004563673314397\n",
      "Episode: 875 \tReward: 6.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200045536442691\n",
      "Episode: 876 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004535193952854\n",
      "Episode: 877 \tReward: 15.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000449339189906\n",
      "Episode: 878 \tReward: 9.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000448046954751\n",
      "Episode: 879 \tReward: 6.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004470533937724\n",
      "Episode: 880 \tReward: 8.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000445723157695\n",
      "Episode: 881 \tReward: 11.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004442369257372\n",
      "Episode: 882 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000442525476426\n",
      "Episode: 883 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004406002653588\n",
      "Episode: 884 \tReward: 9.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004392804452827\n",
      "Episode: 885 \tReward: 7.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004380083773813\n",
      "Episode: 886 \tReward: 16.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000435849951698\n",
      "Episode: 887 \tReward: 15.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004340405819974\n",
      "Episode: 888 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000432550047584\n",
      "Episode: 889 \tReward: 13.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004307974545624\n",
      "Episode: 890 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200042897474024\n",
      "Episode: 891 \tReward: 14.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004269376725437\n",
      "Episode: 892 \tReward: 9.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000425573655583\n",
      "Episode: 893 \tReward: 5.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000424706370257\n",
      "Episode: 894 \tReward: 11.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000418877299872\n",
      "Episode: 895 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004175390348784\n",
      "Episode: 896 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200041344232994\n",
      "Episode: 897 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004119566134463\n",
      "Episode: 898 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000410673311804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 899 \tReward: 13.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004089684593784\n",
      "Episode: 900 \tReward: 10.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004075069699208\n",
      "Episode: 901 \tReward: 9.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004062294048622\n",
      "Episode: 902 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004041548257637\n",
      "Episode: 903 \tReward: 14.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004013998395496\n",
      "Episode: 904 \tReward: 8.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020004002374662707\n",
      "Episode: 905 \tReward: 5.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003994457801155\n",
      "Episode: 906 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003959935949025\n",
      "Episode: 907 \tReward: 7.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003945469073983\n",
      "Episode: 908 \tReward: 12.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000393058335262\n",
      "Episode: 909 \tReward: 9.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000391857415101\n",
      "Episode: 910 \tReward: 7.0 \tMean: 9.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000390722674766\n",
      "Episode: 911 \tReward: 11.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003892796720706\n",
      "Episode: 912 \tReward: 10.0 \tMean: 9.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003879350918703\n",
      "Episode: 913 \tReward: 18.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003857301518956\n",
      "Episode: 914 \tReward: 10.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003844285848695\n",
      "Episode: 915 \tReward: 10.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003831467352764\n",
      "Episode: 916 \tReward: 14.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003815485245106\n",
      "Episode: 917 \tReward: 6.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003806948123305\n",
      "Episode: 918 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003789173231774\n",
      "Episode: 919 \tReward: 7.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003778956263162\n",
      "Episode: 920 \tReward: 12.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003748395383394\n",
      "Episode: 921 \tReward: 10.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003735672480285\n",
      "Episode: 922 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000372142943295\n",
      "Episode: 923 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200037070182625\n",
      "Episode: 924 \tReward: 11.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000368241155217\n",
      "Episode: 925 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003665218130094\n",
      "Episode: 926 \tReward: 8.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003654823677715\n",
      "Episode: 927 \tReward: 15.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003635940640356\n",
      "Episode: 928 \tReward: 11.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003623599434115\n",
      "Episode: 929 \tReward: 9.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000361072235493\n",
      "Episode: 930 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003598394776653\n",
      "Episode: 931 \tReward: 11.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000358603756521\n",
      "Episode: 932 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003567153185502\n",
      "Episode: 933 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000355618325605\n",
      "Episode: 934 \tReward: 14.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003526013281307\n",
      "Episode: 935 \tReward: 8.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000351608393082\n",
      "Episode: 936 \tReward: 18.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003499037219975\n",
      "Episode: 937 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003485208431655\n",
      "Episode: 938 \tReward: 9.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003474421014654\n",
      "Episode: 939 \tReward: 9.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003464013370883\n",
      "Episode: 940 \tReward: 6.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003456400918232\n",
      "Episode: 941 \tReward: 10.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000344515139792\n",
      "Episode: 942 \tReward: 5.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003416811651655\n",
      "Episode: 943 \tReward: 7.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003406372188524\n",
      "Episode: 944 \tReward: 15.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003389925180998\n",
      "Episode: 945 \tReward: 14.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003374029915783\n",
      "Episode: 946 \tReward: 12.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003357739066648\n",
      "Episode: 947 \tReward: 4.0 \tMean: 9.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000335116434341\n",
      "Episode: 948 \tReward: 15.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000333705222739\n",
      "Episode: 949 \tReward: 9.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003326058105314\n",
      "Episode: 950 \tReward: 9.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003315763290397\n",
      "Episode: 951 \tReward: 9.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003305632562647\n",
      "Episode: 952 \tReward: 7.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000329691720202\n",
      "Episode: 953 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000328671258402\n",
      "Episode: 954 \tReward: 15.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000327169385952\n",
      "Episode: 955 \tReward: 8.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000321976331001\n",
      "Episode: 956 \tReward: 12.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003208064675992\n",
      "Episode: 957 \tReward: 13.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000319551367849\n",
      "Episode: 958 \tReward: 10.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000318549550231\n",
      "Episode: 959 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003173286655566\n",
      "Episode: 960 \tReward: 6.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003166566413832\n",
      "Episode: 961 \tReward: 6.0 \tMean: 9.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003158786233998\n",
      "Episode: 962 \tReward: 12.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003146365101934\n",
      "Episode: 963 \tReward: 7.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000313863455625\n",
      "Episode: 964 \tReward: 9.0 \tMean: 9.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003127918760525\n",
      "Episode: 965 \tReward: 13.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003115432075502\n",
      "Episode: 966 \tReward: 13.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000310268495345\n",
      "Episode: 967 \tReward: 10.0 \tMean: 9.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003092215581515\n",
      "Episode: 968 \tReward: 11.0 \tMean: 9.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003081226865563\n",
      "Episode: 969 \tReward: 12.0 \tMean: 9.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000307058424296\n",
      "Episode: 970 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003061263841052\n",
      "Episode: 971 \tReward: 12.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200030487383541\n",
      "Episode: 972 \tReward: 16.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003034503593923\n",
      "Episode: 973 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003022692077335\n",
      "Episode: 974 \tReward: 8.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000301544631474\n",
      "Episode: 975 \tReward: 16.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020003001607116253\n",
      "Episode: 976 \tReward: 8.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002993393969902\n",
      "Episode: 977 \tReward: 14.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002957569601965\n",
      "Episode: 978 \tReward: 8.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002949476953247\n",
      "Episode: 979 \tReward: 14.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002936410304997\n",
      "Episode: 980 \tReward: 15.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002923576953418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 981 \tReward: 10.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002913945050854\n",
      "Episode: 982 \tReward: 10.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200029045191471\n",
      "Episode: 983 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002884258508036\n",
      "Episode: 984 \tReward: 10.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002874986132176\n",
      "Episode: 985 \tReward: 11.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002861276490612\n",
      "Episode: 986 \tReward: 8.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002814452786385\n",
      "Episode: 987 \tReward: 8.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002806583340946\n",
      "Episode: 988 \tReward: 12.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000279593856214\n",
      "Episode: 989 \tReward: 11.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002784888538922\n",
      "Episode: 990 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002773993144773\n",
      "Episode: 991 \tReward: 10.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002764080004422\n",
      "Episode: 992 \tReward: 14.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002752164933888\n",
      "Episode: 993 \tReward: 5.0 \tMean: 10.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002746391451803\n",
      "Episode: 994 \tReward: 11.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002733021710222\n",
      "Episode: 995 \tReward: 12.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002707451673596\n",
      "Episode: 996 \tReward: 13.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002697128937184\n",
      "Episode: 997 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002688028030572\n",
      "Episode: 998 \tReward: 15.0 \tMean: 11.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002675584471892\n",
      "Episode: 999 \tReward: 7.0 \tMean: 10.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002668957243563\n",
      "Episode: 1000 \tReward: 6.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000266330504765\n",
      "Episode: 1001 \tReward: 11.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002654477536668\n",
      "Episode: 1002 \tReward: 11.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002644303888834\n",
      "Episode: 1003 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002634801509378\n",
      "Episode: 1004 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000262554331205\n",
      "Episode: 1005 \tReward: 14.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002589611464228\n",
      "Episode: 1006 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002582577291858\n",
      "Episode: 1007 \tReward: 11.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002573348195093\n",
      "Episode: 1008 \tReward: 13.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000256251154712\n",
      "Episode: 1009 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000255401811568\n",
      "Episode: 1010 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002541635701275\n",
      "Episode: 1011 \tReward: 12.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002532097094856\n",
      "Episode: 1012 \tReward: 12.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002521837621478\n",
      "Episode: 1013 \tReward: 9.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002514384018892\n",
      "Episode: 1014 \tReward: 18.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002487325036886\n",
      "Episode: 1015 \tReward: 17.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000247457298704\n",
      "Episode: 1016 \tReward: 9.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002466864351046\n",
      "Episode: 1017 \tReward: 12.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000245721317146\n",
      "Episode: 1018 \tReward: 12.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002447697656394\n",
      "Episode: 1019 \tReward: 10.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000243919447267\n",
      "Episode: 1020 \tReward: 13.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000240302377514\n",
      "Episode: 1021 \tReward: 12.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002393622360753\n",
      "Episode: 1022 \tReward: 13.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200023824940297\n",
      "Episode: 1023 \tReward: 15.0 \tMean: 13.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000236757884988\n",
      "Episode: 1024 \tReward: 17.0 \tMean: 13.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002355440716317\n",
      "Episode: 1025 \tReward: 10.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002348150156304\n",
      "Episode: 1026 \tReward: 11.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002334150120198\n",
      "Episode: 1027 \tReward: 10.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000232646012028\n",
      "Episode: 1028 \tReward: 12.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000231791448066\n",
      "Episode: 1029 \tReward: 18.0 \tMean: 13.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000230621545688\n",
      "Episode: 1030 \tReward: 9.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000229893931839\n",
      "Episode: 1031 \tReward: 10.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002290494769197\n",
      "Episode: 1032 \tReward: 16.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000226629842475\n",
      "Episode: 1033 \tReward: 10.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000225874161491\n",
      "Episode: 1034 \tReward: 9.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002251345079363\n",
      "Episode: 1035 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002242806202202\n",
      "Episode: 1036 \tReward: 15.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002232602288523\n",
      "Episode: 1037 \tReward: 10.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002224134498817\n",
      "Episode: 1038 \tReward: 15.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002213439965066\n",
      "Episode: 1039 \tReward: 8.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002208045755164\n",
      "Episode: 1040 \tReward: 10.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002200331103535\n",
      "Episode: 1041 \tReward: 16.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002189707231503\n",
      "Episode: 1042 \tReward: 10.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002181271253503\n",
      "Episode: 1043 \tReward: 5.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000217652126154\n",
      "Episode: 1044 \tReward: 11.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002168352907728\n",
      "Episode: 1045 \tReward: 9.0 \tMean: 10.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002161598189495\n",
      "Episode: 1046 \tReward: 13.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200021530121263\n",
      "Episode: 1047 \tReward: 13.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002143559683567\n",
      "Episode: 1048 \tReward: 11.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000213585674232\n",
      "Episode: 1049 \tReward: 7.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000211782125569\n",
      "Episode: 1050 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002111604005033\n",
      "Episode: 1051 \tReward: 17.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000210149259261\n",
      "Episode: 1052 \tReward: 9.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000209494615348\n",
      "Episode: 1053 \tReward: 12.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002087250919547\n",
      "Episode: 1054 \tReward: 13.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002079334416934\n",
      "Episode: 1055 \tReward: 11.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000207144793995\n",
      "Episode: 1056 \tReward: 17.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002060374681833\n",
      "Episode: 1057 \tReward: 8.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002054038490556\n",
      "Episode: 1058 \tReward: 15.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000204461161194\n",
      "Episode: 1059 \tReward: 8.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002037875514297\n",
      "Episode: 1060 \tReward: 12.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000202974029353\n",
      "Episode: 1061 \tReward: 13.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020002018728485605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1062 \tReward: 12.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000200805752765\n",
      "Episode: 1063 \tReward: 14.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001998921630997\n",
      "Episode: 1064 \tReward: 12.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000199066320219\n",
      "Episode: 1065 \tReward: 15.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000196687866195\n",
      "Episode: 1066 \tReward: 10.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001960437868616\n",
      "Episode: 1067 \tReward: 12.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200019539009289\n",
      "Episode: 1068 \tReward: 6.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000194956808008\n",
      "Episode: 1069 \tReward: 16.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001940193772164\n",
      "Episode: 1070 \tReward: 8.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001934884917683\n",
      "Episode: 1071 \tReward: 19.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001924772638024\n",
      "Episode: 1072 \tReward: 14.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001915211098283\n",
      "Episode: 1073 \tReward: 11.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001904592072822\n",
      "Episode: 1074 \tReward: 12.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000189774786832\n",
      "Episode: 1075 \tReward: 18.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000188654639003\n",
      "Episode: 1076 \tReward: 6.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001882249964048\n",
      "Episode: 1077 \tReward: 16.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001873236813086\n",
      "Episode: 1078 \tReward: 12.0 \tMean: 13.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001859872339416\n",
      "Episode: 1079 \tReward: 13.0 \tMean: 12.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001852410660634\n",
      "Episode: 1080 \tReward: 13.0 \tMean: 13.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000184442550693\n",
      "Episode: 1081 \tReward: 13.0 \tMean: 12.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001837356494176\n",
      "Episode: 1082 \tReward: 13.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001815730471974\n",
      "Episode: 1083 \tReward: 5.0 \tMean: 12.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001812030157416\n",
      "Episode: 1084 \tReward: 13.0 \tMean: 12.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000180436341453\n",
      "Episode: 1085 \tReward: 13.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001786731281265\n",
      "Episode: 1086 \tReward: 8.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001781806701972\n",
      "Episode: 1087 \tReward: 14.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001774374294512\n",
      "Episode: 1088 \tReward: 15.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000176686687448\n",
      "Episode: 1089 \tReward: 9.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001756227162833\n",
      "Episode: 1090 \tReward: 13.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001748831500032\n",
      "Episode: 1091 \tReward: 13.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001742198550915\n",
      "Episode: 1092 \tReward: 7.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000173763996507\n",
      "Episode: 1093 \tReward: 14.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001730357181766\n",
      "Episode: 1094 \tReward: 11.0 \tMean: 11.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001724104612744\n",
      "Episode: 1095 \tReward: 12.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001718080794432\n",
      "Episode: 1096 \tReward: 11.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000171159870789\n",
      "Episode: 1097 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001705448030406\n",
      "Episode: 1098 \tReward: 13.0 \tMean: 11.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001698334136033\n",
      "Episode: 1099 \tReward: 11.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000169240035673\n",
      "Episode: 1100 \tReward: 8.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001687499505365\n",
      "Episode: 1101 \tReward: 13.0 \tMean: 11.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001680258836085\n",
      "Episode: 1102 \tReward: 9.0 \tMean: 11.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000167532612974\n",
      "Episode: 1103 \tReward: 11.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001669105494092\n",
      "Episode: 1104 \tReward: 8.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000166410568108\n",
      "Episode: 1105 \tReward: 8.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000165928676541\n",
      "Episode: 1106 \tReward: 8.0 \tMean: 10.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001654878927636\n",
      "Episode: 1107 \tReward: 14.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001646427601386\n",
      "Episode: 1108 \tReward: 16.0 \tMean: 10.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001638642001003\n",
      "Episode: 1109 \tReward: 10.0 \tMean: 10.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000163285146362\n",
      "Episode: 1110 \tReward: 10.0 \tMean: 10.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000162178573977\n",
      "Episode: 1111 \tReward: 8.0 \tMean: 10.2 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001617121716254\n",
      "Episode: 1112 \tReward: 10.0 \tMean: 10.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001611084976775\n",
      "Episode: 1113 \tReward: 12.0 \tMean: 10.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001605745043845\n",
      "Episode: 1114 \tReward: 14.0 \tMean: 11.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.0200015989191195\n",
      "Episode: 1115 \tReward: 18.0 \tMean: 12.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001591835655537\n",
      "Episode: 1116 \tReward: 11.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001585576162353\n",
      "Episode: 1117 \tReward: 6.0 \tMean: 11.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001580573649813\n",
      "Episode: 1118 \tReward: 19.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000157146428554\n",
      "Episode: 1119 \tReward: 8.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000156681962874\n",
      "Episode: 1120 \tReward: 13.0 \tMean: 11.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000156006556722\n",
      "Episode: 1121 \tReward: 14.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001544851594888\n",
      "Episode: 1122 \tReward: 11.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000153677774449\n",
      "Episode: 1123 \tReward: 11.0 \tMean: 12.5 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000153171473649\n",
      "Episode: 1124 \tReward: 13.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000152587474768\n",
      "Episode: 1125 \tReward: 12.0 \tMean: 11.8 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001505835435224\n",
      "Episode: 1126 \tReward: 9.0 \tMean: 11.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000150108450567\n",
      "Episode: 1127 \tReward: 20.0 \tMean: 13.0 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001490136684997\n",
      "Episode: 1128 \tReward: 13.0 \tMean: 12.4 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001484158360006\n",
      "Episode: 1129 \tReward: 7.0 \tMean: 12.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001479712556967\n",
      "Episode: 1130 \tReward: 16.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001472450251107\n",
      "Episode: 1131 \tReward: 17.0 \tMean: 12.9 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001464579031476\n",
      "Episode: 1132 \tReward: 8.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001460162674855\n",
      "Episode: 1133 \tReward: 12.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001454682771872\n",
      "Episode: 1134 \tReward: 12.0 \tMean: 12.6 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001449020557557\n",
      "Episode: 1135 \tReward: 13.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001443351515553\n",
      "Episode: 1136 \tReward: 15.0 \tMean: 13.3 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000143698598005\n",
      "Episode: 1137 \tReward: 14.0 \tMean: 12.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000143084882294\n",
      "Episode: 1138 \tReward: 23.0 \tMean: 13.7 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.020001421464745157\n",
      "Episode: 1139 \tReward: 11.0 \tMean: 14.1 \tBestMean: 13.7 \tTRAIN START: True \tEpsi: 0.02000141655497594\n",
      "Episode: 1140 \tReward: 10.0 \tMean: 13.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001405436387502\n",
      "Episode: 1141 \tReward: 10.0 \tMean: 12.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000140108628085\n",
      "Episode: 1142 \tReward: 12.0 \tMean: 13.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001395939758745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1143 \tReward: 10.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001391563382407\n",
      "Episode: 1144 \tReward: 14.0 \tMean: 13.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001385897370334\n",
      "Episode: 1145 \tReward: 10.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001380944728267\n",
      "Episode: 1146 \tReward: 9.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001376560298968\n",
      "Episode: 1147 \tReward: 8.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000137240935794\n",
      "Episode: 1148 \tReward: 11.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000136777844496\n",
      "Episode: 1149 \tReward: 12.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000136210030535\n",
      "Episode: 1150 \tReward: 8.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001358481933105\n",
      "Episode: 1151 \tReward: 12.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001353491906872\n",
      "Episode: 1152 \tReward: 15.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001347468774536\n",
      "Episode: 1153 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001342680314216\n",
      "Episode: 1154 \tReward: 14.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000133734706677\n",
      "Episode: 1155 \tReward: 13.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000133187516885\n",
      "Episode: 1156 \tReward: 14.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000132597475172\n",
      "Episode: 1157 \tReward: 13.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000132017968277\n",
      "Episode: 1158 \tReward: 18.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001313568987492\n",
      "Episode: 1159 \tReward: 11.0 \tMean: 12.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000130863924183\n",
      "Episode: 1160 \tReward: 10.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001304040929476\n",
      "Episode: 1161 \tReward: 10.0 \tMean: 12.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001299406797415\n",
      "Episode: 1162 \tReward: 10.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001294970416705\n",
      "Episode: 1163 \tReward: 8.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001291246267254\n",
      "Episode: 1164 \tReward: 10.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001287120883334\n",
      "Episode: 1165 \tReward: 10.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000127913983822\n",
      "Episode: 1166 \tReward: 9.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000127421187553\n",
      "Episode: 1167 \tReward: 9.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000127021712528\n",
      "Episode: 1168 \tReward: 6.0 \tMean: 9.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000126719760318\n",
      "Episode: 1169 \tReward: 11.0 \tMean: 9.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001262189423413\n",
      "Episode: 1170 \tReward: 12.0 \tMean: 9.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001256999900748\n",
      "Episode: 1171 \tReward: 9.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001253485223868\n",
      "Episode: 1172 \tReward: 6.0 \tMean: 9.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001250905702126\n",
      "Episode: 1173 \tReward: 13.0 \tMean: 9.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001246061591652\n",
      "Episode: 1174 \tReward: 12.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001241509341926\n",
      "Episode: 1175 \tReward: 7.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000123779039511\n",
      "Episode: 1176 \tReward: 12.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000123255327438\n",
      "Episode: 1177 \tReward: 14.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001222561014394\n",
      "Episode: 1178 \tReward: 15.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200012167311173\n",
      "Episode: 1179 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000121233451331\n",
      "Episode: 1180 \tReward: 16.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001202650475412\n",
      "Episode: 1181 \tReward: 14.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000119746623139\n",
      "Episode: 1182 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001193067654004\n",
      "Episode: 1183 \tReward: 11.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001189065673778\n",
      "Episode: 1184 \tReward: 9.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001184911218457\n",
      "Episode: 1185 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001180629594262\n",
      "Episode: 1186 \tReward: 13.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001176010585424\n",
      "Episode: 1187 \tReward: 13.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200011709411775\n",
      "Episode: 1188 \tReward: 12.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000116687338427\n",
      "Episode: 1189 \tReward: 14.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001161866601013\n",
      "Episode: 1190 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001157459885992\n",
      "Episode: 1191 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001153692710594\n",
      "Episode: 1192 \tReward: 12.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001149271025656\n",
      "Episode: 1193 \tReward: 7.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001146355581433\n",
      "Episode: 1194 \tReward: 13.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001141550984706\n",
      "Episode: 1195 \tReward: 4.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001139315736036\n",
      "Episode: 1196 \tReward: 6.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001136561925408\n",
      "Episode: 1197 \tReward: 9.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001132862766436\n",
      "Episode: 1198 \tReward: 12.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001128656345738\n",
      "Episode: 1199 \tReward: 14.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000111749307503\n",
      "Episode: 1200 \tReward: 10.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000111378914994\n",
      "Episode: 1201 \tReward: 10.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000110952040085\n",
      "Episode: 1202 \tReward: 9.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001105820784508\n",
      "Episode: 1203 \tReward: 7.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000109670239066\n",
      "Episode: 1204 \tReward: 15.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000109180015316\n",
      "Episode: 1205 \tReward: 7.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001087767956754\n",
      "Episode: 1206 \tReward: 10.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001083902387626\n",
      "Episode: 1207 \tReward: 12.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000108022337737\n",
      "Episode: 1208 \tReward: 10.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000107621241143\n",
      "Episode: 1209 \tReward: 7.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001072645310886\n",
      "Episode: 1210 \tReward: 12.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001067487600555\n",
      "Episode: 1211 \tReward: 9.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001064162229517\n",
      "Episode: 1212 \tReward: 10.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001060126086573\n",
      "Episode: 1213 \tReward: 10.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000105686592146\n",
      "Episode: 1214 \tReward: 13.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001052583744516\n",
      "Episode: 1215 \tReward: 9.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001049178892026\n",
      "Episode: 1216 \tReward: 8.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001046308076673\n",
      "Episode: 1217 \tReward: 13.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001041735269058\n",
      "Episode: 1218 \tReward: 13.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001037555899437\n",
      "Episode: 1219 \tReward: 12.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000103306266421\n",
      "Episode: 1220 \tReward: 15.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001024769644896\n",
      "Episode: 1221 \tReward: 7.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000102194518023\n",
      "Episode: 1222 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001017885921697\n",
      "Episode: 1223 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000101404557574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1224 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000100914945333\n",
      "Episode: 1225 \tReward: 14.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020001004236800617\n",
      "Episode: 1226 \tReward: 15.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000999507971733\n",
      "Episode: 1227 \tReward: 11.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000995657307525\n",
      "Episode: 1228 \tReward: 13.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000991543807092\n",
      "Episode: 1229 \tReward: 17.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000098667739276\n",
      "Episode: 1230 \tReward: 15.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000098218838656\n",
      "Episode: 1231 \tReward: 17.0 \tMean: 13.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000977680695618\n",
      "Episode: 1232 \tReward: 9.0 \tMean: 13.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000974986017266\n",
      "Episode: 1233 \tReward: 10.0 \tMean: 13.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000971773866373\n",
      "Episode: 1234 \tReward: 10.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000968494815422\n",
      "Episode: 1235 \tReward: 14.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000964223514866\n",
      "Episode: 1236 \tReward: 13.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000096043194851\n",
      "Episode: 1237 \tReward: 6.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000095814883845\n",
      "Episode: 1238 \tReward: 9.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000095516407273\n",
      "Episode: 1239 \tReward: 15.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000951046663943\n",
      "Episode: 1240 \tReward: 13.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000947382699818\n",
      "Episode: 1241 \tReward: 16.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000942751879365\n",
      "Episode: 1242 \tReward: 10.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000936231832057\n",
      "Episode: 1243 \tReward: 12.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000932774174886\n",
      "Episode: 1244 \tReward: 15.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000092856754975\n",
      "Episode: 1245 \tReward: 12.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000924879195598\n",
      "Episode: 1246 \tReward: 12.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000092135289659\n",
      "Episode: 1247 \tReward: 10.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000918060350394\n",
      "Episode: 1248 \tReward: 7.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000091589628257\n",
      "Episode: 1249 \tReward: 17.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000911109538274\n",
      "Episode: 1250 \tReward: 10.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000907944387636\n",
      "Episode: 1251 \tReward: 9.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000905297057007\n",
      "Episode: 1252 \tReward: 9.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000090265744531\n",
      "Episode: 1253 \tReward: 13.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000899251840815\n",
      "Episode: 1254 \tReward: 9.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000896396761943\n",
      "Episode: 1255 \tReward: 11.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000893211263023\n",
      "Episode: 1256 \tReward: 11.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000890001483546\n",
      "Episode: 1257 \tReward: 15.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000886076357905\n",
      "Episode: 1258 \tReward: 7.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000883828579844\n",
      "Episode: 1259 \tReward: 8.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000881251564663\n",
      "Episode: 1260 \tReward: 15.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000877066774916\n",
      "Episode: 1261 \tReward: 10.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000087412477588\n",
      "Episode: 1262 \tReward: 11.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000870948745576\n",
      "Episode: 1263 \tReward: 11.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000867766899497\n",
      "Episode: 1264 \tReward: 15.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000853378459495\n",
      "Episode: 1265 \tReward: 16.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000084717147978\n",
      "Episode: 1266 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000084443108602\n",
      "Episode: 1267 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000841379771702\n",
      "Episode: 1268 \tReward: 6.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000839379668914\n",
      "Episode: 1269 \tReward: 9.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000836965733203\n",
      "Episode: 1270 \tReward: 14.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000833524528132\n",
      "Episode: 1271 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000830429577066\n",
      "Episode: 1272 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000827925462858\n",
      "Episode: 1273 \tReward: 11.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000082503278887\n",
      "Episode: 1274 \tReward: 7.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000822874032168\n",
      "Episode: 1275 \tReward: 9.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000819818627346\n",
      "Episode: 1276 \tReward: 15.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000081310733941\n",
      "Episode: 1277 \tReward: 5.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000811531440288\n",
      "Episode: 1278 \tReward: 10.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000080910049421\n",
      "Episode: 1279 \tReward: 13.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000806047867442\n",
      "Episode: 1280 \tReward: 12.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000801129918765\n",
      "Episode: 1281 \tReward: 7.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000799065667606\n",
      "Episode: 1282 \tReward: 13.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000795955380502\n",
      "Episode: 1283 \tReward: 12.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000792159792467\n",
      "Episode: 1284 \tReward: 6.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000790403148325\n",
      "Episode: 1285 \tReward: 11.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000078748406032\n",
      "Episode: 1286 \tReward: 13.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000784277670835\n",
      "Episode: 1287 \tReward: 13.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000078120932026\n",
      "Episode: 1288 \tReward: 8.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000077897825355\n",
      "Episode: 1289 \tReward: 16.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000775155093232\n",
      "Episode: 1290 \tReward: 11.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000772338657713\n",
      "Episode: 1291 \tReward: 14.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000768671061507\n",
      "Episode: 1292 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000076566376909\n",
      "Episode: 1293 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000762958111186\n",
      "Episode: 1294 \tReward: 14.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000075965404799\n",
      "Episode: 1295 \tReward: 6.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000757696666652\n",
      "Episode: 1296 \tReward: 10.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000755200388777\n",
      "Episode: 1297 \tReward: 14.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000075174947961\n",
      "Episode: 1298 \tReward: 15.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000748104840784\n",
      "Episode: 1299 \tReward: 14.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000074468635492\n",
      "Episode: 1300 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000742039984833\n",
      "Episode: 1301 \tReward: 18.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200007357740907\n",
      "Episode: 1302 \tReward: 14.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000073230942005\n",
      "Episode: 1303 \tReward: 13.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000729254755368\n",
      "Episode: 1304 \tReward: 9.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000072492132348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1305 \tReward: 12.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000721969669948\n",
      "Episode: 1306 \tReward: 11.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000719447193015\n",
      "Episode: 1307 \tReward: 10.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000071711995627\n",
      "Episode: 1308 \tReward: 8.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000713843056697\n",
      "Episode: 1309 \tReward: 10.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000711605104922\n",
      "Episode: 1310 \tReward: 11.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000708920315073\n",
      "Episode: 1311 \tReward: 15.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000070563854441\n",
      "Episode: 1312 \tReward: 17.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000070199278741\n",
      "Episode: 1313 \tReward: 19.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000698477614084\n",
      "Episode: 1314 \tReward: 13.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000695105150377\n",
      "Episode: 1315 \tReward: 8.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000069289822687\n",
      "Episode: 1316 \tReward: 13.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000068999415713\n",
      "Episode: 1317 \tReward: 8.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000687941035215\n",
      "Episode: 1318 \tReward: 4.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000068666265415\n",
      "Episode: 1319 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000684427778723\n",
      "Episode: 1320 \tReward: 8.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000682391219923\n",
      "Episode: 1321 \tReward: 15.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000679653513695\n",
      "Episode: 1322 \tReward: 14.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000676832027837\n",
      "Episode: 1323 \tReward: 13.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000674143589907\n",
      "Episode: 1324 \tReward: 14.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000670995969087\n",
      "Episode: 1325 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000668611470363\n",
      "Episode: 1326 \tReward: 5.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000667328967936\n",
      "Episode: 1327 \tReward: 12.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000662064596934\n",
      "Episode: 1328 \tReward: 9.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200006602002048\n",
      "Episode: 1329 \tReward: 14.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000657354291514\n",
      "Episode: 1330 \tReward: 13.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000654782506684\n",
      "Episode: 1331 \tReward: 8.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000652938621116\n",
      "Episode: 1332 \tReward: 12.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000650605280026\n",
      "Episode: 1333 \tReward: 12.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000064834510863\n",
      "Episode: 1334 \tReward: 14.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000645550298894\n",
      "Episode: 1335 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000643487839635\n",
      "Episode: 1336 \tReward: 10.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000641239568965\n",
      "Episode: 1337 \tReward: 12.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000638820258772\n",
      "Episode: 1338 \tReward: 8.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000637148740338\n",
      "Episode: 1339 \tReward: 11.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000634922617732\n",
      "Episode: 1340 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000632754891307\n",
      "Episode: 1341 \tReward: 12.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000630367592653\n",
      "Episode: 1342 \tReward: 15.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200006274745608\n",
      "Episode: 1343 \tReward: 9.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000062544483316\n",
      "Episode: 1344 \tReward: 8.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000062367108974\n",
      "Episode: 1345 \tReward: 8.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000621952130787\n",
      "Episode: 1346 \tReward: 10.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000061975431268\n",
      "Episode: 1347 \tReward: 5.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000061846656343\n",
      "Episode: 1348 \tReward: 8.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000616675608537\n",
      "Episode: 1349 \tReward: 11.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000614729989312\n",
      "Episode: 1350 \tReward: 8.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000611370482427\n",
      "Episode: 1351 \tReward: 12.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000609319724808\n",
      "Episode: 1352 \tReward: 15.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000606462641506\n",
      "Episode: 1353 \tReward: 13.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000060011609588\n",
      "Episode: 1354 \tReward: 10.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000059825861656\n",
      "Episode: 1355 \tReward: 12.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000059601338784\n",
      "Episode: 1356 \tReward: 8.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000059420425841\n",
      "Episode: 1357 \tReward: 5.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000059291030405\n",
      "Episode: 1358 \tReward: 14.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000059060245709\n",
      "Episode: 1359 \tReward: 14.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000587985995025\n",
      "Episode: 1360 \tReward: 12.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000585767603364\n",
      "Episode: 1361 \tReward: 14.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000583405876148\n",
      "Episode: 1362 \tReward: 13.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000581100157216\n",
      "Episode: 1363 \tReward: 12.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200005783059938\n",
      "Episode: 1364 \tReward: 8.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000576758208696\n",
      "Episode: 1365 \tReward: 10.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000574881038385\n",
      "Episode: 1366 \tReward: 17.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000057192229236\n",
      "Episode: 1367 \tReward: 11.0 \tMean: 12.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000568421448074\n",
      "Episode: 1368 \tReward: 12.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000056633350132\n",
      "Episode: 1369 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000564005007288\n",
      "Episode: 1370 \tReward: 8.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200005625742524\n",
      "Episode: 1371 \tReward: 15.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000559880366486\n",
      "Episode: 1372 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000557723393906\n",
      "Episode: 1373 \tReward: 10.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000555696971078\n",
      "Episode: 1374 \tReward: 10.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000553777582017\n",
      "Episode: 1375 \tReward: 12.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000551566896008\n",
      "Episode: 1376 \tReward: 16.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000549101403142\n",
      "Episode: 1377 \tReward: 11.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000054707348192\n",
      "Episode: 1378 \tReward: 10.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000544464710605\n",
      "Episode: 1379 \tReward: 13.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000054130512929\n",
      "Episode: 1380 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000539230503423\n",
      "Episode: 1381 \tReward: 10.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000537367989887\n",
      "Episode: 1382 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000053552261986\n",
      "Episode: 1383 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200005335448473\n",
      "Episode: 1384 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000531904057286\n",
      "Episode: 1385 \tReward: 11.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000053006684945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1386 \tReward: 7.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000528690465716\n",
      "Episode: 1387 \tReward: 7.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000052690650853\n",
      "Episode: 1388 \tReward: 11.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000521747174038\n",
      "Episode: 1389 \tReward: 13.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000519570822595\n",
      "Episode: 1390 \tReward: 8.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000518169873506\n",
      "Episode: 1391 \tReward: 7.0 \tMean: 9.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000516907080247\n",
      "Episode: 1392 \tReward: 16.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000051440100653\n",
      "Episode: 1393 \tReward: 12.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000051260375004\n",
      "Episode: 1394 \tReward: 13.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000508458261054\n",
      "Episode: 1395 \tReward: 11.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000050649939521\n",
      "Episode: 1396 \tReward: 7.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200005051235888\n",
      "Episode: 1397 \tReward: 12.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000050309706801\n",
      "Episode: 1398 \tReward: 9.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000501479700807\n",
      "Episode: 1399 \tReward: 8.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000500147537365\n",
      "Episode: 1400 \tReward: 17.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000496529615195\n",
      "Episode: 1401 \tReward: 12.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000494567245973\n",
      "Episode: 1402 \tReward: 9.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000492661896095\n",
      "Episode: 1403 \tReward: 12.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000490459707386\n",
      "Episode: 1404 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000489000313038\n",
      "Episode: 1405 \tReward: 11.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000048734053519\n",
      "Episode: 1406 \tReward: 12.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000485297997278\n",
      "Episode: 1407 \tReward: 9.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000483912027887\n",
      "Episode: 1408 \tReward: 17.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000481325198313\n",
      "Episode: 1409 \tReward: 12.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000479374979632\n",
      "Episode: 1410 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000047666938131\n",
      "Episode: 1411 \tReward: 15.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000474424803204\n",
      "Episode: 1412 \tReward: 8.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000047314558396\n",
      "Episode: 1413 \tReward: 14.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000469854526932\n",
      "Episode: 1414 \tReward: 6.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000046874697767\n",
      "Episode: 1415 \tReward: 10.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000467296112046\n",
      "Episode: 1416 \tReward: 12.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000465365505253\n",
      "Episode: 1417 \tReward: 13.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000462850047265\n",
      "Episode: 1418 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000045990646398\n",
      "Episode: 1419 \tReward: 6.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000045881318811\n",
      "Episode: 1420 \tReward: 14.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000456817117204\n",
      "Episode: 1421 \tReward: 14.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000454884313068\n",
      "Episode: 1422 \tReward: 10.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000453186223146\n",
      "Episode: 1423 \tReward: 12.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000451566717113\n",
      "Episode: 1424 \tReward: 14.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000449656127545\n",
      "Episode: 1425 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000444808178478\n",
      "Episode: 1426 \tReward: 12.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000442226913644\n",
      "Episode: 1427 \tReward: 11.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000044057607398\n",
      "Episode: 1428 \tReward: 16.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000438431300244\n",
      "Episode: 1429 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000043566915201\n",
      "Episode: 1430 \tReward: 10.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000043425986823\n",
      "Episode: 1431 \tReward: 11.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000432777236225\n",
      "Episode: 1432 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000043130829224\n",
      "Episode: 1433 \tReward: 11.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000429818544302\n",
      "Episode: 1434 \tReward: 10.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000424589631548\n",
      "Episode: 1435 \tReward: 3.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000423927788096\n",
      "Episode: 1436 \tReward: 12.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000422412839988\n",
      "Episode: 1437 \tReward: 13.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000042075180778\n",
      "Episode: 1438 \tReward: 9.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000041677359205\n",
      "Episode: 1439 \tReward: 13.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000041365948262\n",
      "Episode: 1440 \tReward: 10.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000412321394767\n",
      "Episode: 1441 \tReward: 10.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000410905446\n",
      "Episode: 1442 \tReward: 14.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200004091996299\n",
      "Episode: 1443 \tReward: 15.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000405444148685\n",
      "Episode: 1444 \tReward: 16.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000040338971509\n",
      "Episode: 1445 \tReward: 13.0 \tMean: 12.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000040177937905\n",
      "Episode: 1446 \tReward: 11.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000400327567062\n",
      "Episode: 1447 \tReward: 9.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000039809199812\n",
      "Episode: 1448 \tReward: 13.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000039637595002\n",
      "Episode: 1449 \tReward: 9.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000039495156204\n",
      "Episode: 1450 \tReward: 13.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000393288378233\n",
      "Episode: 1451 \tReward: 11.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000039134249765\n",
      "Episode: 1452 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000038986601532\n",
      "Episode: 1453 \tReward: 5.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000389102626293\n",
      "Episode: 1454 \tReward: 14.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000387495071357\n",
      "Episode: 1455 \tReward: 8.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000386396146565\n",
      "Episode: 1456 \tReward: 6.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000385539298574\n",
      "Episode: 1457 \tReward: 13.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000038413848655\n",
      "Episode: 1458 \tReward: 9.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000383003117805\n",
      "Episode: 1459 \tReward: 7.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200003819856833\n",
      "Episode: 1460 \tReward: 15.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200003803314577\n",
      "Episode: 1461 \tReward: 10.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000379086014163\n",
      "Episode: 1462 \tReward: 14.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000377021844835\n",
      "Episode: 1463 \tReward: 9.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000037593006533\n",
      "Episode: 1464 \tReward: 12.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000037454169416\n",
      "Episode: 1465 \tReward: 14.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000372845128987\n",
      "Episode: 1466 \tReward: 13.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000371297314933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1467 \tReward: 6.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000370362823653\n",
      "Episode: 1468 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000368995013215\n",
      "Episode: 1469 \tReward: 13.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000036761754933\n",
      "Episode: 1470 \tReward: 10.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000366487029173\n",
      "Episode: 1471 \tReward: 8.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000365528089915\n",
      "Episode: 1472 \tReward: 8.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000364440437613\n",
      "Episode: 1473 \tReward: 11.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000363152599284\n",
      "Episode: 1474 \tReward: 13.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000361500393325\n",
      "Episode: 1475 \tReward: 13.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000359718985082\n",
      "Episode: 1476 \tReward: 8.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000035874905382\n",
      "Episode: 1477 \tReward: 17.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200003542146657\n",
      "Episode: 1478 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000035290649305\n",
      "Episode: 1479 \tReward: 14.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000351350088538\n",
      "Episode: 1480 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000348425045514\n",
      "Episode: 1481 \tReward: 13.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000346964729132\n",
      "Episode: 1482 \tReward: 11.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000343141579297\n",
      "Episode: 1483 \tReward: 9.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000342120539496\n",
      "Episode: 1484 \tReward: 12.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000340925210653\n",
      "Episode: 1485 \tReward: 5.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000340203214794\n",
      "Episode: 1486 \tReward: 11.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000033893323112\n",
      "Episode: 1487 \tReward: 14.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000337559951845\n",
      "Episode: 1488 \tReward: 13.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000335004220292\n",
      "Episode: 1489 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000333820401946\n",
      "Episode: 1490 \tReward: 13.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000331976150212\n",
      "Episode: 1491 \tReward: 15.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000330584774316\n",
      "Episode: 1492 \tReward: 10.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000329462694703\n",
      "Episode: 1493 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000326530424987\n",
      "Episode: 1494 \tReward: 12.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000032529196394\n",
      "Episode: 1495 \tReward: 12.0 \tMean: 12.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000321829895022\n",
      "Episode: 1496 \tReward: 13.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000032057720277\n",
      "Episode: 1497 \tReward: 7.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000031973199512\n",
      "Episode: 1498 \tReward: 12.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000318442883618\n",
      "Episode: 1499 \tReward: 11.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000316981410318\n",
      "Episode: 1500 \tReward: 11.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000315943414535\n",
      "Episode: 1501 \tReward: 5.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000031531846548\n",
      "Episode: 1502 \tReward: 12.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000313745808074\n",
      "Episode: 1503 \tReward: 16.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000311563487493\n",
      "Episode: 1504 \tReward: 16.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000310152195316\n",
      "Episode: 1505 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000307551677376\n",
      "Episode: 1506 \tReward: 17.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000030593820271\n",
      "Episode: 1507 \tReward: 13.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000304722988544\n",
      "Episode: 1508 \tReward: 10.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000303658322338\n",
      "Episode: 1509 \tReward: 10.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000302609480086\n",
      "Episode: 1510 \tReward: 9.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000030172111475\n",
      "Episode: 1511 \tReward: 18.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000299305002772\n",
      "Episode: 1512 \tReward: 9.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000296623343315\n",
      "Episode: 1513 \tReward: 10.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000295681579284\n",
      "Episode: 1514 \tReward: 6.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000295014093457\n",
      "Episode: 1515 \tReward: 15.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000029371300868\n",
      "Episode: 1516 \tReward: 15.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000292470301922\n",
      "Episode: 1517 \tReward: 11.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000291436787453\n",
      "Episode: 1518 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000290523111162\n",
      "Episode: 1519 \tReward: 13.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000289322831776\n",
      "Episode: 1520 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000288536942967\n",
      "Episode: 1521 \tReward: 11.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000287511577685\n",
      "Episode: 1522 \tReward: 12.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000028641537853\n",
      "Episode: 1523 \tReward: 14.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000285277710785\n",
      "Episode: 1524 \tReward: 21.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000028370164201\n",
      "Episode: 1525 \tReward: 4.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000028320843037\n",
      "Episode: 1526 \tReward: 15.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000281970690075\n",
      "Episode: 1527 \tReward: 13.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000028085067703\n",
      "Episode: 1528 \tReward: 11.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000279785469637\n",
      "Episode: 1529 \tReward: 6.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000279226457893\n",
      "Episode: 1530 \tReward: 9.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000278451286328\n",
      "Episode: 1531 \tReward: 7.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000027768382037\n",
      "Episode: 1532 \tReward: 12.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000276652755528\n",
      "Episode: 1533 \tReward: 9.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000027582955749\n",
      "Episode: 1534 \tReward: 7.0 \tMean: 9.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000275129839432\n",
      "Episode: 1535 \tReward: 11.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000027422889192\n",
      "Episode: 1536 \tReward: 9.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000273412906246\n",
      "Episode: 1537 \tReward: 13.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000271962211852\n",
      "Episode: 1538 \tReward: 17.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200002706003826\n",
      "Episode: 1539 \tReward: 17.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000026925075756\n",
      "Episode: 1540 \tReward: 7.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000268578471377\n",
      "Episode: 1541 \tReward: 8.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000267886432034\n",
      "Episode: 1542 \tReward: 11.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000266923774702\n",
      "Episode: 1543 \tReward: 20.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000265496890733\n",
      "Episode: 1544 \tReward: 5.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000026493463353\n",
      "Episode: 1545 \tReward: 17.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000262839381697\n",
      "Episode: 1546 \tReward: 15.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000261701130572\n",
      "Episode: 1547 \tReward: 14.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000260578231673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1548 \tReward: 8.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000259641836562\n",
      "Episode: 1549 \tReward: 6.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000259045346563\n",
      "Episode: 1550 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000257053216005\n",
      "Episode: 1551 \tReward: 8.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000256308841544\n",
      "Episode: 1552 \tReward: 14.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000255173352938\n",
      "Episode: 1553 \tReward: 14.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000253768676503\n",
      "Episode: 1554 \tReward: 11.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000252876981067\n",
      "Episode: 1555 \tReward: 5.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000252356590673\n",
      "Episode: 1556 \tReward: 8.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000251047742355\n",
      "Episode: 1557 \tReward: 11.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000025016560777\n",
      "Episode: 1558 \tReward: 12.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000249231735826\n",
      "Episode: 1559 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000024830135004\n",
      "Episode: 1560 \tReward: 13.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000247369489958\n",
      "Episode: 1561 \tReward: 15.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000246125884247\n",
      "Episode: 1562 \tReward: 6.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000024549169792\n",
      "Episode: 1563 \tReward: 12.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000244545926478\n",
      "Episode: 1564 \tReward: 14.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000024340412544\n",
      "Episode: 1565 \tReward: 10.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000242660447226\n",
      "Episode: 1566 \tReward: 13.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000241677243062\n",
      "Episode: 1567 \tReward: 12.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000240346859918\n",
      "Episode: 1568 \tReward: 9.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000023956460492\n",
      "Episode: 1569 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000023651298934\n",
      "Episode: 1570 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000023571963927\n",
      "Episode: 1571 \tReward: 9.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000023492425185\n",
      "Episode: 1572 \tReward: 16.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000233878822726\n",
      "Episode: 1573 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000233010409756\n",
      "Episode: 1574 \tReward: 7.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000023233565843\n",
      "Episode: 1575 \tReward: 5.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000231838991744\n",
      "Episode: 1576 \tReward: 6.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000231301748727\n",
      "Episode: 1577 \tReward: 8.0 \tMean: 9.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000230618107837\n",
      "Episode: 1578 \tReward: 15.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000229656136067\n",
      "Episode: 1579 \tReward: 12.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000228446747266\n",
      "Episode: 1580 \tReward: 7.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000227853557203\n",
      "Episode: 1581 \tReward: 12.0 \tMean: 9.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200002269485023\n",
      "Episode: 1582 \tReward: 17.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000225852725467\n",
      "Episode: 1583 \tReward: 11.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000224991613826\n",
      "Episode: 1584 \tReward: 9.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200002242413954\n",
      "Episode: 1585 \tReward: 12.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000223386427297\n",
      "Episode: 1586 \tReward: 10.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000022257923034\n",
      "Episode: 1587 \tReward: 16.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000022066442964\n",
      "Episode: 1588 \tReward: 4.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000220232350933\n",
      "Episode: 1589 \tReward: 15.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000218639254004\n",
      "Episode: 1590 \tReward: 12.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000217749023153\n",
      "Episode: 1591 \tReward: 13.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000021691447027\n",
      "Episode: 1592 \tReward: 9.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000021620415636\n",
      "Episode: 1593 \tReward: 9.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000215517719157\n",
      "Episode: 1594 \tReward: 9.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000021485924292\n",
      "Episode: 1595 \tReward: 12.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000021398012345\n",
      "Episode: 1596 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000021014192371\n",
      "Episode: 1597 \tReward: 15.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000209181674347\n",
      "Episode: 1598 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000208442480367\n",
      "Episode: 1599 \tReward: 6.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000207930342052\n",
      "Episode: 1600 \tReward: 15.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020702573923\n",
      "Episode: 1601 \tReward: 6.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020652947321\n",
      "Episode: 1602 \tReward: 12.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020579553547\n",
      "Episode: 1603 \tReward: 10.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000205142145108\n",
      "Episode: 1604 \tReward: 14.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000204241502537\n",
      "Episode: 1605 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200002036296962\n",
      "Episode: 1606 \tReward: 8.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020299942157\n",
      "Episode: 1607 \tReward: 16.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000202043521997\n",
      "Episode: 1608 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020140607217\n",
      "Episode: 1609 \tReward: 14.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000020066224663\n",
      "Episode: 1610 \tReward: 14.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000199825229024\n",
      "Episode: 1611 \tReward: 16.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000198932014292\n",
      "Episode: 1612 \tReward: 12.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000019811410045\n",
      "Episode: 1613 \tReward: 8.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000197595720883\n",
      "Episode: 1614 \tReward: 14.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000195801840436\n",
      "Episode: 1615 \tReward: 16.0 \tMean: 12.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000019486034639\n",
      "Episode: 1616 \tReward: 14.0 \tMean: 13.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000019386133387\n",
      "Episode: 1617 \tReward: 15.0 \tMean: 13.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000192944605512\n",
      "Episode: 1618 \tReward: 4.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000192586062095\n",
      "Episode: 1619 \tReward: 14.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000189806119905\n",
      "Episode: 1620 \tReward: 19.0 \tMean: 13.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000018877260256\n",
      "Episode: 1621 \tReward: 9.0 \tMean: 12.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000187834851937\n",
      "Episode: 1622 \tReward: 16.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000018699523395\n",
      "Episode: 1623 \tReward: 12.0 \tMean: 13.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000186297177952\n",
      "Episode: 1624 \tReward: 4.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000185958425447\n",
      "Episode: 1625 \tReward: 9.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000018493846158\n",
      "Episode: 1626 \tReward: 11.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000018424439862\n",
      "Episode: 1627 \tReward: 14.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200001834685255\n",
      "Episode: 1628 \tReward: 16.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000182597290504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1629 \tReward: 13.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000181875635056\n",
      "Episode: 1630 \tReward: 15.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000181015584474\n",
      "Episode: 1631 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000180249703212\n",
      "Episode: 1632 \tReward: 15.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000017943322437\n",
      "Episode: 1633 \tReward: 13.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000017869548028\n",
      "Episode: 1634 \tReward: 8.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000178213653245\n",
      "Episode: 1635 \tReward: 13.0 \tMean: 13.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000017743123575\n",
      "Episode: 1636 \tReward: 12.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000176804239614\n",
      "Episode: 1637 \tReward: 7.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000176320459077\n",
      "Episode: 1638 \tReward: 2.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000176087869616\n",
      "Episode: 1639 \tReward: 11.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000017547614884\n",
      "Episode: 1640 \tReward: 11.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000174922519407\n",
      "Episode: 1641 \tReward: 12.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000174189385482\n",
      "Episode: 1642 \tReward: 13.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000173455855114\n",
      "Episode: 1643 \tReward: 8.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000172912057936\n",
      "Episode: 1644 \tReward: 12.0 \tMean: 10.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000172266574648\n",
      "Episode: 1645 \tReward: 9.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000171716202674\n",
      "Episode: 1646 \tReward: 12.0 \tMean: 9.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000017020832528\n",
      "Episode: 1647 \tReward: 6.0 \tMean: 9.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016979352323\n",
      "Episode: 1648 \tReward: 17.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016859225875\n",
      "Episode: 1649 \tReward: 12.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016800321727\n",
      "Episode: 1650 \tReward: 13.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016732585347\n",
      "Episode: 1651 \tReward: 14.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000166571247306\n",
      "Episode: 1652 \tReward: 14.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000165883067855\n",
      "Episode: 1653 \tReward: 9.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016533655597\n",
      "Episode: 1654 \tReward: 13.0 \tMean: 11.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000164640305827\n",
      "Episode: 1655 \tReward: 8.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016418324139\n",
      "Episode: 1656 \tReward: 9.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000163462422095\n",
      "Episode: 1657 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016277080868\n",
      "Episode: 1658 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016226700048\n",
      "Episode: 1659 \tReward: 12.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000161648322964\n",
      "Episode: 1660 \tReward: 21.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000016051752548\n",
      "Episode: 1661 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000160017491258\n",
      "Episode: 1662 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000159423332012\n",
      "Episode: 1663 \tReward: 8.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000158958494878\n",
      "Episode: 1664 \tReward: 9.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000158453809737\n",
      "Episode: 1665 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000015796652281\n",
      "Episode: 1666 \tReward: 10.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000157405161804\n",
      "Episode: 1667 \tReward: 6.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000157056109937\n",
      "Episode: 1668 \tReward: 14.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000155627157352\n",
      "Episode: 1669 \tReward: 11.0 \tMean: 11.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000015504309796\n",
      "Episode: 1670 \tReward: 14.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000154408722617\n",
      "Episode: 1671 \tReward: 7.0 \tMean: 10.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000153998541197\n",
      "Episode: 1672 \tReward: 6.0 \tMean: 9.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000015319369937\n",
      "Episode: 1673 \tReward: 12.0 \tMean: 9.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000152667618423\n",
      "Episode: 1674 \tReward: 17.0 \tMean: 10.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000015188795785\n",
      "Episode: 1675 \tReward: 11.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000151351225057\n",
      "Episode: 1676 \tReward: 15.0 \tMean: 11.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000015066263465\n",
      "Episode: 1677 \tReward: 16.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000149917198194\n",
      "Episode: 1678 \tReward: 6.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000014914561784\n",
      "Episode: 1679 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000148502698475\n",
      "Episode: 1680 \tReward: 13.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000147895083874\n",
      "Episode: 1681 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000147334149006\n",
      "Episode: 1682 \tReward: 16.0 \tMean: 13.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000014662277464\n",
      "Episode: 1683 \tReward: 17.0 \tMean: 13.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000014507387996\n",
      "Episode: 1684 \tReward: 7.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000144691390026\n",
      "Episode: 1685 \tReward: 9.0 \tMean: 12.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000014422046412\n",
      "Episode: 1686 \tReward: 11.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000143200125314\n",
      "Episode: 1687 \tReward: 9.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200001427683133\n",
      "Episode: 1688 \tReward: 15.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000142064777\n",
      "Episode: 1689 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000141463697534\n",
      "Episode: 1690 \tReward: 8.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000141031480248\n",
      "Episode: 1691 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000014023549683\n",
      "Episode: 1692 \tReward: 16.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000139474687005\n",
      "Episode: 1693 \tReward: 17.0 \tMean: 11.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000013736246056\n",
      "Episode: 1694 \tReward: 13.0 \tMean: 12.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000136794955516\n",
      "Episode: 1695 \tReward: 16.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000013591139005\n",
      "Episode: 1696 \tReward: 19.0 \tMean: 13.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000134928246486\n",
      "Episode: 1697 \tReward: 14.0 \tMean: 14.0 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000134351987664\n",
      "Episode: 1698 \tReward: 11.0 \tMean: 13.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000013391471333\n",
      "Episode: 1699 \tReward: 13.0 \tMean: 13.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000133201514697\n",
      "Episode: 1700 \tReward: 9.0 \tMean: 13.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000013276267418\n",
      "Episode: 1701 \tReward: 7.0 \tMean: 13.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.0200001324232364\n",
      "Episode: 1702 \tReward: 12.0 \tMean: 13.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000131889325753\n",
      "Episode: 1703 \tReward: 13.0 \tMean: 12.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000013131028754\n",
      "Episode: 1704 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000130869825362\n",
      "Episode: 1705 \tReward: 14.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000130295263097\n",
      "Episode: 1706 \tReward: 11.0 \tMean: 11.6 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000129655784807\n",
      "Episode: 1707 \tReward: 13.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000128924005954\n",
      "Episode: 1708 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000128417044738\n",
      "Episode: 1709 \tReward: 15.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000127876266656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1710 \tReward: 4.0 \tMean: 11.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000127653955417\n",
      "Episode: 1711 \tReward: 13.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000127139273793\n",
      "Episode: 1712 \tReward: 11.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000126401472307\n",
      "Episode: 1713 \tReward: 14.0 \tMean: 11.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000125823877266\n",
      "Episode: 1714 \tReward: 5.0 \tMean: 11.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000125580015564\n",
      "Episode: 1715 \tReward: 11.0 \tMean: 10.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000125136248242\n",
      "Episode: 1716 \tReward: 7.0 \tMean: 10.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000124803828137\n",
      "Episode: 1717 \tReward: 11.0 \tMean: 10.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000124327986948\n",
      "Episode: 1718 \tReward: 12.0 \tMean: 10.3 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000123836621666\n",
      "Episode: 1719 \tReward: 17.0 \tMean: 10.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000012322144834\n",
      "Episode: 1720 \tReward: 14.0 \tMean: 11.5 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000122695187545\n",
      "Episode: 1721 \tReward: 19.0 \tMean: 12.1 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000122061269738\n",
      "Episode: 1722 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000121605613198\n",
      "Episode: 1723 \tReward: 9.0 \tMean: 11.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000121202552013\n",
      "Episode: 1724 \tReward: 12.0 \tMean: 12.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.02000012067767275\n",
      "Episode: 1725 \tReward: 16.0 \tMean: 12.9 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000120147857438\n",
      "Episode: 1726 \tReward: 12.0 \tMean: 13.4 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000119656259686\n",
      "Episode: 1727 \tReward: 15.0 \tMean: 13.8 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000119111869295\n",
      "Episode: 1728 \tReward: 21.0 \tMean: 14.7 \tBestMean: 14.1 \tTRAIN START: True \tEpsi: 0.020000118423020047\n",
      "Episode: 1729 \tReward: 4.0 \tMean: 13.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000118219507524\n",
      "Episode: 1730 \tReward: 10.0 \tMean: 13.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011779232657\n",
      "Episode: 1731 \tReward: 12.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011730802054\n",
      "Episode: 1732 \tReward: 13.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000116853747283\n",
      "Episode: 1733 \tReward: 12.0 \tMean: 12.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011638261048\n",
      "Episode: 1734 \tReward: 16.0 \tMean: 13.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000115806781966\n",
      "Episode: 1735 \tReward: 10.0 \tMean: 12.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000115443718977\n",
      "Episode: 1736 \tReward: 8.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000115118626288\n",
      "Episode: 1737 \tReward: 10.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011474854047\n",
      "Episode: 1738 \tReward: 9.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000114365919676\n",
      "Episode: 1739 \tReward: 7.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000114059829356\n",
      "Episode: 1740 \tReward: 5.0 \tMean: 10.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000113841044585\n",
      "Episode: 1741 \tReward: 17.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011287072414\n",
      "Episode: 1742 \tReward: 9.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000112467369383\n",
      "Episode: 1743 \tReward: 17.0 \tMean: 10.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000111890770233\n",
      "Episode: 1744 \tReward: 11.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011140621653\n",
      "Episode: 1745 \tReward: 11.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000111003655105\n",
      "Episode: 1746 \tReward: 16.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000011043014285\n",
      "Episode: 1747 \tReward: 10.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000108977684252\n",
      "Episode: 1748 \tReward: 16.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000010827595743\n",
      "Episode: 1749 \tReward: 7.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000107984006654\n",
      "Episode: 1750 \tReward: 9.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000107318723336\n",
      "Episode: 1751 \tReward: 15.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000106858243567\n",
      "Episode: 1752 \tReward: 7.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000106574378347\n",
      "Episode: 1753 \tReward: 11.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000106199896013\n",
      "Episode: 1754 \tReward: 14.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000010574633178\n",
      "Episode: 1755 \tReward: 13.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000105324191293\n",
      "Episode: 1756 \tReward: 9.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000105002391872\n",
      "Episode: 1757 \tReward: 17.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000104441084698\n",
      "Episode: 1758 \tReward: 14.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000104007512242\n",
      "Episode: 1759 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000010348256347\n",
      "Episode: 1760 \tReward: 5.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200001032572172\n",
      "Episode: 1761 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000102717564507\n",
      "Episode: 1762 \tReward: 11.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000102225701612\n",
      "Episode: 1763 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000010189706424\n",
      "Episode: 1764 \tReward: 13.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000101510590163\n",
      "Episode: 1765 \tReward: 13.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000101083118074\n",
      "Episode: 1766 \tReward: 14.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000010027767918\n",
      "Episode: 1767 \tReward: 10.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009992732079\n",
      "Episode: 1768 \tReward: 18.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000099428931196\n",
      "Episode: 1769 \tReward: 12.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000099045875297\n",
      "Episode: 1770 \tReward: 8.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000098684029972\n",
      "Episode: 1771 \tReward: 9.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000098406133027\n",
      "Episode: 1772 \tReward: 13.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000098009374242\n",
      "Episode: 1773 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000097536154986\n",
      "Episode: 1774 \tReward: 15.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009686934673\n",
      "Episode: 1775 \tReward: 18.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000096353443107\n",
      "Episode: 1776 \tReward: 13.0 \tMean: 12.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000095953445356\n",
      "Episode: 1777 \tReward: 7.0 \tMean: 12.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000095692806613\n",
      "Episode: 1778 \tReward: 6.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009547296607\n",
      "Episode: 1779 \tReward: 14.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000095095640723\n",
      "Episode: 1780 \tReward: 14.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000094697076604\n",
      "Episode: 1781 \tReward: 7.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000094456851244\n",
      "Episode: 1782 \tReward: 9.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000093492678613\n",
      "Episode: 1783 \tReward: 12.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009316043642\n",
      "Episode: 1784 \tReward: 11.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000092859085057\n",
      "Episode: 1785 \tReward: 10.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000092555006222\n",
      "Episode: 1786 \tReward: 8.0 \tMean: 9.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009227406625\n",
      "Episode: 1787 \tReward: 10.0 \tMean: 10.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009197190313\n",
      "Episode: 1788 \tReward: 14.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000091571778535\n",
      "Episode: 1789 \tReward: 11.0 \tMean: 10.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000091250012515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1790 \tReward: 13.0 \tMean: 10.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000090882106136\n",
      "Episode: 1791 \tReward: 15.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000009047586496\n",
      "Episode: 1792 \tReward: 9.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000090199431973\n",
      "Episode: 1793 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000088337360746\n",
      "Episode: 1794 \tReward: 14.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000087977678566\n",
      "Episode: 1795 \tReward: 11.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000087663281582\n",
      "Episode: 1796 \tReward: 11.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000087355249285\n",
      "Episode: 1797 \tReward: 19.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000086865689735\n",
      "Episode: 1798 \tReward: 13.0 \tMean: 12.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000086517190617\n",
      "Episode: 1799 \tReward: 10.0 \tMean: 12.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000008619766849\n",
      "Episode: 1800 \tReward: 10.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000085913685014\n",
      "Episode: 1801 \tReward: 7.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000008569059957\n",
      "Episode: 1802 \tReward: 12.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000085357057062\n",
      "Episode: 1803 \tReward: 13.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000084994209414\n",
      "Episode: 1804 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000008477012063\n",
      "Episode: 1805 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000083666874093\n",
      "Episode: 1806 \tReward: 14.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000083326208673\n",
      "Episode: 1807 \tReward: 11.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000083031755385\n",
      "Episode: 1808 \tReward: 10.0 \tMean: 10.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000082759857384\n",
      "Episode: 1809 \tReward: 13.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000082310866123\n",
      "Episode: 1810 \tReward: 9.0 \tMean: 10.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000082051174317\n",
      "Episode: 1811 \tReward: 16.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000081288384125\n",
      "Episode: 1812 \tReward: 20.0 \tMean: 12.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000080329998348\n",
      "Episode: 1813 \tReward: 10.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000080044531986\n",
      "Episode: 1814 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007972499336\n",
      "Episode: 1815 \tReward: 16.0 \tMean: 13.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000079332123083\n",
      "Episode: 1816 \tReward: 16.0 \tMean: 13.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000078925402138\n",
      "Episode: 1817 \tReward: 14.0 \tMean: 13.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000078619764897\n",
      "Episode: 1818 \tReward: 14.0 \tMean: 14.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007826364018\n",
      "Episode: 1819 \tReward: 14.0 \tMean: 14.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007787641364\n",
      "Episode: 1820 \tReward: 13.0 \tMean: 14.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007755622286\n",
      "Episode: 1821 \tReward: 14.0 \tMean: 14.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000077007523865\n",
      "Episode: 1822 \tReward: 13.0 \tMean: 13.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000076703177078\n",
      "Episode: 1823 \tReward: 13.0 \tMean: 13.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000076406145362\n",
      "Episode: 1824 \tReward: 8.0 \tMean: 13.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000076197079077\n",
      "Episode: 1825 \tReward: 8.0 \tMean: 12.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007596275312\n",
      "Episode: 1826 \tReward: 8.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000075733691662\n",
      "Episode: 1827 \tReward: 10.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007546908707\n",
      "Episode: 1828 \tReward: 11.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000075200894786\n",
      "Episode: 1829 \tReward: 12.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000074923165592\n",
      "Episode: 1830 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007469275725\n",
      "Episode: 1831 \tReward: 17.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000074242972714\n",
      "Episode: 1832 \tReward: 8.0 \tMean: 10.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000074020577557\n",
      "Episode: 1833 \tReward: 19.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000736072208\n",
      "Episode: 1834 \tReward: 13.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000073311913738\n",
      "Episode: 1835 \tReward: 8.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000073095231323\n",
      "Episode: 1836 \tReward: 8.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000072879189337\n",
      "Episode: 1837 \tReward: 8.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007267541303\n",
      "Episode: 1838 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000072424390617\n",
      "Episode: 1839 \tReward: 7.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007224644558\n",
      "Episode: 1840 \tReward: 11.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000719897055\n",
      "Episode: 1841 \tReward: 6.0 \tMean: 9.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000071815701043\n",
      "Episode: 1842 \tReward: 11.0 \tMean: 10.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000071579099835\n",
      "Episode: 1843 \tReward: 14.0 \tMean: 9.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007108974761\n",
      "Episode: 1844 \tReward: 7.0 \tMean: 9.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007089806418\n",
      "Episode: 1845 \tReward: 13.0 \tMean: 9.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000070606565057\n",
      "Episode: 1846 \tReward: 7.0 \tMean: 9.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007042322643\n",
      "Episode: 1847 \tReward: 9.0 \tMean: 9.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000007019402052\n",
      "Episode: 1848 \tReward: 12.0 \tMean: 9.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000069912406982\n",
      "Episode: 1849 \tReward: 9.0 \tMean: 9.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000069691832465\n",
      "Episode: 1850 \tReward: 16.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000069338695685\n",
      "Episode: 1851 \tReward: 14.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000068977690733\n",
      "Episode: 1852 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000068732566736\n",
      "Episode: 1853 \tReward: 12.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006847050918\n",
      "Episode: 1854 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000068227187535\n",
      "Episode: 1855 \tReward: 13.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000067969775583\n",
      "Episode: 1856 \tReward: 8.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000677322972\n",
      "Episode: 1857 \tReward: 15.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000067405264936\n",
      "Episode: 1858 \tReward: 8.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000067224860675\n",
      "Episode: 1859 \tReward: 13.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006649209907\n",
      "Episode: 1860 \tReward: 17.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000066126073843\n",
      "Episode: 1861 \tReward: 15.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006582654192\n",
      "Episode: 1862 \tReward: 9.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000065643798266\n",
      "Episode: 1863 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000065146796395\n",
      "Episode: 1864 \tReward: 11.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000064920479566\n",
      "Episode: 1865 \tReward: 9.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000064726009976\n",
      "Episode: 1866 \tReward: 6.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006457860278\n",
      "Episode: 1867 \tReward: 15.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006423081819\n",
      "Episode: 1868 \tReward: 12.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006399360328\n",
      "Episode: 1869 \tReward: 12.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000063766191088\n",
      "Episode: 1870 \tReward: 19.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000063351787944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1871 \tReward: 11.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000063114032483\n",
      "Episode: 1872 \tReward: 16.0 \tMean: 12.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006280553017\n",
      "Episode: 1873 \tReward: 10.0 \tMean: 12.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006257858517\n",
      "Episode: 1874 \tReward: 9.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000062396122228\n",
      "Episode: 1875 \tReward: 13.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006214703624\n",
      "Episode: 1876 \tReward: 16.0 \tMean: 13.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000061681443353\n",
      "Episode: 1877 \tReward: 11.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000061447498645\n",
      "Episode: 1878 \tReward: 7.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000061298975483\n",
      "Episode: 1879 \tReward: 8.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000061137359613\n",
      "Episode: 1880 \tReward: 15.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000006086042512\n",
      "Episode: 1881 \tReward: 9.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000606198944\n",
      "Episode: 1882 \tReward: 16.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000060353752805\n",
      "Episode: 1883 \tReward: 12.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005979984863\n",
      "Episode: 1884 \tReward: 15.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000059538498066\n",
      "Episode: 1885 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000059274733126\n",
      "Episode: 1886 \tReward: 13.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000059041650153\n",
      "Episode: 1887 \tReward: 9.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000058840072603\n",
      "Episode: 1888 \tReward: 18.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000058518510888\n",
      "Episode: 1889 \tReward: 12.0 \tMean: 13.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000058303558523\n",
      "Episode: 1890 \tReward: 9.0 \tMean: 12.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005810566304\n",
      "Episode: 1891 \tReward: 6.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000057960580308\n",
      "Episode: 1892 \tReward: 10.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000057783492016\n",
      "Episode: 1893 \tReward: 11.0 \tMean: 11.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000057564331417\n",
      "Episode: 1894 \tReward: 13.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000056952815662\n",
      "Episode: 1895 \tReward: 9.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000056781077614\n",
      "Episode: 1896 \tReward: 9.0 \tMean: 10.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005660419673\n",
      "Episode: 1897 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000056381614967\n",
      "Episode: 1898 \tReward: 15.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000056118365497\n",
      "Episode: 1899 \tReward: 9.0 \tMean: 10.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000055917820937\n",
      "Episode: 1900 \tReward: 11.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005571910741\n",
      "Episode: 1901 \tReward: 10.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000055548867544\n",
      "Episode: 1902 \tReward: 11.0 \tMean: 10.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000055351465162\n",
      "Episode: 1903 \tReward: 13.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000055119476525\n",
      "Episode: 1904 \tReward: 16.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000054864314585\n",
      "Episode: 1905 \tReward: 15.0 \tMean: 11.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000054469620793\n",
      "Episode: 1906 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000054257602977\n",
      "Episode: 1907 \tReward: 12.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000054047491358\n",
      "Episode: 1908 \tReward: 14.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000053063172072\n",
      "Episode: 1909 \tReward: 11.0 \tMean: 12.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005265510156\n",
      "Episode: 1910 \tReward: 16.0 \tMean: 13.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005223658595\n",
      "Episode: 1911 \tReward: 10.0 \tMean: 13.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000052057200814\n",
      "Episode: 1912 \tReward: 9.0 \tMean: 12.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000051892959697\n",
      "Episode: 1913 \tReward: 9.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000051706480903\n",
      "Episode: 1914 \tReward: 8.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000051567061708\n",
      "Episode: 1915 \tReward: 13.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000051345799397\n",
      "Episode: 1916 \tReward: 9.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005118175545\n",
      "Episode: 1917 \tReward: 10.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000510151746\n",
      "Episode: 1918 \tReward: 10.0 \tMean: 10.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005085015291\n",
      "Episode: 1919 \tReward: 8.0 \tMean: 10.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005069174768\n",
      "Episode: 1920 \tReward: 9.0 \tMean: 9.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000050537878764\n",
      "Episode: 1921 \tReward: 14.0 \tMean: 9.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000050328077876\n",
      "Episode: 1922 \tReward: 17.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000005005904104\n",
      "Episode: 1923 \tReward: 13.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004985721049\n",
      "Episode: 1924 \tReward: 13.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000049662152786\n",
      "Episode: 1925 \tReward: 9.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000049503487896\n",
      "Episode: 1926 \tReward: 8.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000049343356148\n",
      "Episode: 1927 \tReward: 8.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004917882426\n",
      "Episode: 1928 \tReward: 13.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004897270635\n",
      "Episode: 1929 \tReward: 10.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000048795745646\n",
      "Episode: 1930 \tReward: 19.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000048535870847\n",
      "Episode: 1931 \tReward: 10.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004834211513\n",
      "Episode: 1932 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004815780052\n",
      "Episode: 1933 \tReward: 10.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000047984744123\n",
      "Episode: 1934 \tReward: 5.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000047890786136\n",
      "Episode: 1935 \tReward: 10.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004773300702\n",
      "Episode: 1936 \tReward: 13.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000047539603886\n",
      "Episode: 1937 \tReward: 11.0 \tMean: 11.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004721931994\n",
      "Episode: 1938 \tReward: 14.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000046901193818\n",
      "Episode: 1939 \tReward: 7.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000467663127\n",
      "Episode: 1940 \tReward: 9.0 \tMean: 10.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000046642079612\n",
      "Episode: 1941 \tReward: 10.0 \tMean: 10.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000046489344215\n",
      "Episode: 1942 \tReward: 14.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004626858077\n",
      "Episode: 1943 \tReward: 13.0 \tMean: 10.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000046074660247\n",
      "Episode: 1944 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045904498998\n",
      "Episode: 1945 \tReward: 11.0 \tMean: 11.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045741369522\n",
      "Episode: 1946 \tReward: 3.0 \tMean: 10.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045676462873\n",
      "Episode: 1947 \tReward: 8.0 \tMean: 10.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004552142661\n",
      "Episode: 1948 \tReward: 15.0 \tMean: 10.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045318853122\n",
      "Episode: 1949 \tReward: 7.0 \tMean: 10.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045191233985\n",
      "Episode: 1950 \tReward: 10.0 \tMean: 10.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000045043249565\n",
      "Episode: 1951 \tReward: 16.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000044821284615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1952 \tReward: 14.0 \tMean: 10.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000446245042\n",
      "Episode: 1953 \tReward: 17.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004439128337\n",
      "Episode: 1954 \tReward: 10.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.0200000442529984\n",
      "Episode: 1955 \tReward: 6.0 \tMean: 10.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004414338694\n",
      "Episode: 1956 \tReward: 15.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000043957494357\n",
      "Episode: 1957 \tReward: 12.0 \tMean: 12.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004374262948\n",
      "Episode: 1958 \tReward: 16.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004352446221\n",
      "Episode: 1959 \tReward: 8.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000043394084486\n",
      "Episode: 1960 \tReward: 25.0 \tMean: 13.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004297433726\n",
      "Episode: 1961 \tReward: 9.0 \tMean: 13.2 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004284389365\n",
      "Episode: 1962 \tReward: 13.0 \tMean: 13.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004267115349\n",
      "Episode: 1963 \tReward: 10.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000042539077736\n",
      "Episode: 1964 \tReward: 10.0 \tMean: 12.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000042384516966\n",
      "Episode: 1965 \tReward: 11.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000042186620864\n",
      "Episode: 1966 \tReward: 12.0 \tMean: 12.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004196194473\n",
      "Episode: 1967 \tReward: 15.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004177771777\n",
      "Episode: 1968 \tReward: 10.0 \tMean: 12.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000041634249326\n",
      "Episode: 1969 \tReward: 14.0 \tMean: 12.9 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004145643553\n",
      "Episode: 1970 \tReward: 11.0 \tMean: 11.5 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000041308286837\n",
      "Episode: 1971 \tReward: 10.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000040948825543\n",
      "Episode: 1972 \tReward: 7.0 \tMean: 11.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004083759608\n",
      "Episode: 1973 \tReward: 8.0 \tMean: 10.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000040712009785\n",
      "Episode: 1974 \tReward: 9.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000040585997973\n",
      "Episode: 1975 \tReward: 11.0 \tMean: 10.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000040440151065\n",
      "Episode: 1976 \tReward: 18.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000004001134863\n",
      "Episode: 1977 \tReward: 13.0 \tMean: 11.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000003985640538\n",
      "Episode: 1978 \tReward: 12.0 \tMean: 11.3 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000039710003355\n",
      "Episode: 1979 \tReward: 17.0 \tMean: 11.6 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000039516690604\n",
      "Episode: 1980 \tReward: 13.0 \tMean: 11.8 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000039355790967\n",
      "Episode: 1981 \tReward: 12.0 \tMean: 12.0 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000039207306888\n",
      "Episode: 1982 \tReward: 14.0 \tMean: 12.7 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000039038296648\n",
      "Episode: 1983 \tReward: 25.0 \tMean: 14.4 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.020000038760555925\n",
      "Episode: 1984 \tReward: 16.0 \tMean: 15.1 \tBestMean: 14.7 \tTRAIN START: True \tEpsi: 0.02000003804855585\n",
      "Episode: 1985 \tReward: 12.0 \tMean: 15.2 \tBestMean: 15.1 \tTRAIN START: True \tEpsi: 0.020000037879994745\n",
      "Episode: 1986 \tReward: 12.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003774840147\n",
      "Episode: 1987 \tReward: 16.0 \tMean: 14.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003757515759\n",
      "Episode: 1988 \tReward: 12.0 \tMean: 14.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000037438632642\n",
      "Episode: 1989 \tReward: 16.0 \tMean: 14.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003726830113\n",
      "Episode: 1990 \tReward: 9.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000037150719175\n",
      "Episode: 1991 \tReward: 8.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000037043879027\n",
      "Episode: 1992 \tReward: 3.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000036986875358\n",
      "Episode: 1993 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000036661352312\n",
      "Episode: 1994 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003653399254\n",
      "Episode: 1995 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000036373596104\n",
      "Episode: 1996 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003621680109\n",
      "Episode: 1997 \tReward: 16.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000036041214458\n",
      "Episode: 1998 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000035898773468\n",
      "Episode: 1999 \tReward: 17.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003568902183\n",
      "Episode: 2000 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003551599398\n",
      "Episode: 2001 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000035403940575\n",
      "Episode: 2002 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003527530449\n",
      "Episode: 2003 \tReward: 9.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000035165417054\n",
      "Episode: 2004 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000035020133172\n",
      "Episode: 2005 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000034886611454\n",
      "Episode: 2006 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003475568409\n",
      "Episode: 2007 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000034643950778\n",
      "Episode: 2008 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000034519456776\n",
      "Episode: 2009 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003438303003\n",
      "Episode: 2010 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000034283463686\n",
      "Episode: 2011 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003415821555\n",
      "Episode: 2012 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000034049764956\n",
      "Episode: 2013 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000033938943458\n",
      "Episode: 2014 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003383321897\n",
      "Episode: 2015 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003370961572\n",
      "Episode: 2016 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000033603933536\n",
      "Episode: 2017 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003348518592\n",
      "Episode: 2018 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003340358166\n",
      "Episode: 2019 \tReward: 14.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000033262250312\n",
      "Episode: 2020 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000331281419\n",
      "Episode: 2021 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000033008434826\n",
      "Episode: 2022 \tReward: 16.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000032853002125\n",
      "Episode: 2023 \tReward: 6.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003277752705\n",
      "Episode: 2024 \tReward: 5.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003270484165\n",
      "Episode: 2025 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000032593834007\n",
      "Episode: 2026 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003247865582\n",
      "Episode: 2027 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000032338650657\n",
      "Episode: 2028 \tReward: 20.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000032015595057\n",
      "Episode: 2029 \tReward: 19.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003185209413\n",
      "Episode: 2030 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003171986465\n",
      "Episode: 2031 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000031608407003\n",
      "Episode: 2032 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000031484744586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2033 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000031368466276\n",
      "Episode: 2034 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000312494923\n",
      "Episode: 2035 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000031140310258\n",
      "Episode: 2036 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000031015377492\n",
      "Episode: 2037 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030902068693\n",
      "Episode: 2038 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030767013618\n",
      "Episode: 2039 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030639901484\n",
      "Episode: 2040 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000003053590272\n",
      "Episode: 2041 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030402447945\n",
      "Episode: 2042 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030289560936\n",
      "Episode: 2043 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000030071056458\n",
      "Episode: 2044 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029958201587\n",
      "Episode: 2045 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029852934094\n",
      "Episode: 2046 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002976886741\n",
      "Episode: 2047 \tReward: 4.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029717708968\n",
      "Episode: 2048 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002960262766\n",
      "Episode: 2049 \tReward: 7.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002952044664\n",
      "Episode: 2050 \tReward: 14.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029384376738\n",
      "Episode: 2051 \tReward: 15.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029240745475\n",
      "Episode: 2052 \tReward: 8.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000029160735497\n",
      "Episode: 2053 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002903677499\n",
      "Episode: 2054 \tReward: 12.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028905824935\n",
      "Episode: 2055 \tReward: 6.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028833650627\n",
      "Episode: 2056 \tReward: 7.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028763382284\n",
      "Episode: 2057 \tReward: 8.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028684678487\n",
      "Episode: 2058 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028490854176\n",
      "Episode: 2059 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002839528555\n",
      "Episode: 2060 \tReward: 19.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028260445165\n",
      "Episode: 2061 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028160580056\n",
      "Episode: 2062 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000028082964014\n",
      "Episode: 2063 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002800332154\n",
      "Episode: 2064 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002791441242\n",
      "Episode: 2065 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027824116084\n",
      "Episode: 2066 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027706945717\n",
      "Episode: 2067 \tReward: 19.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027550567373\n",
      "Episode: 2068 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027435097645\n",
      "Episode: 2069 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027332682017\n",
      "Episode: 2070 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002725353206\n",
      "Episode: 2071 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002715776827\n",
      "Episode: 2072 \tReward: 19.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000027015293447\n",
      "Episode: 2073 \tReward: 8.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002693814009\n",
      "Episode: 2074 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000026831139366\n",
      "Episode: 2075 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000026736325054\n",
      "Episode: 2076 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002664184579\n",
      "Episode: 2077 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000026508438854\n",
      "Episode: 2078 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000026412651785\n",
      "Episode: 2079 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002628302069\n",
      "Episode: 2080 \tReward: 23.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002611691346\n",
      "Episode: 2081 \tReward: 17.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025981977632\n",
      "Episode: 2082 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025884986523\n",
      "Episode: 2083 \tReward: 6.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025826552508\n",
      "Episode: 2084 \tReward: 20.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002569054768\n",
      "Episode: 2085 \tReward: 21.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025538398157\n",
      "Episode: 2086 \tReward: 9.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025441027573\n",
      "Episode: 2087 \tReward: 10.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000025366340796\n",
      "Episode: 2088 \tReward: 9.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002525143863\n",
      "Episode: 2089 \tReward: 13.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002514661084\n",
      "Episode: 2090 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024845164093\n",
      "Episode: 2091 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024755882303\n",
      "Episode: 2092 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002465212564\n",
      "Episode: 2093 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024569924894\n",
      "Episode: 2094 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024488977777\n",
      "Episode: 2095 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002442636617\n",
      "Episode: 2096 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024340049705\n",
      "Episode: 2097 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024240944613\n",
      "Episode: 2098 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024143691626\n",
      "Episode: 2099 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000024070887665\n",
      "Episode: 2100 \tReward: 8.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002400742433\n",
      "Episode: 2101 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002391923937\n",
      "Episode: 2102 \tReward: 10.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002383328492\n",
      "Episode: 2103 \tReward: 9.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002355982968\n",
      "Episode: 2104 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000023478923108\n",
      "Episode: 2105 \tReward: 13.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002337771293\n",
      "Episode: 2106 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000023284854545\n",
      "Episode: 2107 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002319885977\n",
      "Episode: 2108 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000023106249674\n",
      "Episode: 2109 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000023005265617\n",
      "Episode: 2110 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002292809764\n",
      "Episode: 2111 \tReward: 18.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022811005793\n",
      "Episode: 2112 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022717217784\n",
      "Episode: 2113 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022634224738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2114 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022552888023\n",
      "Episode: 2115 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022457915368\n",
      "Episode: 2116 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002237542212\n",
      "Episode: 2117 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000022184705937\n",
      "Episode: 2118 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002211869392\n",
      "Episode: 2119 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021961328905\n",
      "Episode: 2120 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021857041382\n",
      "Episode: 2121 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002176717562\n",
      "Episode: 2122 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002168895467\n",
      "Episode: 2123 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021623552834\n",
      "Episode: 2124 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021532493712\n",
      "Episode: 2125 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021481307313\n",
      "Episode: 2126 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002136433899\n",
      "Episode: 2127 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000021287565645\n",
      "Episode: 2128 \tReward: 18.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002117715761\n",
      "Episode: 2129 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000002102691176\n",
      "Episode: 2130 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020865208978\n",
      "Episode: 2131 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020785240213\n",
      "Episode: 2132 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020709719468\n",
      "Episode: 2133 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020640664393\n",
      "Episode: 2134 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020387523684\n",
      "Episode: 2135 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020305324242\n",
      "Episode: 2136 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020244499553\n",
      "Episode: 2137 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020178206374\n",
      "Episode: 2138 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000020114946178\n",
      "Episode: 2139 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000200354485\n",
      "Episode: 2140 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019933527832\n",
      "Episode: 2141 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019864279715\n",
      "Episode: 2142 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019780233472\n",
      "Episode: 2143 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019723348354\n",
      "Episode: 2144 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019657582264\n",
      "Episode: 2145 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019523973674\n",
      "Episode: 2146 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001947444571\n",
      "Episode: 2147 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001938390591\n",
      "Episode: 2148 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001932274945\n",
      "Episode: 2149 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019249462334\n",
      "Episode: 2150 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019159968522\n",
      "Episode: 2151 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019051067366\n",
      "Episode: 2152 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000019007300262\n",
      "Episode: 2153 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018947710942\n",
      "Episode: 2154 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018873581306\n",
      "Episode: 2155 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001881704541\n",
      "Episode: 2156 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001875580172\n",
      "Episode: 2157 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018682796546\n",
      "Episode: 2158 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001861454249\n",
      "Episode: 2159 \tReward: 19.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001851281379\n",
      "Episode: 2160 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001846585091\n",
      "Episode: 2161 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001839654968\n",
      "Episode: 2162 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018309922568\n",
      "Episode: 2163 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001824667971\n",
      "Episode: 2164 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001819238554\n",
      "Episode: 2165 \tReward: 18.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018102012677\n",
      "Episode: 2166 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000018056091907\n",
      "Episode: 2167 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001797933656\n",
      "Episode: 2168 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017928347685\n",
      "Episode: 2169 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001778691598\n",
      "Episode: 2170 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001771201335\n",
      "Episode: 2171 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017668141978\n",
      "Episode: 2172 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001761169429\n",
      "Episode: 2173 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017567017348\n",
      "Episode: 2174 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017481499138\n",
      "Episode: 2175 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017428087512\n",
      "Episode: 2176 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017363375467\n",
      "Episode: 2177 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017297519844\n",
      "Episode: 2178 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017246739818\n",
      "Episode: 2179 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017167930362\n",
      "Episode: 2180 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017104184302\n",
      "Episode: 2181 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000017035222795\n",
      "Episode: 2182 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016965521367\n",
      "Episode: 2183 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016907260238\n",
      "Episode: 2184 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016851895275\n",
      "Episode: 2185 \tReward: 20.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016752761824\n",
      "Episode: 2186 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016698236745\n",
      "Episode: 2187 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016624925905\n",
      "Episode: 2188 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016558559024\n",
      "Episode: 2189 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001650136541\n",
      "Episode: 2190 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016334560344\n",
      "Episode: 2191 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016282047648\n",
      "Episode: 2192 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016158773126\n",
      "Episode: 2193 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016081396864\n",
      "Episode: 2194 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000016024569363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2195 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001597528962\n",
      "Episode: 2196 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001592138429\n",
      "Episode: 2197 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001586131506\n",
      "Episode: 2198 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001579483724\n",
      "Episode: 2199 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015708204096\n",
      "Episode: 2200 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015632672726\n",
      "Episode: 2201 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015569332744\n",
      "Episode: 2202 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015493539487\n",
      "Episode: 2203 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015421815988\n",
      "Episode: 2204 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015376234907\n",
      "Episode: 2205 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015320367152\n",
      "Episode: 2206 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015256156547\n",
      "Episode: 2207 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015218063792\n",
      "Episode: 2208 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015149433364\n",
      "Episode: 2209 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001508111245\n",
      "Episode: 2210 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000015010097325\n",
      "Episode: 2211 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014922395372\n",
      "Episode: 2212 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001488096872\n",
      "Episode: 2213 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014826010874\n",
      "Episode: 2214 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014760624515\n",
      "Episode: 2215 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001471846944\n",
      "Episode: 2216 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014660299555\n",
      "Episode: 2217 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014591265988\n",
      "Episode: 2218 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001452459079\n",
      "Episode: 2219 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001448948378\n",
      "Episode: 2220 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014441169632\n",
      "Episode: 2221 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001440799311\n",
      "Episode: 2222 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001434904127\n",
      "Episode: 2223 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001431006491\n",
      "Episode: 2224 \tReward: 6.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001427890295\n",
      "Episode: 2225 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014231006346\n",
      "Episode: 2226 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014185823624\n",
      "Episode: 2227 \tReward: 12.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001413456378\n",
      "Episode: 2228 \tReward: 15.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000014069975498\n",
      "Episode: 2229 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001401212645\n",
      "Episode: 2230 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013968197377\n",
      "Episode: 2231 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013896029192\n",
      "Episode: 2232 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013839172107\n",
      "Episode: 2233 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013787786024\n",
      "Episode: 2234 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013751709306\n",
      "Episode: 2235 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001368914427\n",
      "Episode: 2236 \tReward: 22.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013600181384\n",
      "Episode: 2237 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013538847283\n",
      "Episode: 2238 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013502881806\n",
      "Episode: 2239 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001342828267\n",
      "Episode: 2240 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013366654423\n",
      "Episode: 2241 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013288820655\n",
      "Episode: 2242 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001324292079\n",
      "Episode: 2243 \tReward: 16.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013180561486\n",
      "Episode: 2244 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013102238975\n",
      "Episode: 2245 \tReward: 9.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000013065342707\n",
      "Episode: 2246 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012969275404\n",
      "Episode: 2247 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001293378823\n",
      "Episode: 2248 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012887310303\n",
      "Episode: 2249 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012842540407\n",
      "Episode: 2250 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012782833393\n",
      "Episode: 2251 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001272442188\n",
      "Episode: 2252 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012670837963\n",
      "Episode: 2253 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012623032602\n",
      "Episode: 2254 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001255203909\n",
      "Episode: 2255 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012509684816\n",
      "Episode: 2256 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001243037569\n",
      "Episode: 2257 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012385211374\n",
      "Episode: 2258 \tReward: 17.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012320482603\n",
      "Episode: 2259 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012248005773\n",
      "Episode: 2260 \tReward: 6.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012216446646\n",
      "Episode: 2261 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001217425078\n",
      "Episode: 2262 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012129289285\n",
      "Episode: 2263 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000012086669242\n",
      "Episode: 2264 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001205190971\n",
      "Episode: 2265 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001190981833\n",
      "Episode: 2266 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011863697768\n",
      "Episode: 2267 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001182603113\n",
      "Episode: 2268 \tReward: 7.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001179626705\n",
      "Episode: 2269 \tReward: 16.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001174048505\n",
      "Episode: 2270 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011667452522\n",
      "Episode: 2271 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011622735417\n",
      "Episode: 2272 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011574485266\n",
      "Episode: 2273 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001151053991\n",
      "Episode: 2274 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001148134024\n",
      "Episode: 2275 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011441454617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2276 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001141516951\n",
      "Episode: 2277 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001136437122\n",
      "Episode: 2278 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001131447783\n",
      "Episode: 2279 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001127832937\n",
      "Episode: 2280 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000112422964\n",
      "Episode: 2281 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011188015154\n",
      "Episode: 2282 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011145804283\n",
      "Episode: 2283 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011107084298\n",
      "Episode: 2284 \tReward: 6.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001108245392\n",
      "Episode: 2285 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011055224587\n",
      "Episode: 2286 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000011006688457\n",
      "Episode: 2287 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010961872657\n",
      "Episode: 2288 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010925976613\n",
      "Episode: 2289 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010881707077\n",
      "Episode: 2290 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001079089939\n",
      "Episode: 2291 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010759435922\n",
      "Episode: 2292 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010716055488\n",
      "Episode: 2293 \tReward: 4.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010696783938\n",
      "Episode: 2294 \tReward: 13.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001064982148\n",
      "Episode: 2295 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001060985334\n",
      "Episode: 2296 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010574475542\n",
      "Episode: 2297 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001049651324\n",
      "Episode: 2298 \tReward: 8.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001046883899\n",
      "Episode: 2299 \tReward: 8.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010435183544\n",
      "Episode: 2300 \tReward: 13.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001039477348\n",
      "Episode: 2301 \tReward: 12.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010354105726\n",
      "Episode: 2302 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001030864774\n",
      "Episode: 2303 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010276534884\n",
      "Episode: 2304 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001024185883\n",
      "Episode: 2305 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010191796477\n",
      "Episode: 2306 \tReward: 20.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000001004970348\n",
      "Episode: 2307 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000010020200742\n",
      "Episode: 2308 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000998658937\n",
      "Episode: 2309 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000099066191\n",
      "Episode: 2310 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009855435492\n",
      "Episode: 2311 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009819626918\n",
      "Episode: 2312 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009773778433\n",
      "Episode: 2313 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009742747186\n",
      "Episode: 2314 \tReward: 14.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009693185664\n",
      "Episode: 2315 \tReward: 16.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009570477786\n",
      "Episode: 2316 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009535132448\n",
      "Episode: 2317 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000948890413\n",
      "Episode: 2318 \tReward: 6.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009465400804\n",
      "Episode: 2319 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009423656057\n",
      "Episode: 2320 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000938021918\n",
      "Episode: 2321 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009346511104\n",
      "Episode: 2322 \tReward: 7.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009320936717\n",
      "Episode: 2323 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009282427806\n",
      "Episode: 2324 \tReward: 4.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009265178538\n",
      "Episode: 2325 \tReward: 17.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009219705815\n",
      "Episode: 2326 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000091873095\n",
      "Episode: 2327 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009162353973\n",
      "Episode: 2328 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009122857976\n",
      "Episode: 2329 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000090831689\n",
      "Episode: 2330 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009043290756\n",
      "Episode: 2331 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000009014218192\n",
      "Episode: 2332 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008951159973\n",
      "Episode: 2333 \tReward: 17.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000889690203\n",
      "Episode: 2334 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008823716293\n",
      "Episode: 2335 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000879148052\n",
      "Episode: 2336 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008753233104\n",
      "Episode: 2337 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000872945666\n",
      "Episode: 2338 \tReward: 4.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008713583498\n",
      "Episode: 2339 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008672552295\n",
      "Episode: 2340 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008621707317\n",
      "Episode: 2341 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008592958852\n",
      "Episode: 2342 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000855300882\n",
      "Episode: 2343 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000851273374\n",
      "Episode: 2344 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008483500246\n",
      "Episode: 2345 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000084641799\n",
      "Episode: 2346 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000843308896\n",
      "Episode: 2347 \tReward: 17.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008392539275\n",
      "Episode: 2348 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008356695968\n",
      "Episode: 2349 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008332163362\n",
      "Episode: 2350 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000829823739\n",
      "Episode: 2351 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008253217544\n",
      "Episode: 2352 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000823310424\n",
      "Episode: 2353 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000819548284\n",
      "Episode: 2354 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000817224069\n",
      "Episode: 2355 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000813961702\n",
      "Episode: 2356 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000811036708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2357 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000807815197\n",
      "Episode: 2358 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000008049927857\n",
      "Episode: 2359 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000801939618\n",
      "Episode: 2360 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000798514651\n",
      "Episode: 2361 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007961067746\n",
      "Episode: 2362 \tReward: 15.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000792421396\n",
      "Episode: 2363 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007891475526\n",
      "Episode: 2364 \tReward: 6.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007873975885\n",
      "Episode: 2365 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000782969166\n",
      "Episode: 2366 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007804832784\n",
      "Episode: 2367 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007775386207\n",
      "Episode: 2368 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000774682537\n",
      "Episode: 2369 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000770264002\n",
      "Episode: 2370 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007672658224\n",
      "Episode: 2371 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007643710325\n",
      "Episode: 2372 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007616090113\n",
      "Episode: 2373 \tReward: 16.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000754981553\n",
      "Episode: 2374 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000751621833\n",
      "Episode: 2375 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000749985082\n",
      "Episode: 2376 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007475441117\n",
      "Episode: 2377 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000740017116\n",
      "Episode: 2378 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007368271375\n",
      "Episode: 2379 \tReward: 5.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007354579127\n",
      "Episode: 2380 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000732580561\n",
      "Episode: 2381 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007260604788\n",
      "Episode: 2382 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007226560014\n",
      "Episode: 2383 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007195840348\n",
      "Episode: 2384 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007173424313\n",
      "Episode: 2385 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000714621703\n",
      "Episode: 2386 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000007115411958\n",
      "Episode: 2387 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000708403124\n",
      "Episode: 2388 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006958911926\n",
      "Episode: 2389 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006933627534\n",
      "Episode: 2390 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000690981683\n",
      "Episode: 2391 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006889531803\n",
      "Episode: 2392 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006862714956\n",
      "Episode: 2393 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006846811913\n",
      "Episode: 2394 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006824254672\n",
      "Episode: 2395 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000680245196\n",
      "Episode: 2396 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006774077057\n",
      "Episode: 2397 \tReward: 17.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006739212844\n",
      "Episode: 2398 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000671539821\n",
      "Episode: 2399 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006693541655\n",
      "Episode: 2400 \tReward: 7.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006677496417\n",
      "Episode: 2401 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000665496458\n",
      "Episode: 2402 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006627072346\n",
      "Episode: 2403 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006604710654\n",
      "Episode: 2404 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006583741032\n",
      "Episode: 2405 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000656218174\n",
      "Episode: 2406 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000653650834\n",
      "Episode: 2407 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006511456277\n",
      "Episode: 2408 \tReward: 16.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006479498594\n",
      "Episode: 2409 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000645234177\n",
      "Episode: 2410 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000642954086\n",
      "Episode: 2411 \tReward: 6.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006413487082\n",
      "Episode: 2412 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006387628864\n",
      "Episode: 2413 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006365438548\n",
      "Episode: 2414 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000633470426\n",
      "Episode: 2415 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006315349695\n",
      "Episode: 2416 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006290264556\n",
      "Episode: 2417 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000626841248\n",
      "Episode: 2418 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000623914485\n",
      "Episode: 2419 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006218340867\n",
      "Episode: 2420 \tReward: 19.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006184233872\n",
      "Episode: 2421 \tReward: 8.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006165215738\n",
      "Episode: 2422 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006146870742\n",
      "Episode: 2423 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006121352873\n",
      "Episode: 2424 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000610374874\n",
      "Episode: 2425 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006075857488\n",
      "Episode: 2426 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000604084033\n",
      "Episode: 2427 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000006022263164\n",
      "Episode: 2428 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005995703504\n",
      "Episode: 2429 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005928214843\n",
      "Episode: 2430 \tReward: 6.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005915187108\n",
      "Episode: 2431 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005888981896\n",
      "Episode: 2432 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005866763565\n",
      "Episode: 2433 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000584462906\n",
      "Episode: 2434 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005827704188\n",
      "Episode: 2435 \tReward: 6.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005814781032\n",
      "Episode: 2436 \tReward: 6.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005800378244\n",
      "Episode: 2437 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005766833424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2438 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000574932887\n",
      "Episode: 2439 \tReward: 15.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005725003323\n",
      "Episode: 2440 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005672234488\n",
      "Episode: 2441 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000056554695\n",
      "Episode: 2442 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005638528513\n",
      "Episode: 2443 \tReward: 8.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005621525846\n",
      "Episode: 2444 \tReward: 19.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005592257935\n",
      "Episode: 2445 \tReward: 8.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005576733048\n",
      "Episode: 2446 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000055452579\n",
      "Episode: 2447 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000552720979\n",
      "Episode: 2448 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005503383746\n",
      "Episode: 2449 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005483168513\n",
      "Episode: 2450 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005463027534\n",
      "Episode: 2451 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000544089261\n",
      "Episode: 2452 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005412456896\n",
      "Episode: 2453 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000539430156\n",
      "Episode: 2454 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005377820228\n",
      "Episode: 2455 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005350356155\n",
      "Episode: 2456 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005324522997\n",
      "Episode: 2457 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005306981032\n",
      "Episode: 2458 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005287381484\n",
      "Episode: 2459 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005264905148\n",
      "Episode: 2460 \tReward: 18.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005238855874\n",
      "Episode: 2461 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000521669015\n",
      "Episode: 2462 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000051906718\n",
      "Episode: 2463 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005169537\n",
      "Episode: 2464 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005148900154\n",
      "Episode: 2465 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000051250646\n",
      "Episode: 2466 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000051061369\n",
      "Episode: 2467 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005086872136\n",
      "Episode: 2468 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005068085483\n",
      "Episode: 2469 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005046642292\n",
      "Episode: 2470 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000005028507045\n",
      "Episode: 2471 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000498046435\n",
      "Episode: 2472 \tReward: 21.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004948097352\n",
      "Episode: 2473 \tReward: 9.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004933669983\n",
      "Episode: 2474 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004914662726\n",
      "Episode: 2475 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004895434957\n",
      "Episode: 2476 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004876575002\n",
      "Episode: 2477 \tReward: 15.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004852252982\n",
      "Episode: 2478 \tReward: 14.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004830756736\n",
      "Episode: 2479 \tReward: 16.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000480868246\n",
      "Episode: 2480 \tReward: 13.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004789294572\n",
      "Episode: 2481 \tReward: 11.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004771606926\n",
      "Episode: 2482 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004754650205\n",
      "Episode: 2483 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004731787934\n",
      "Episode: 2484 \tReward: 7.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004719406876\n",
      "Episode: 2485 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000466395187\n",
      "Episode: 2486 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004649237044\n",
      "Episode: 2487 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004631696103\n",
      "Episode: 2488 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004618653117\n",
      "Episode: 2489 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000459727221\n",
      "Episode: 2490 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004575624213\n",
      "Episode: 2491 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004560184713\n",
      "Episode: 2492 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004543615814\n",
      "Episode: 2493 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000045276504\n",
      "Episode: 2494 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000451372669\n",
      "Episode: 2495 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004499305852\n",
      "Episode: 2496 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004475880667\n",
      "Episode: 2497 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004462026922\n",
      "Episode: 2498 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004444214462\n",
      "Episode: 2499 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000044316108\n",
      "Episode: 2500 \tReward: 17.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000044108311\n",
      "Episode: 2501 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000439295943\n",
      "Episode: 2502 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000437533518\n",
      "Episode: 2503 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000435778164\n",
      "Episode: 2504 \tReward: 23.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004330933595\n",
      "Episode: 2505 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000431597446\n",
      "Episode: 2506 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004299260923\n",
      "Episode: 2507 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000428209823\n",
      "Episode: 2508 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004232543573\n",
      "Episode: 2509 \tReward: 12.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004216490428\n",
      "Episode: 2510 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000419898626\n",
      "Episode: 2511 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004182642108\n",
      "Episode: 2512 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004148733593\n",
      "Episode: 2513 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004136306045\n",
      "Episode: 2514 \tReward: 15.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004119134752\n",
      "Episode: 2515 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004049215384\n",
      "Episode: 2516 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000040370052\n",
      "Episode: 2517 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004024751338\n",
      "Episode: 2518 \tReward: 8.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000004012695177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2519 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003902366368\n",
      "Episode: 2520 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003889509784\n",
      "Episode: 2521 \tReward: 8.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003877315875\n",
      "Episode: 2522 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003861760353\n",
      "Episode: 2523 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003846651886\n",
      "Episode: 2524 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000383129601\n",
      "Episode: 2525 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003817833557\n",
      "Episode: 2526 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000380586436\n",
      "Episode: 2527 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000379029226\n",
      "Episode: 2528 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003770558484\n",
      "Episode: 2529 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000375437989\n",
      "Episode: 2530 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003741636678\n",
      "Episode: 2531 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000372208178\n",
      "Episode: 2532 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000367841933\n",
      "Episode: 2533 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003667400606\n",
      "Episode: 2534 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000365349093\n",
      "Episode: 2535 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003633815253\n",
      "Episode: 2536 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000362423463\n",
      "Episode: 2537 \tReward: 16.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000036078179\n",
      "Episode: 2538 \tReward: 18.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000359047006\n",
      "Episode: 2539 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003576065344\n",
      "Episode: 2540 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003561219813\n",
      "Episode: 2541 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003549203206\n",
      "Episode: 2542 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003533762366\n",
      "Episode: 2543 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000351684095\n",
      "Episode: 2544 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003503081922\n",
      "Episode: 2545 \tReward: 6.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000349496419\n",
      "Episode: 2546 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003482474587\n",
      "Episode: 2547 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003472945668\n",
      "Episode: 2548 \tReward: 16.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000345659199\n",
      "Episode: 2549 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003443344128\n",
      "Episode: 2550 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003433578904\n",
      "Episode: 2551 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003423225138\n",
      "Episode: 2552 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000341372179\n",
      "Episode: 2553 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000339730724\n",
      "Episode: 2554 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003384218912\n",
      "Episode: 2555 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003367407395\n",
      "Episode: 2556 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003343984732\n",
      "Episode: 2557 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003334968153\n",
      "Episode: 2558 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000033079317\n",
      "Episode: 2559 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003293408772\n",
      "Episode: 2560 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003279408693\n",
      "Episode: 2561 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003266774577\n",
      "Episode: 2562 \tReward: 6.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000325887854\n",
      "Episode: 2563 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000324833686\n",
      "Episode: 2564 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000323174788\n",
      "Episode: 2565 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003216915977\n",
      "Episode: 2566 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003203881775\n",
      "Episode: 2567 \tReward: 16.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003190326077\n",
      "Episode: 2568 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000315959271\n",
      "Episode: 2569 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003144777467\n",
      "Episode: 2570 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000313122133\n",
      "Episode: 2571 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003119407656\n",
      "Episode: 2572 \tReward: 14.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000310521554\n",
      "Episode: 2573 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003092819487\n",
      "Episode: 2574 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003083616602\n",
      "Episode: 2575 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000307548659\n",
      "Episode: 2576 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000003064067035\n",
      "Episode: 2577 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000304311947\n",
      "Episode: 2578 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000302443147\n",
      "Episode: 2579 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000301018979\n",
      "Episode: 2580 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000299961255\n",
      "Episode: 2581 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002989969328\n",
      "Episode: 2582 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002981072483\n",
      "Episode: 2583 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002974342866\n",
      "Episode: 2584 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002963358132\n",
      "Episode: 2585 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002951705474\n",
      "Episode: 2586 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002940039834\n",
      "Episode: 2587 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002929943472\n",
      "Episode: 2588 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002911717548\n",
      "Episode: 2589 \tReward: 21.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002895631232\n",
      "Episode: 2590 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000288165024\n",
      "Episode: 2591 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000287072075\n",
      "Episode: 2592 \tReward: 6.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000286418296\n",
      "Episode: 2593 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002852863224\n",
      "Episode: 2594 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002842213444\n",
      "Episode: 2595 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002832849598\n",
      "Episode: 2596 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002822330974\n",
      "Episode: 2597 \tReward: 18.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000280657009\n",
      "Episode: 2598 \tReward: 20.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000279184629\n",
      "Episode: 2599 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000278020073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2600 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000276943445\n",
      "Episode: 2601 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002759758374\n",
      "Episode: 2602 \tReward: 23.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002742975087\n",
      "Episode: 2603 \tReward: 7.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002735469622\n",
      "Episode: 2604 \tReward: 11.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002725639638\n",
      "Episode: 2605 \tReward: 17.0 \tMean: 14.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000027118285\n",
      "Episode: 2606 \tReward: 12.0 \tMean: 14.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002701164914\n",
      "Episode: 2607 \tReward: 8.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000269226576\n",
      "Episode: 2608 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002681947286\n",
      "Episode: 2609 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002641067337\n",
      "Episode: 2610 \tReward: 8.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002633208672\n",
      "Episode: 2611 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000262274933\n",
      "Episode: 2612 \tReward: 7.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002615520523\n",
      "Episode: 2613 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002605860975\n",
      "Episode: 2614 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000259670447\n",
      "Episode: 2615 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002588770698\n",
      "Episode: 2616 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000257864258\n",
      "Episode: 2617 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000256932477\n",
      "Episode: 2618 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002559528673\n",
      "Episode: 2619 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000255017792\n",
      "Episode: 2620 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000253933727\n",
      "Episode: 2621 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002531882582\n",
      "Episode: 2622 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000252303648\n",
      "Episode: 2623 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002514673893\n",
      "Episode: 2624 \tReward: 6.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000250884661\n",
      "Episode: 2625 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002501431403\n",
      "Episode: 2626 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002489503094\n",
      "Episode: 2627 \tReward: 17.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002477383913\n",
      "Episode: 2628 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002466951383\n",
      "Episode: 2629 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002458332142\n",
      "Episode: 2630 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002449792015\n",
      "Episode: 2631 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002441135086\n",
      "Episode: 2632 \tReward: 7.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002435039868\n",
      "Episode: 2633 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002424300743\n",
      "Episode: 2634 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002413705528\n",
      "Episode: 2635 \tReward: 5.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002408690237\n",
      "Episode: 2636 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000239907472\n",
      "Episode: 2637 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002392749516\n",
      "Episode: 2638 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002383054646\n",
      "Episode: 2639 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002369604655\n",
      "Episode: 2640 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000235972038\n",
      "Episode: 2641 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000234964236\n",
      "Episode: 2642 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000234105839\n",
      "Episode: 2643 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002332459126\n",
      "Episode: 2644 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002325193195\n",
      "Episode: 2645 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002315772047\n",
      "Episode: 2646 \tReward: 16.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002304176003\n",
      "Episode: 2647 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002294931808\n",
      "Episode: 2648 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002288423448\n",
      "Episode: 2649 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002263750906\n",
      "Episode: 2650 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000225579651\n",
      "Episode: 2651 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002243513424\n",
      "Episode: 2652 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002234021066\n",
      "Episode: 2653 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002224924828\n",
      "Episode: 2654 \tReward: 5.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000221959141\n",
      "Episode: 2655 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002211969133\n",
      "Episode: 2656 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002201949557\n",
      "Episode: 2657 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000219232611\n",
      "Episode: 2658 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002184491612\n",
      "Episode: 2659 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002177076953\n",
      "Episode: 2660 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002158218535\n",
      "Episode: 2661 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002145951684\n",
      "Episode: 2662 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002135633084\n",
      "Episode: 2663 \tReward: 7.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000212991725\n",
      "Episode: 2664 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000212069344\n",
      "Episode: 2665 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002112734606\n",
      "Episode: 2666 \tReward: 18.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000021021973\n",
      "Episode: 2667 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002093386583\n",
      "Episode: 2668 \tReward: 20.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002081280086\n",
      "Episode: 2669 \tReward: 15.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000207168675\n",
      "Episode: 2670 \tReward: 19.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000020610656\n",
      "Episode: 2671 \tReward: 16.0 \tMean: 15.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000204717978\n",
      "Episode: 2672 \tReward: 12.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000203908898\n",
      "Episode: 2673 \tReward: 11.0 \tMean: 15.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002032005283\n",
      "Episode: 2674 \tReward: 14.0 \tMean: 15.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002014040955\n",
      "Episode: 2675 \tReward: 8.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002007847253\n",
      "Episode: 2676 \tReward: 10.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000002001112207\n",
      "Episode: 2677 \tReward: 12.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000199352241\n",
      "Episode: 2678 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001986398362\n",
      "Episode: 2679 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001981240433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2680 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001967302134\n",
      "Episode: 2681 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001960428615\n",
      "Episode: 2682 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001952797834\n",
      "Episode: 2683 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001945235657\n",
      "Episode: 2684 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001939292335\n",
      "Episode: 2685 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000193104852\n",
      "Episode: 2686 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000192418621\n",
      "Episode: 2687 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001919266593\n",
      "Episode: 2688 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000191053466\n",
      "Episode: 2689 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001904735453\n",
      "Episode: 2690 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000189773891\n",
      "Episode: 2691 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000188970953\n",
      "Episode: 2692 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000188401122\n",
      "Episode: 2693 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001876940635\n",
      "Episode: 2694 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001870158393\n",
      "Episode: 2695 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000186224571\n",
      "Episode: 2696 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001854663225\n",
      "Episode: 2697 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001850143362\n",
      "Episode: 2698 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001842683864\n",
      "Episode: 2699 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001835841812\n",
      "Episode: 2700 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001828732548\n",
      "Episode: 2701 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001812565293\n",
      "Episode: 2702 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001806087908\n",
      "Episode: 2703 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001797942812\n",
      "Episode: 2704 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000179119524\n",
      "Episode: 2705 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001783759346\n",
      "Episode: 2706 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000177766931\n",
      "Episode: 2707 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000017715292\n",
      "Episode: 2708 \tReward: 18.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001762270667\n",
      "Episode: 2709 \tReward: 19.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000175281511\n",
      "Episode: 2710 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001746621116\n",
      "Episode: 2711 \tReward: 11.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001739857356\n",
      "Episode: 2712 \tReward: 6.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001735964435\n",
      "Episode: 2713 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001729484056\n",
      "Episode: 2714 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000172437235\n",
      "Episode: 2715 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001720582902\n",
      "Episode: 2716 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001712652142\n",
      "Episode: 2717 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001707009708\n",
      "Episode: 2718 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001698394054\n",
      "Episode: 2719 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001678974397\n",
      "Episode: 2720 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000016724726\n",
      "Episode: 2721 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001666129263\n",
      "Episode: 2722 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000166010878\n",
      "Episode: 2723 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001652555915\n",
      "Episode: 2724 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001645695563\n",
      "Episode: 2725 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000016398801\n",
      "Episode: 2726 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000162323834\n",
      "Episode: 2727 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001617114082\n",
      "Episode: 2728 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000161101293\n",
      "Episode: 2729 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000015983041\n",
      "Episode: 2730 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000159214654\n",
      "Episode: 2731 \tReward: 5.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000158107205\n",
      "Episode: 2732 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001575075376\n",
      "Episode: 2733 \tReward: 18.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000155884183\n",
      "Episode: 2734 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001551315268\n",
      "Episode: 2735 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001542281987\n",
      "Episode: 2736 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001536739753\n",
      "Episode: 2737 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001532810733\n",
      "Episode: 2738 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001527608027\n",
      "Episode: 2739 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000151846982\n",
      "Episode: 2740 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001512014896\n",
      "Episode: 2741 \tReward: 14.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001505226114\n",
      "Episode: 2742 \tReward: 11.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000149978705\n",
      "Episode: 2743 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001495593518\n",
      "Episode: 2744 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000149036809\n",
      "Episode: 2745 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001483617157\n",
      "Episode: 2746 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001476276633\n",
      "Episode: 2747 \tReward: 19.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000014681794\n",
      "Episode: 2748 \tReward: 14.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000146205522\n",
      "Episode: 2749 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000145284417\n",
      "Episode: 2750 \tReward: 8.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001448434227\n",
      "Episode: 2751 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001443893276\n",
      "Episode: 2752 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001438186765\n",
      "Episode: 2753 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001419980488\n",
      "Episode: 2754 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001415981784\n",
      "Episode: 2755 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001411881383\n",
      "Episode: 2756 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000014064139\n",
      "Episode: 2757 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000140001525\n",
      "Episode: 2758 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000138553054\n",
      "Episode: 2759 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000137955796\n",
      "Episode: 2760 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001373254032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2761 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001369496468\n",
      "Episode: 2762 \tReward: 18.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001362257335\n",
      "Episode: 2763 \tReward: 6.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000135937241\n",
      "Episode: 2764 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001354243683\n",
      "Episode: 2765 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001330723965\n",
      "Episode: 2766 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001322366758\n",
      "Episode: 2767 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000131901221\n",
      "Episode: 2768 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001314666643\n",
      "Episode: 2769 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001310676124\n",
      "Episode: 2770 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001306070655\n",
      "Episode: 2771 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001301949986\n",
      "Episode: 2772 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001296233992\n",
      "Episode: 2773 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001291885953\n",
      "Episode: 2774 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001287372254\n",
      "Episode: 2775 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001282258695\n",
      "Episode: 2776 \tReward: 17.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001276220696\n",
      "Episode: 2777 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001271380262\n",
      "Episode: 2778 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001266203597\n",
      "Episode: 2779 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001262107735\n",
      "Episode: 2780 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001259107492\n",
      "Episode: 2781 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001253704953\n",
      "Episode: 2782 \tReward: 5.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000125112498\n",
      "Episode: 2783 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000124500946\n",
      "Episode: 2784 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001240461057\n",
      "Episode: 2785 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001235657393\n",
      "Episode: 2786 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001231414034\n",
      "Episode: 2787 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001227037992\n",
      "Episode: 2788 \tReward: 13.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000122218853\n",
      "Episode: 2789 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000121696874\n",
      "Episode: 2790 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000121189243\n",
      "Episode: 2791 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000120625815\n",
      "Episode: 2792 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001201010312\n",
      "Episode: 2793 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001196000566\n",
      "Episode: 2794 \tReward: 14.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001190630657\n",
      "Episode: 2795 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000011860674\n",
      "Episode: 2796 \tReward: 8.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001182751057\n",
      "Episode: 2797 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001177181627\n",
      "Episode: 2798 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001170420553\n",
      "Episode: 2799 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001167124616\n",
      "Episode: 2800 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001162744467\n",
      "Episode: 2801 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001159655677\n",
      "Episode: 2802 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000115680643\n",
      "Episode: 2803 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001151290088\n",
      "Episode: 2804 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001146739995\n",
      "Episode: 2805 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001140404622\n",
      "Episode: 2806 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000113671569\n",
      "Episode: 2807 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000113278945\n",
      "Episode: 2808 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001128786464\n",
      "Episode: 2809 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001123336338\n",
      "Episode: 2810 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000011179796\n",
      "Episode: 2811 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000111304904\n",
      "Episode: 2812 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001108317535\n",
      "Episode: 2813 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001104047673\n",
      "Episode: 2814 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001100300285\n",
      "Episode: 2815 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001094900105\n",
      "Episode: 2816 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000109199154\n",
      "Episode: 2817 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001086697337\n",
      "Episode: 2818 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001082770603\n",
      "Episode: 2819 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001078944372\n",
      "Episode: 2820 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001076185808\n",
      "Episode: 2821 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001072554438\n",
      "Episode: 2822 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001069042223\n",
      "Episode: 2823 \tReward: 16.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001064135922\n",
      "Episode: 2824 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001059718314\n",
      "Episode: 2825 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001055297936\n",
      "Episode: 2826 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001051547752\n",
      "Episode: 2827 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001045320074\n",
      "Episode: 2828 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001041230443\n",
      "Episode: 2829 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001037758532\n",
      "Episode: 2830 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001034318888\n",
      "Episode: 2831 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000103041654\n",
      "Episode: 2832 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001021490802\n",
      "Episode: 2833 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001017107822\n",
      "Episode: 2834 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001012055214\n",
      "Episode: 2835 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001008176376\n",
      "Episode: 2836 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001004071396\n",
      "Episode: 2837 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000001001143783\n",
      "Episode: 2838 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000993623545\n",
      "Episode: 2839 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000990052932\n",
      "Episode: 2840 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000098564713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2841 \tReward: 17.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000098071158\n",
      "Episode: 2842 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000976991946\n",
      "Episode: 2843 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000974260194\n",
      "Episode: 2844 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000965396027\n",
      "Episode: 2845 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000961830664\n",
      "Episode: 2846 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000095942909\n",
      "Episode: 2847 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000095590488\n",
      "Episode: 2848 \tReward: 16.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000009504337\n",
      "Episode: 2849 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000094737823\n",
      "Episode: 2850 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000094329438\n",
      "Episode: 2851 \tReward: 19.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000093441289\n",
      "Episode: 2852 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000093142755\n",
      "Episode: 2853 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000921551266\n",
      "Episode: 2854 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000918331474\n",
      "Episode: 2855 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000914427704\n",
      "Episode: 2856 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000009116156\n",
      "Episode: 2857 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000907885628\n",
      "Episode: 2858 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000090440603\n",
      "Episode: 2859 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000901877237\n",
      "Episode: 2860 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000008995354\n",
      "Episode: 2861 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000089524588\n",
      "Episode: 2862 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000892314285\n",
      "Episode: 2863 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000884372548\n",
      "Episode: 2864 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000880260962\n",
      "Episode: 2865 \tReward: 8.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000877273154\n",
      "Episode: 2866 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000873159646\n",
      "Episode: 2867 \tReward: 17.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000086922187\n",
      "Episode: 2868 \tReward: 7.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000867016848\n",
      "Episode: 2869 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000861864795\n",
      "Episode: 2870 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000085660629\n",
      "Episode: 2871 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000849457925\n",
      "Episode: 2872 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000084606688\n",
      "Episode: 2873 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000843667456\n",
      "Episode: 2874 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000084033314\n",
      "Episode: 2875 \tReward: 4.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000008388219\n",
      "Episode: 2876 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000835139194\n",
      "Episode: 2877 \tReward: 8.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000832804073\n",
      "Episode: 2878 \tReward: 14.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000008244186\n",
      "Episode: 2879 \tReward: 8.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000082208057\n",
      "Episode: 2880 \tReward: 13.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000818356786\n",
      "Episode: 2881 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000808142505\n",
      "Episode: 2882 \tReward: 19.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000803790295\n",
      "Episode: 2883 \tReward: 6.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000801847474\n",
      "Episode: 2884 \tReward: 20.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000795442376\n",
      "Episode: 2885 \tReward: 19.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000791111097\n",
      "Episode: 2886 \tReward: 7.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000788583588\n",
      "Episode: 2887 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000785844085\n",
      "Episode: 2888 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000782957494\n",
      "Episode: 2889 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000778351647\n",
      "Episode: 2890 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000077588042\n",
      "Episode: 2891 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000773494384\n",
      "Episode: 2892 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000077006768\n",
      "Episode: 2893 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000766932206\n",
      "Episode: 2894 \tReward: 19.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000759027803\n",
      "Episode: 2895 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000075310029\n",
      "Episode: 2896 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000749718954\n",
      "Episode: 2897 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000074741337\n",
      "Episode: 2898 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000074463816\n",
      "Episode: 2899 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000074153207\n",
      "Episode: 2900 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000738350326\n",
      "Episode: 2901 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000073619749\n",
      "Episode: 2902 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000007335226\n",
      "Episode: 2903 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000731559393\n",
      "Episode: 2904 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000072970359\n",
      "Episode: 2905 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000726892363\n",
      "Episode: 2906 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000072341164\n",
      "Episode: 2907 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000721158113\n",
      "Episode: 2908 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000071912731\n",
      "Episode: 2909 \tReward: 11.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000716442798\n",
      "Episode: 2910 \tReward: 15.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000712955074\n",
      "Episode: 2911 \tReward: 16.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000709399196\n",
      "Episode: 2912 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000706835813\n",
      "Episode: 2913 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000704521192\n",
      "Episode: 2914 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000070257939\n",
      "Episode: 2915 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000699145173\n",
      "Episode: 2916 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000696507394\n",
      "Episode: 2917 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000693976717\n",
      "Episode: 2918 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000688860244\n",
      "Episode: 2919 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000686508364\n",
      "Episode: 2920 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000681651416\n",
      "Episode: 2921 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000067992222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2922 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000066919695\n",
      "Episode: 2923 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000666472187\n",
      "Episode: 2924 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000066387801\n",
      "Episode: 2925 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000661862884\n",
      "Episode: 2926 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000659431704\n",
      "Episode: 2927 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000652087273\n",
      "Episode: 2928 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000649730985\n",
      "Episode: 2929 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000646891388\n",
      "Episode: 2930 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000644089962\n",
      "Episode: 2931 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000641570072\n",
      "Episode: 2932 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000639149515\n",
      "Episode: 2933 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000634767257\n",
      "Episode: 2934 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000630755563\n",
      "Episode: 2935 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000062902966\n",
      "Episode: 2936 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000062645592\n",
      "Episode: 2937 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000624766767\n",
      "Episode: 2938 \tReward: 19.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000621601\n",
      "Episode: 2939 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000614997626\n",
      "Episode: 2940 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000612910185\n",
      "Episode: 2941 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000610695463\n",
      "Episode: 2942 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000060913408\n",
      "Episode: 2943 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000060704226\n",
      "Episode: 2944 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000604715688\n",
      "Episode: 2945 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000601747794\n",
      "Episode: 2946 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000599441514\n",
      "Episode: 2947 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000597156013\n",
      "Episode: 2948 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000594451072\n",
      "Episode: 2949 \tReward: 7.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000592895646\n",
      "Episode: 2950 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000005907178\n",
      "Episode: 2951 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000588936525\n",
      "Episode: 2952 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000586597216\n",
      "Episode: 2953 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000584465882\n",
      "Episode: 2954 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000581899883\n",
      "Episode: 2955 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000578974483\n",
      "Episode: 2956 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000057630579\n",
      "Episode: 2957 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000574016654\n",
      "Episode: 2958 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000571496528\n",
      "Episode: 2959 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000561077143\n",
      "Episode: 2960 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000055590555\n",
      "Episode: 2961 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000055345387\n",
      "Episode: 2962 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000055156429\n",
      "Episode: 2963 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000549527275\n",
      "Episode: 2964 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000547180326\n",
      "Episode: 2965 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000544974177\n",
      "Episode: 2966 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000543135273\n",
      "Episode: 2967 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000540783172\n",
      "Episode: 2968 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000538915298\n",
      "Episode: 2969 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000536527816\n",
      "Episode: 2970 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000053448219\n",
      "Episode: 2971 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000531295525\n",
      "Episode: 2972 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000052971462\n",
      "Episode: 2973 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000527483935\n",
      "Episode: 2974 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000525693534\n",
      "Episode: 2975 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000052275788\n",
      "Episode: 2976 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000521296205\n",
      "Episode: 2977 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000519516416\n",
      "Episode: 2978 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000517183845\n",
      "Episode: 2979 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000514624965\n",
      "Episode: 2980 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000512242634\n",
      "Episode: 2981 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000510738854\n",
      "Episode: 2982 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000508669458\n",
      "Episode: 2983 \tReward: 5.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000507622677\n",
      "Episode: 2984 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000505960402\n",
      "Episode: 2985 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000503839824\n",
      "Episode: 2986 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000499485422\n",
      "Episode: 2987 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000049798921\n",
      "Episode: 2988 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000495961553\n",
      "Episode: 2989 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000049422872\n",
      "Episode: 2990 \tReward: 15.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000491272228\n",
      "Episode: 2991 \tReward: 7.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000489947583\n",
      "Episode: 2992 \tReward: 15.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000487513707\n",
      "Episode: 2993 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000485606396\n",
      "Episode: 2994 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000004835131\n",
      "Episode: 2995 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000481322926\n",
      "Episode: 2996 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000047985233\n",
      "Episode: 2997 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000478156654\n",
      "Episode: 2998 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000475657666\n",
      "Episode: 2999 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000047388203\n",
      "Episode: 3000 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000471763788\n",
      "Episode: 3001 \tReward: 7.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000470538796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3002 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000468744766\n",
      "Episode: 3003 \tReward: 18.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000466239013\n",
      "Episode: 3004 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000046445209\n",
      "Episode: 3005 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000460778943\n",
      "Episode: 3006 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000045938949\n",
      "Episode: 3007 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000457564754\n",
      "Episode: 3008 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000456285364\n",
      "Episode: 3009 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000454636596\n",
      "Episode: 3010 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000453066272\n",
      "Episode: 3011 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000045123055\n",
      "Episode: 3012 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000449276453\n",
      "Episode: 3013 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000448181555\n",
      "Episode: 3014 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000446839025\n",
      "Episode: 3015 \tReward: 23.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000044421932\n",
      "Episode: 3016 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000044259645\n",
      "Episode: 3017 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000044097069\n",
      "Episode: 3018 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000438166254\n",
      "Episode: 3019 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000042992828\n",
      "Episode: 3020 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000004271001\n",
      "Episode: 3021 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000425590837\n",
      "Episode: 3022 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000424511208\n",
      "Episode: 3023 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000423519012\n",
      "Episode: 3024 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000422123704\n",
      "Episode: 3025 \tReward: 7.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000042101919\n",
      "Episode: 3026 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000419011517\n",
      "Episode: 3027 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000417438994\n",
      "Episode: 3028 \tReward: 9.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000041575594\n",
      "Episode: 3029 \tReward: 15.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000413988587\n",
      "Episode: 3030 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000041247616\n",
      "Episode: 3031 \tReward: 7.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000041141334\n",
      "Episode: 3032 \tReward: 7.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000410279408\n",
      "Episode: 3033 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000406847494\n",
      "Episode: 3034 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000405118012\n",
      "Episode: 3035 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000400237614\n",
      "Episode: 3036 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000039901476\n",
      "Episode: 3037 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000397604745\n",
      "Episode: 3038 \tReward: 21.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000395202548\n",
      "Episode: 3039 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000392979878\n",
      "Episode: 3040 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000390980783\n",
      "Episode: 3041 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000389871972\n",
      "Episode: 3042 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000388657468\n",
      "Episode: 3043 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000387299544\n",
      "Episode: 3044 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000385529768\n",
      "Episode: 3045 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000038397537\n",
      "Episode: 3046 \tReward: 18.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000038198388\n",
      "Episode: 3047 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000380694955\n",
      "Episode: 3048 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000379137302\n",
      "Episode: 3049 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000037764644\n",
      "Episode: 3050 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000037640226\n",
      "Episode: 3051 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000374712255\n",
      "Episode: 3052 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000373268653\n",
      "Episode: 3053 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000371756255\n",
      "Episode: 3054 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000370361076\n",
      "Episode: 3055 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000369022792\n",
      "Episode: 3056 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000367329185\n",
      "Episode: 3057 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000366140965\n",
      "Episode: 3058 \tReward: 7.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000365153717\n",
      "Episode: 3059 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000364001652\n",
      "Episode: 3060 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000362229653\n",
      "Episode: 3061 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000036081249\n",
      "Episode: 3062 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000035942244\n",
      "Episode: 3063 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000357901716\n",
      "Episode: 3064 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000356337533\n",
      "Episode: 3065 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000354858247\n",
      "Episode: 3066 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000353568914\n",
      "Episode: 3067 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000352157463\n",
      "Episode: 3068 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000350471156\n",
      "Episode: 3069 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000349316507\n",
      "Episode: 3070 \tReward: 20.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000346706435\n",
      "Episode: 3071 \tReward: 8.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000345695528\n",
      "Episode: 3072 \tReward: 6.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000034487375\n",
      "Episode: 3073 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000342989013\n",
      "Episode: 3074 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000033917575\n",
      "Episode: 3075 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000337531354\n",
      "Episode: 3076 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000033590165\n",
      "Episode: 3077 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000333285143\n",
      "Episode: 3078 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000033170911\n",
      "Episode: 3079 \tReward: 21.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000032980396\n",
      "Episode: 3080 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000327117164\n",
      "Episode: 3081 \tReward: 9.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000032615033\n",
      "Episode: 3082 \tReward: 11.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000324913312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3083 \tReward: 17.0 \tMean: 14.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000032342214\n",
      "Episode: 3084 \tReward: 8.0 \tMean: 14.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000322459778\n",
      "Episode: 3085 \tReward: 14.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000320537222\n",
      "Episode: 3086 \tReward: 15.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000031881099\n",
      "Episode: 3087 \tReward: 13.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000317493837\n",
      "Episode: 3088 \tReward: 9.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000316580772\n",
      "Episode: 3089 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000031529806\n",
      "Episode: 3090 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000314045665\n",
      "Episode: 3091 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000312391877\n",
      "Episode: 3092 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000031123816\n",
      "Episode: 3093 \tReward: 16.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000309791165\n",
      "Episode: 3094 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000308560646\n",
      "Episode: 3095 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000307611742\n",
      "Episode: 3096 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000030585111\n",
      "Episode: 3097 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000304916634\n",
      "Episode: 3098 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000303997175\n",
      "Episode: 3099 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000030276545\n",
      "Episode: 3100 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000301725725\n",
      "Episode: 3101 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000300196843\n",
      "Episode: 3102 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000029905228\n",
      "Episode: 3103 \tReward: 19.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000296621943\n",
      "Episode: 3104 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000295626968\n",
      "Episode: 3105 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000293940806\n",
      "Episode: 3106 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000291528687\n",
      "Episode: 3107 \tReward: 17.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000289854308\n",
      "Episode: 3108 \tReward: 9.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000028891092\n",
      "Episode: 3109 \tReward: 10.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000287913017\n",
      "Episode: 3110 \tReward: 12.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000286752195\n",
      "Episode: 3111 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000028583034\n",
      "Episode: 3112 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000284746244\n",
      "Episode: 3113 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000284001184\n",
      "Episode: 3114 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000028239828\n",
      "Episode: 3115 \tReward: 19.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000027956041\n",
      "Episode: 3116 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000278622664\n",
      "Episode: 3117 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000027681749\n",
      "Episode: 3118 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000027589998\n",
      "Episode: 3119 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000027466122\n",
      "Episode: 3120 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000272805317\n",
      "Episode: 3121 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000271982687\n",
      "Episode: 3122 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000270658645\n",
      "Episode: 3123 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000269561998\n",
      "Episode: 3124 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000268609434\n",
      "Episode: 3125 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000026419789\n",
      "Episode: 3126 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000026229725\n",
      "Episode: 3127 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000261600467\n",
      "Episode: 3128 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000026069168\n",
      "Episode: 3129 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000259682158\n",
      "Episode: 3130 \tReward: 5.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000259116666\n",
      "Episode: 3131 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000258319814\n",
      "Episode: 3132 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000257376093\n",
      "Episode: 3133 \tReward: 19.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000255805762\n",
      "Episode: 3134 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000254886515\n",
      "Episode: 3135 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000254194166\n",
      "Episode: 3136 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000253098418\n",
      "Episode: 3137 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000250354623\n",
      "Episode: 3138 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000024944\n",
      "Episode: 3139 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000248503867\n",
      "Episode: 3140 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000247348534\n",
      "Episode: 3141 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000246075504\n",
      "Episode: 3142 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000245240266\n",
      "Episode: 3143 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000244305236\n",
      "Episode: 3144 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000243329968\n",
      "Episode: 3145 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000242416764\n",
      "Episode: 3146 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000241087133\n",
      "Episode: 3147 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000024008149\n",
      "Episode: 3148 \tReward: 18.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000023884586\n",
      "Episode: 3149 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000238254257\n",
      "Episode: 3150 \tReward: 5.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000237749692\n",
      "Episode: 3151 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000236497683\n",
      "Episode: 3152 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000235506476\n",
      "Episode: 3153 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000234444388\n",
      "Episode: 3154 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000023370939\n",
      "Episode: 3155 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000232692633\n",
      "Episode: 3156 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000231198908\n",
      "Episode: 3157 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000230239116\n",
      "Episode: 3158 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000022897628\n",
      "Episode: 3159 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000227866153\n",
      "Episode: 3160 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000226938354\n",
      "Episode: 3161 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000226181643\n",
      "Episode: 3162 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000225224662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3163 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000022407446\n",
      "Episode: 3164 \tReward: 14.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000222062397\n",
      "Episode: 3165 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000022122016\n",
      "Episode: 3166 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000220099214\n",
      "Episode: 3167 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000219448682\n",
      "Episode: 3168 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000218808826\n",
      "Episode: 3169 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000218223204\n",
      "Episode: 3170 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000217434664\n",
      "Episode: 3171 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000216532015\n",
      "Episode: 3172 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000021570644\n",
      "Episode: 3173 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000021498718\n",
      "Episode: 3174 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000214317467\n",
      "Episode: 3175 \tReward: 14.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000213159008\n",
      "Episode: 3176 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000212584256\n",
      "Episode: 3177 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000211739852\n",
      "Episode: 3178 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000210940987\n",
      "Episode: 3179 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000021035959\n",
      "Episode: 3180 \tReward: 19.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000209143037\n",
      "Episode: 3181 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000208416486\n",
      "Episode: 3182 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000207788016\n",
      "Episode: 3183 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020706203\n",
      "Episode: 3184 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020604579\n",
      "Episode: 3185 \tReward: 6.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020558065\n",
      "Episode: 3186 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020487057\n",
      "Episode: 3187 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000203583942\n",
      "Episode: 3188 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000202775287\n",
      "Episode: 3189 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020192138\n",
      "Episode: 3190 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000020117565\n",
      "Episode: 3191 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000200565006\n",
      "Episode: 3192 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000199952215\n",
      "Episode: 3193 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000019924962\n",
      "Episode: 3194 \tReward: 19.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000019822414\n",
      "Episode: 3195 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000197499965\n",
      "Episode: 3196 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000019699501\n",
      "Episode: 3197 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000196102683\n",
      "Episode: 3198 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000195362813\n",
      "Episode: 3199 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000194656878\n",
      "Episode: 3200 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000193949614\n",
      "Episode: 3201 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000193237194\n",
      "Episode: 3202 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000192627525\n",
      "Episode: 3203 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000192015945\n",
      "Episode: 3204 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000019144076\n",
      "Episode: 3205 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000190962756\n",
      "Episode: 3206 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018988496\n",
      "Episode: 3207 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018942978\n",
      "Episode: 3208 \tReward: 10.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000187421187\n",
      "Episode: 3209 \tReward: 9.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000186856028\n",
      "Episode: 3210 \tReward: 13.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018613243\n",
      "Episode: 3211 \tReward: 10.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000185541468\n",
      "Episode: 3212 \tReward: 9.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018500418\n",
      "Episode: 3213 \tReward: 16.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000001841367\n",
      "Episode: 3214 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000183467658\n",
      "Episode: 3215 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018276815\n",
      "Episode: 3216 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000182005775\n",
      "Episode: 3217 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000181569482\n",
      "Episode: 3218 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018103283\n",
      "Episode: 3219 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000180515818\n",
      "Episode: 3220 \tReward: 5.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000018011912\n",
      "Episode: 3221 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000179511344\n",
      "Episode: 3222 \tReward: 15.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000177753614\n",
      "Episode: 3223 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000017713965\n",
      "Episode: 3224 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000176524278\n",
      "Episode: 3225 \tReward: 10.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000175847722\n",
      "Episode: 3226 \tReward: 11.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000017503018\n",
      "Episode: 3227 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000001742025\n",
      "Episode: 3228 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000017348973\n",
      "Episode: 3229 \tReward: 4.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000173191586\n",
      "Episode: 3230 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000017236915\n",
      "Episode: 3231 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000171533472\n",
      "Episode: 3232 \tReward: 19.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000170551688\n",
      "Episode: 3233 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016974858\n",
      "Episode: 3234 \tReward: 17.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000168993188\n",
      "Episode: 3235 \tReward: 15.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016819742\n",
      "Episode: 3236 \tReward: 16.0 \tMean: 14.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000167412095\n",
      "Episode: 3237 \tReward: 8.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016693732\n",
      "Episode: 3238 \tReward: 11.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016636404\n",
      "Episode: 3239 \tReward: 8.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000001656204\n",
      "Episode: 3240 \tReward: 12.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000165002134\n",
      "Episode: 3241 \tReward: 10.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016448484\n",
      "Episode: 3242 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000163746322\n",
      "Episode: 3243 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000161350402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3244 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000016076737\n",
      "Episode: 3245 \tReward: 18.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000015993355\n",
      "Episode: 3246 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000015901498\n",
      "Episode: 3247 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000156691424\n",
      "Episode: 3248 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000156109615\n",
      "Episode: 3249 \tReward: 11.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000155589077\n",
      "Episode: 3250 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000154281432\n",
      "Episode: 3251 \tReward: 12.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000153662465\n",
      "Episode: 3252 \tReward: 15.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000152981715\n",
      "Episode: 3253 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000152477708\n",
      "Episode: 3254 \tReward: 18.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000151689915\n",
      "Episode: 3255 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000151199238\n",
      "Episode: 3256 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000150511336\n",
      "Episode: 3257 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000015003047\n",
      "Episode: 3258 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000149416605\n",
      "Episode: 3259 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000148900517\n",
      "Episode: 3260 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000148240864\n",
      "Episode: 3261 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000147693386\n",
      "Episode: 3262 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014727748\n",
      "Episode: 3263 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014687449\n",
      "Episode: 3264 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014624136\n",
      "Episode: 3265 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014589372\n",
      "Episode: 3266 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000145369446\n",
      "Episode: 3267 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014483547\n",
      "Episode: 3268 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014307349\n",
      "Episode: 3269 \tReward: 7.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000142311514\n",
      "Episode: 3270 \tReward: 16.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000141669718\n",
      "Episode: 3271 \tReward: 12.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000014111546\n",
      "Episode: 3272 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000140490293\n",
      "Episode: 3273 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013994905\n",
      "Episode: 3274 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013947403\n",
      "Episode: 3275 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000138889466\n",
      "Episode: 3276 \tReward: 19.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013765333\n",
      "Episode: 3277 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013708188\n",
      "Episode: 3278 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000136597466\n",
      "Episode: 3279 \tReward: 12.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000136082104\n",
      "Episode: 3280 \tReward: 6.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000135764043\n",
      "Episode: 3281 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000135308643\n",
      "Episode: 3282 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000134744234\n",
      "Episode: 3283 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000134147294\n",
      "Episode: 3284 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000133593075\n",
      "Episode: 3285 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000133105017\n",
      "Episode: 3286 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013209461\n",
      "Episode: 3287 \tReward: 19.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000131406872\n",
      "Episode: 3288 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000013087706\n",
      "Episode: 3289 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000130167023\n",
      "Episode: 3290 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000128866685\n",
      "Episode: 3291 \tReward: 13.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000128070183\n",
      "Episode: 3292 \tReward: 7.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000012772486\n",
      "Episode: 3293 \tReward: 7.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000012736773\n",
      "Episode: 3294 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000126740084\n",
      "Episode: 3295 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000125823283\n",
      "Episode: 3296 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000125300947\n",
      "Episode: 3297 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000124888135\n",
      "Episode: 3298 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000124444323\n",
      "Episode: 3299 \tReward: 17.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000123885583\n",
      "Episode: 3300 \tReward: 19.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000123196224\n",
      "Episode: 3301 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000122728966\n",
      "Episode: 3302 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000122229255\n",
      "Episode: 3303 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000121780277\n",
      "Episode: 3304 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000121308686\n",
      "Episode: 3305 \tReward: 13.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000120831668\n",
      "Episode: 3306 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000012022421\n",
      "Episode: 3307 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000119581533\n",
      "Episode: 3308 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000119099397\n",
      "Episode: 3309 \tReward: 7.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000118756883\n",
      "Episode: 3310 \tReward: 18.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000117949716\n",
      "Episode: 3311 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011734032\n",
      "Episode: 3312 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000116766756\n",
      "Episode: 3313 \tReward: 18.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000116137916\n",
      "Episode: 3314 \tReward: 9.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000115769183\n",
      "Episode: 3315 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000115362394\n",
      "Episode: 3316 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000114913357\n",
      "Episode: 3317 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011440427\n",
      "Episode: 3318 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011339059\n",
      "Episode: 3319 \tReward: 9.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011305545\n",
      "Episode: 3320 \tReward: 17.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000112262335\n",
      "Episode: 3321 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000111823128\n",
      "Episode: 3322 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000111392323\n",
      "Episode: 3323 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011092102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3324 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000011044729\n",
      "Episode: 3325 \tReward: 18.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000109861273\n",
      "Episode: 3326 \tReward: 14.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010938332\n",
      "Episode: 3327 \tReward: 16.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010882253\n",
      "Episode: 3328 \tReward: 10.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000108477026\n",
      "Episode: 3329 \tReward: 11.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000108100182\n",
      "Episode: 3330 \tReward: 9.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010773542\n",
      "Episode: 3331 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010729461\n",
      "Episode: 3332 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000106785102\n",
      "Episode: 3333 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000106239757\n",
      "Episode: 3334 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000104488647\n",
      "Episode: 3335 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010421941\n",
      "Episode: 3336 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010372451\n",
      "Episode: 3337 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000103238144\n",
      "Episode: 3338 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000001029536\n",
      "Episode: 3339 \tReward: 7.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000102667788\n",
      "Episode: 3340 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000102182294\n",
      "Episode: 3341 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000101823245\n",
      "Episode: 3342 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000101376206\n",
      "Episode: 3343 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000101058384\n",
      "Episode: 3344 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010060263\n",
      "Episode: 3345 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000010016496\n",
      "Episode: 3346 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009975113\n",
      "Episode: 3347 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009934299\n",
      "Episode: 3348 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009886333\n",
      "Episode: 3349 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000098521858\n",
      "Episode: 3350 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000982621\n",
      "Episode: 3351 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009783657\n",
      "Episode: 3352 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009748109\n",
      "Episode: 3353 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009707447\n",
      "Episode: 3354 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009661156\n",
      "Episode: 3355 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000096295194\n",
      "Episode: 3356 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000096035548\n",
      "Episode: 3357 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009571724\n",
      "Episode: 3358 \tReward: 16.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009505146\n",
      "Episode: 3359 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000094624687\n",
      "Episode: 3360 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000094305397\n",
      "Episode: 3361 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009396087\n",
      "Episode: 3362 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000093430552\n",
      "Episode: 3363 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009252866\n",
      "Episode: 3364 \tReward: 16.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000092087425\n",
      "Episode: 3365 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009172715\n",
      "Episode: 3366 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000091461526\n",
      "Episode: 3367 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000009121856\n",
      "Episode: 3368 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000090868955\n",
      "Episode: 3369 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000090524307\n",
      "Episode: 3370 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000090319953\n",
      "Episode: 3371 \tReward: 15.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000089900043\n",
      "Episode: 3372 \tReward: 17.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008949998\n",
      "Episode: 3373 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000891962\n",
      "Episode: 3374 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000088881\n",
      "Episode: 3375 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008852796\n",
      "Episode: 3376 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008814634\n",
      "Episode: 3377 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000878331\n",
      "Episode: 3378 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008748772\n",
      "Episode: 3379 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000087093166\n",
      "Episode: 3380 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000086691724\n",
      "Episode: 3381 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008635083\n",
      "Episode: 3382 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008601988\n",
      "Episode: 3383 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008567306\n",
      "Episode: 3384 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000085389096\n",
      "Episode: 3385 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000084827385\n",
      "Episode: 3386 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000084492132\n",
      "Episode: 3387 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000084169987\n",
      "Episode: 3388 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000083822245\n",
      "Episode: 3389 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000083519355\n",
      "Episode: 3390 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008319759\n",
      "Episode: 3391 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000082850553\n",
      "Episode: 3392 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008259742\n",
      "Episode: 3393 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000082093464\n",
      "Episode: 3394 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000081747762\n",
      "Episode: 3395 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000008136282\n",
      "Episode: 3396 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000080667713\n",
      "Episode: 3397 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000080381046\n",
      "Episode: 3398 \tReward: 19.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000079279406\n",
      "Episode: 3399 \tReward: 11.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000078988195\n",
      "Episode: 3400 \tReward: 14.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000078669727\n",
      "Episode: 3401 \tReward: 13.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007829928\n",
      "Episode: 3402 \tReward: 11.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000077924344\n",
      "Episode: 3403 \tReward: 11.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000077658297\n",
      "Episode: 3404 \tReward: 15.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007723235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3405 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007695635\n",
      "Episode: 3406 \tReward: 7.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000076450114\n",
      "Episode: 3407 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000076077946\n",
      "Episode: 3408 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000075601675\n",
      "Episode: 3409 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000075326985\n",
      "Episode: 3410 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000075101342\n",
      "Episode: 3411 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000074783586\n",
      "Episode: 3412 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000074459727\n",
      "Episode: 3413 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000074144687\n",
      "Episode: 3414 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000073861993\n",
      "Episode: 3415 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007352742\n",
      "Episode: 3416 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007327199\n",
      "Episode: 3417 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000073011608\n",
      "Episode: 3418 \tReward: 4.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000072884678\n",
      "Episode: 3419 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000072114738\n",
      "Episode: 3420 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000071773723\n",
      "Episode: 3421 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000007160024\n",
      "Episode: 3422 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000071181887\n",
      "Episode: 3423 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000070883553\n",
      "Episode: 3424 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000070542714\n",
      "Episode: 3425 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000703511\n",
      "Episode: 3426 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000070102497\n",
      "Episode: 3427 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000069780765\n",
      "Episode: 3428 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000069589827\n",
      "Episode: 3429 \tReward: 10.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000069350852\n",
      "Episode: 3430 \tReward: 10.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000069125137\n",
      "Episode: 3431 \tReward: 7.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000068964952\n",
      "Episode: 3432 \tReward: 10.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000068744615\n",
      "Episode: 3433 \tReward: 12.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000068336115\n",
      "Episode: 3434 \tReward: 11.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000068037458\n",
      "Episode: 3435 \tReward: 11.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000067776694\n",
      "Episode: 3436 \tReward: 17.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006732411\n",
      "Episode: 3437 \tReward: 7.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000067139895\n",
      "Episode: 3438 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006687722\n",
      "Episode: 3439 \tReward: 6.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000066734257\n",
      "Episode: 3440 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000066562305\n",
      "Episode: 3441 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006624622\n",
      "Episode: 3442 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000066058347\n",
      "Episode: 3443 \tReward: 9.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000065876277\n",
      "Episode: 3444 \tReward: 17.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006555034\n",
      "Episode: 3445 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000065308252\n",
      "Episode: 3446 \tReward: 18.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000064947447\n",
      "Episode: 3447 \tReward: 5.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000064815088\n",
      "Episode: 3448 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000064584758\n",
      "Episode: 3449 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000064271637\n",
      "Episode: 3450 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000064065014\n",
      "Episode: 3451 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000063834796\n",
      "Episode: 3452 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006354437\n",
      "Episode: 3453 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000063312224\n",
      "Episode: 3454 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006275501\n",
      "Episode: 3455 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000062481992\n",
      "Episode: 3456 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000062195235\n",
      "Episode: 3457 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000062064763\n",
      "Episode: 3458 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006163306\n",
      "Episode: 3459 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006147917\n",
      "Episode: 3460 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006128275\n",
      "Episode: 3461 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000061129737\n",
      "Episode: 3462 \tReward: 16.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000060790796\n",
      "Episode: 3463 \tReward: 8.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000060612335\n",
      "Episode: 3464 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000006031968\n",
      "Episode: 3465 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000060088497\n",
      "Episode: 3466 \tReward: 17.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000059785215\n",
      "Episode: 3467 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005960017\n",
      "Episode: 3468 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000058992978\n",
      "Episode: 3469 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000058775107\n",
      "Episode: 3470 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000058535795\n",
      "Episode: 3471 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005834061\n",
      "Episode: 3472 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005782484\n",
      "Episode: 3473 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005759746\n",
      "Episode: 3474 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000057379\n",
      "Episode: 3475 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005720941\n",
      "Episode: 3476 \tReward: 5.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005709853\n",
      "Episode: 3477 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000056891072\n",
      "Episode: 3478 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000056642434\n",
      "Episode: 3479 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000056449047\n",
      "Episode: 3480 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000056282205\n",
      "Episode: 3481 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005605304\n",
      "Episode: 3482 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000055867256\n",
      "Episode: 3483 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005560752\n",
      "Episode: 3484 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000055393288\n",
      "Episode: 3485 \tReward: 6.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000055259398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3486 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000055041003\n",
      "Episode: 3487 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005481251\n",
      "Episode: 3488 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000054623185\n",
      "Episode: 3489 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000054400776\n",
      "Episode: 3490 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000054096984\n",
      "Episode: 3491 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005392523\n",
      "Episode: 3492 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000053767997\n",
      "Episode: 3493 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000053043823\n",
      "Episode: 3494 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000052821505\n",
      "Episode: 3495 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000052572776\n",
      "Episode: 3496 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000052237385\n",
      "Episode: 3497 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000052072576\n",
      "Episode: 3498 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005181908\n",
      "Episode: 3499 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000051617377\n",
      "Episode: 3500 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000051446292\n",
      "Episode: 3501 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000051273725\n",
      "Episode: 3502 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000051079252\n",
      "Episode: 3503 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000050891628\n",
      "Episode: 3504 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000050680356\n",
      "Episode: 3505 \tReward: 17.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000504407\n",
      "Episode: 3506 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000050237332\n",
      "Episode: 3507 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000005003078\n",
      "Episode: 3508 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000049684767\n",
      "Episode: 3509 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004945081\n",
      "Episode: 3510 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000049286905\n",
      "Episode: 3511 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000049130422\n",
      "Episode: 3512 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000048957786\n",
      "Episode: 3513 \tReward: 17.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000048717506\n",
      "Episode: 3514 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000048557974\n",
      "Episode: 3515 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000048221184\n",
      "Episode: 3516 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004805847\n",
      "Episode: 3517 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000047792964\n",
      "Episode: 3518 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004761836\n",
      "Episode: 3519 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000047383705\n",
      "Episode: 3520 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000047248383\n",
      "Episode: 3521 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004710214\n",
      "Episode: 3522 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000046568225\n",
      "Episode: 3523 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004635172\n",
      "Episode: 3524 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004600354\n",
      "Episode: 3525 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000045840977\n",
      "Episode: 3526 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000045540336\n",
      "Episode: 3527 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004537759\n",
      "Episode: 3528 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004517295\n",
      "Episode: 3529 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000045038532\n",
      "Episode: 3530 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000044851564\n",
      "Episode: 3531 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000044689492\n",
      "Episode: 3532 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000044519104\n",
      "Episode: 3533 \tReward: 17.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000442404\n",
      "Episode: 3534 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000044107877\n",
      "Episode: 3535 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004396344\n",
      "Episode: 3536 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000043776556\n",
      "Episode: 3537 \tReward: 6.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000043685594\n",
      "Episode: 3538 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000043477278\n",
      "Episode: 3539 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000043302848\n",
      "Episode: 3540 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004318695\n",
      "Episode: 3541 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000042999067\n",
      "Episode: 3542 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004286169\n",
      "Episode: 3543 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000042741845\n",
      "Episode: 3544 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000042571218\n",
      "Episode: 3545 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004230471\n",
      "Episode: 3546 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000042208366\n",
      "Episode: 3547 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004201213\n",
      "Episode: 3548 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004190304\n",
      "Episode: 3549 \tReward: 9.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004176666\n",
      "Episode: 3550 \tReward: 9.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004117694\n",
      "Episode: 3551 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000041015844\n",
      "Episode: 3552 \tReward: 7.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004088889\n",
      "Episode: 3553 \tReward: 15.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000004069635\n",
      "Episode: 3554 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000040561464\n",
      "Episode: 3555 \tReward: 10.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000040410047\n",
      "Episode: 3556 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000040234243\n",
      "Episode: 3557 \tReward: 7.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000040125757\n",
      "Episode: 3558 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003999676\n",
      "Episode: 3559 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000039821955\n",
      "Episode: 3560 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003972888\n",
      "Episode: 3561 \tReward: 9.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000039597992\n",
      "Episode: 3562 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003945964\n",
      "Episode: 3563 \tReward: 8.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000393438\n",
      "Episode: 3564 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000039013918\n",
      "Episode: 3565 \tReward: 10.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003888927\n",
      "Episode: 3566 \tReward: 11.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000038711566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3567 \tReward: 7.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000038612593\n",
      "Episode: 3568 \tReward: 10.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003848153\n",
      "Episode: 3569 \tReward: 7.0 \tMean: 8.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000038386215\n",
      "Episode: 3570 \tReward: 8.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000038058272\n",
      "Episode: 3571 \tReward: 9.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037935162\n",
      "Episode: 3572 \tReward: 14.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037755775\n",
      "Episode: 3573 \tReward: 11.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037627624\n",
      "Episode: 3574 \tReward: 14.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037460927\n",
      "Episode: 3575 \tReward: 8.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003734871\n",
      "Episode: 3576 \tReward: 10.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037236832\n",
      "Episode: 3577 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000037083732\n",
      "Episode: 3578 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000036898776\n",
      "Episode: 3579 \tReward: 17.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003668832\n",
      "Episode: 3580 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000036505334\n",
      "Episode: 3581 \tReward: 16.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000036308738\n",
      "Episode: 3582 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000036097313\n",
      "Episode: 3583 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000035932365\n",
      "Episode: 3584 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000035771032\n",
      "Episode: 3585 \tReward: 12.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003562966\n",
      "Episode: 3586 \tReward: 6.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000035554206\n",
      "Episode: 3587 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003541298\n",
      "Episode: 3588 \tReward: 10.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003529631\n",
      "Episode: 3589 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000035186358\n",
      "Episode: 3590 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000035048697\n",
      "Episode: 3591 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000034778465\n",
      "Episode: 3592 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000034647945\n",
      "Episode: 3593 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000034535177\n",
      "Episode: 3594 \tReward: 18.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000034304563\n",
      "Episode: 3595 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003419018\n",
      "Episode: 3596 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000034061865\n",
      "Episode: 3597 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000033944892\n",
      "Episode: 3598 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000033730363\n",
      "Episode: 3599 \tReward: 6.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000033649507\n",
      "Episode: 3600 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003354133\n",
      "Episode: 3601 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003343417\n",
      "Episode: 3602 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003329404\n",
      "Episode: 3603 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003261585\n",
      "Episode: 3604 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000032503847\n",
      "Episode: 3605 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000032341085\n",
      "Episode: 3606 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003225324\n",
      "Episode: 3607 \tReward: 18.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003206799\n",
      "Episode: 3608 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000031936145\n",
      "Episode: 3609 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003174764\n",
      "Episode: 3610 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000031556463\n",
      "Episode: 3611 \tReward: 13.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003142106\n",
      "Episode: 3612 \tReward: 11.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000031313157\n",
      "Episode: 3613 \tReward: 8.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003122873\n",
      "Episode: 3614 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000031074217\n",
      "Episode: 3615 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000030979893\n",
      "Episode: 3616 \tReward: 6.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000030905633\n",
      "Episode: 3617 \tReward: 7.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003083463\n",
      "Episode: 3618 \tReward: 6.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000030759486\n",
      "Episode: 3619 \tReward: 13.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000003059689\n",
      "Episode: 3620 \tReward: 16.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000030353092\n",
      "Episode: 3621 \tReward: 8.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000302658\n",
      "Episode: 3622 \tReward: 8.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000030175744\n",
      "Episode: 3623 \tReward: 15.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000029960458\n",
      "Episode: 3624 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000029840856\n",
      "Episode: 3625 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000029715193\n",
      "Episode: 3626 \tReward: 4.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002966472\n",
      "Episode: 3627 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000029561073\n",
      "Episode: 3628 \tReward: 5.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002950024\n",
      "Episode: 3629 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002938953\n",
      "Episode: 3630 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002927513\n",
      "Episode: 3631 \tReward: 8.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000029190942\n",
      "Episode: 3632 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028913785\n",
      "Episode: 3633 \tReward: 13.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028696018\n",
      "Episode: 3634 \tReward: 10.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028600907\n",
      "Episode: 3635 \tReward: 11.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002850269\n",
      "Episode: 3636 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028380958\n",
      "Episode: 3637 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028276142\n",
      "Episode: 3638 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028193698\n",
      "Episode: 3639 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028081708\n",
      "Episode: 3640 \tReward: 5.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000028017755\n",
      "Episode: 3641 \tReward: 5.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002795842\n",
      "Episode: 3642 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000027865197\n",
      "Episode: 3643 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000277534\n",
      "Episode: 3644 \tReward: 14.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000027498143\n",
      "Episode: 3645 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000027404808\n",
      "Episode: 3646 \tReward: 15.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002727467\n",
      "Episode: 3647 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000027161444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3648 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000027055178\n",
      "Episode: 3649 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000026882042\n",
      "Episode: 3650 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000026738872\n",
      "Episode: 3651 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002637452\n",
      "Episode: 3652 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000026286577\n",
      "Episode: 3653 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000026137693\n",
      "Episode: 3654 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000026023458\n",
      "Episode: 3655 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025899883\n",
      "Episode: 3656 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025798555\n",
      "Episode: 3657 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025718702\n",
      "Episode: 3658 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025617058\n",
      "Episode: 3659 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025513772\n",
      "Episode: 3660 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000025388553\n",
      "Episode: 3661 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000252781\n",
      "Episode: 3662 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002515907\n",
      "Episode: 3663 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000024916205\n",
      "Episode: 3664 \tReward: 19.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000024656447\n",
      "Episode: 3665 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002456981\n",
      "Episode: 3666 \tReward: 6.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002450846\n",
      "Episode: 3667 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000024415994\n",
      "Episode: 3668 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002434383\n",
      "Episode: 3669 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000024245193\n",
      "Episode: 3670 \tReward: 21.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000024102085\n",
      "Episode: 3671 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023994352\n",
      "Episode: 3672 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002383079\n",
      "Episode: 3673 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023741353\n",
      "Episode: 3674 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023621053\n",
      "Episode: 3675 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023553594\n",
      "Episode: 3676 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023447373\n",
      "Episode: 3677 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002334443\n",
      "Episode: 3678 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023246124\n",
      "Episode: 3679 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002318762\n",
      "Episode: 3680 \tReward: 8.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002312047\n",
      "Episode: 3681 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000023007457\n",
      "Episode: 3682 \tReward: 16.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002249917\n",
      "Episode: 3683 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000224098\n",
      "Episode: 3684 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000022294018\n",
      "Episode: 3685 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002221657\n",
      "Episode: 3686 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002214116\n",
      "Episode: 3687 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000220466\n",
      "Episode: 3688 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002196518\n",
      "Episode: 3689 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002187662\n",
      "Episode: 3690 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000021774912\n",
      "Episode: 3691 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002168278\n",
      "Episode: 3692 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000021581112\n",
      "Episode: 3693 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000021493238\n",
      "Episode: 3694 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002144086\n",
      "Episode: 3695 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000021328377\n",
      "Episode: 3696 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000021169435\n",
      "Episode: 3697 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002107481\n",
      "Episode: 3698 \tReward: 14.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020981443\n",
      "Episode: 3699 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020869702\n",
      "Episode: 3700 \tReward: 6.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002082384\n",
      "Episode: 3701 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000002073988\n",
      "Episode: 3702 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020659152\n",
      "Episode: 3703 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020535567\n",
      "Episode: 3704 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020455634\n",
      "Episode: 3705 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020376014\n",
      "Episode: 3706 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000203227\n",
      "Episode: 3707 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020245618\n",
      "Episode: 3708 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000020179324\n",
      "Episode: 3709 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000019989726\n",
      "Episode: 3710 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000019946992\n",
      "Episode: 3711 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000019869353\n",
      "Episode: 3712 \tReward: 15.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001977935\n",
      "Episode: 3713 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000196933\n",
      "Episode: 3714 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001961782\n",
      "Episode: 3715 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001954928\n",
      "Episode: 3716 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001943739\n",
      "Episode: 3717 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000019349342\n",
      "Episode: 3718 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001919939\n",
      "Episode: 3719 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000019146855\n",
      "Episode: 3720 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000190708\n",
      "Episode: 3721 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001902204\n",
      "Episode: 3722 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018936256\n",
      "Episode: 3723 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001885161\n",
      "Episode: 3724 \tReward: 14.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018769597\n",
      "Episode: 3725 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018697287\n",
      "Episode: 3726 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018618923\n",
      "Episode: 3727 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018542\n",
      "Episode: 3728 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001835824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3729 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018279833\n",
      "Episode: 3730 \tReward: 18.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018183934\n",
      "Episode: 3731 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000018121127\n",
      "Episode: 3732 \tReward: 17.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001802606\n",
      "Episode: 3733 \tReward: 16.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001794656\n",
      "Episode: 3734 \tReward: 16.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001767442\n",
      "Episode: 3735 \tReward: 18.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000017583456\n",
      "Episode: 3736 \tReward: 10.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001752798\n",
      "Episode: 3737 \tReward: 14.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001745207\n",
      "Episode: 3738 \tReward: 12.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000017381708\n",
      "Episode: 3739 \tReward: 11.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000017315785\n",
      "Episode: 3740 \tReward: 13.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000017172656\n",
      "Episode: 3741 \tReward: 11.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001711026\n",
      "Episode: 3742 \tReward: 14.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000017037188\n",
      "Episode: 3743 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016984112\n",
      "Episode: 3744 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016593623\n",
      "Episode: 3745 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016533664\n",
      "Episode: 3746 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001646206\n",
      "Episode: 3747 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001640553\n",
      "Episode: 3748 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016322073\n",
      "Episode: 3749 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016250415\n",
      "Episode: 3750 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001619137\n",
      "Episode: 3751 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016151914\n",
      "Episode: 3752 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001609612\n",
      "Episode: 3753 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000016032828\n",
      "Episode: 3754 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015981286\n",
      "Episode: 3755 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015942338\n",
      "Episode: 3756 \tReward: 6.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015908896\n",
      "Episode: 3757 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015845388\n",
      "Episode: 3758 \tReward: 9.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015790026\n",
      "Episode: 3759 \tReward: 12.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001572636\n",
      "Episode: 3760 \tReward: 13.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015657944\n",
      "Episode: 3761 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015552143\n",
      "Episode: 3762 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001548882\n",
      "Episode: 3763 \tReward: 18.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015412186\n",
      "Episode: 3764 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015339303\n",
      "Episode: 3765 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015158153\n",
      "Episode: 3766 \tReward: 17.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015077724\n",
      "Episode: 3767 \tReward: 8.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000015030155\n",
      "Episode: 3768 \tReward: 16.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001495549\n",
      "Episode: 3769 \tReward: 13.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014889236\n",
      "Episode: 3770 \tReward: 11.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014613686\n",
      "Episode: 3771 \tReward: 11.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014566706\n",
      "Episode: 3772 \tReward: 13.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001450304\n",
      "Episode: 3773 \tReward: 6.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014464517\n",
      "Episode: 3774 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000144134\n",
      "Episode: 3775 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014369076\n",
      "Episode: 3776 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014332626\n",
      "Episode: 3777 \tReward: 8.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014292266\n",
      "Episode: 3778 \tReward: 7.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001425658\n",
      "Episode: 3779 \tReward: 13.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001420506\n",
      "Episode: 3780 \tReward: 10.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014073288\n",
      "Episode: 3781 \tReward: 8.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000014035058\n",
      "Episode: 3782 \tReward: 10.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013985744\n",
      "Episode: 3783 \tReward: 12.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001393465\n",
      "Episode: 3784 \tReward: 10.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001389096\n",
      "Episode: 3785 \tReward: 15.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001382887\n",
      "Episode: 3786 \tReward: 6.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013796548\n",
      "Episode: 3787 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001375247\n",
      "Episode: 3788 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013703324\n",
      "Episode: 3789 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001366091\n",
      "Episode: 3790 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013580547\n",
      "Episode: 3791 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001352417\n",
      "Episode: 3792 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001349202\n",
      "Episode: 3793 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013445148\n",
      "Episode: 3794 \tReward: 17.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001334202\n",
      "Episode: 3795 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001328982\n",
      "Episode: 3796 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001322777\n",
      "Episode: 3797 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013170222\n",
      "Episode: 3798 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001311345\n",
      "Episode: 3799 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013074955\n",
      "Episode: 3800 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000013035788\n",
      "Episode: 3801 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012989464\n",
      "Episode: 3802 \tReward: 6.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001295729\n",
      "Episode: 3803 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001287102\n",
      "Episode: 3804 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012820412\n",
      "Episode: 3805 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001278303\n",
      "Episode: 3806 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012732253\n",
      "Episode: 3807 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000126931\n",
      "Episode: 3808 \tReward: 8.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012655582\n",
      "Episode: 3809 \tReward: 17.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001258818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3810 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001254119\n",
      "Episode: 3811 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012490127\n",
      "Episode: 3812 \tReward: 19.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012422366\n",
      "Episode: 3813 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001234361\n",
      "Episode: 3814 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012310327\n",
      "Episode: 3815 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012265352\n",
      "Episode: 3816 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012214192\n",
      "Episode: 3817 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012172975\n",
      "Episode: 3818 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012130204\n",
      "Episode: 3819 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012088546\n",
      "Episode: 3820 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000012036678\n",
      "Episode: 3821 \tReward: 18.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001197377\n",
      "Episode: 3822 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011928594\n",
      "Episode: 3823 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001187765\n",
      "Episode: 3824 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001183615\n",
      "Episode: 3825 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011779002\n",
      "Episode: 3826 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011741133\n",
      "Episode: 3827 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011694496\n",
      "Episode: 3828 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001165667\n",
      "Episode: 3829 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011612458\n",
      "Episode: 3830 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001157721\n",
      "Episode: 3831 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001152569\n",
      "Episode: 3832 \tReward: 18.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011454223\n",
      "Episode: 3833 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011404163\n",
      "Episode: 3834 \tReward: 7.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011375235\n",
      "Episode: 3835 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011339343\n",
      "Episode: 3836 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011289785\n",
      "Episode: 3837 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011242244\n",
      "Episode: 3838 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001119759\n",
      "Episode: 3839 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011153332\n",
      "Episode: 3840 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011113697\n",
      "Episode: 3841 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000011021837\n",
      "Episode: 3842 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010983107\n",
      "Episode: 3843 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010939045\n",
      "Episode: 3844 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001090824\n",
      "Episode: 3845 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001086361\n",
      "Episode: 3846 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010831714\n",
      "Episode: 3847 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001079754\n",
      "Episode: 3848 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010760677\n",
      "Episode: 3849 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010715578\n",
      "Episode: 3850 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001048975\n",
      "Episode: 3851 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010370843\n",
      "Episode: 3852 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010344535\n",
      "Episode: 3853 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010263752\n",
      "Episode: 3854 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001021971\n",
      "Episode: 3855 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010193177\n",
      "Episode: 3856 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010146395\n",
      "Episode: 3857 \tReward: 18.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010095588\n",
      "Episode: 3858 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000010051467\n",
      "Episode: 3859 \tReward: 5.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000001003118\n",
      "Episode: 3860 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000993753\n",
      "Episode: 3861 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000985795\n",
      "Episode: 3862 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009820367\n",
      "Episode: 3863 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009761622\n",
      "Episode: 3864 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009717016\n",
      "Episode: 3865 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000967706\n",
      "Episode: 3866 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009640938\n",
      "Episode: 3867 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009607447\n",
      "Episode: 3868 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000957388\n",
      "Episode: 3869 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009492844\n",
      "Episode: 3870 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000946422\n",
      "Episode: 3871 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009419844\n",
      "Episode: 3872 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009383553\n",
      "Episode: 3873 \tReward: 18.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000933787\n",
      "Episode: 3874 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009286468\n",
      "Episode: 3875 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009252172\n",
      "Episode: 3876 \tReward: 7.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000922778\n",
      "Episode: 3877 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009199954\n",
      "Episode: 3878 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009164142\n",
      "Episode: 3879 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009125187\n",
      "Episode: 3880 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009086395\n",
      "Episode: 3881 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000905447\n",
      "Episode: 3882 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000009017062\n",
      "Episode: 3883 \tReward: 19.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008906473\n",
      "Episode: 3884 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008872695\n",
      "Episode: 3885 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000883533\n",
      "Episode: 3886 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000881133\n",
      "Episode: 3887 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000871912\n",
      "Episode: 3888 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008685532\n",
      "Episode: 3889 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000086474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3890 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008616667\n",
      "Episode: 3891 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008578666\n",
      "Episode: 3892 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008534344\n",
      "Episode: 3893 \tReward: 18.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008473965\n",
      "Episode: 3894 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008429\n",
      "Episode: 3895 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008390823\n",
      "Episode: 3896 \tReward: 8.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008367862\n",
      "Episode: 3897 \tReward: 11.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008334958\n",
      "Episode: 3898 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000830484\n",
      "Episode: 3899 \tReward: 6.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008286258\n",
      "Episode: 3900 \tReward: 17.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008146092\n",
      "Episode: 3901 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000081126\n",
      "Episode: 3902 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000808846\n",
      "Episode: 3903 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008057944\n",
      "Episode: 3904 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000803927\n",
      "Episode: 3905 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000008012466\n",
      "Episode: 3906 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007978243\n",
      "Episode: 3907 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007954506\n",
      "Episode: 3908 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007914517\n",
      "Episode: 3909 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007885287\n",
      "Episode: 3910 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007851137\n",
      "Episode: 3911 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000781964\n",
      "Episode: 3912 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007793877\n",
      "Episode: 3913 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007766493\n",
      "Episode: 3914 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007739046\n",
      "Episode: 3915 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000771247\n",
      "Episode: 3916 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007680145\n",
      "Episode: 3917 \tReward: 18.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007639244\n",
      "Episode: 3918 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007610118\n",
      "Episode: 3919 \tReward: 15.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007572464\n",
      "Episode: 3920 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007547668\n",
      "Episode: 3921 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000751979\n",
      "Episode: 3922 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000749367\n",
      "Episode: 3923 \tReward: 17.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007457785\n",
      "Episode: 3924 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000743039\n",
      "Episode: 3925 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007407835\n",
      "Episode: 3926 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007385943\n",
      "Episode: 3927 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007362934\n",
      "Episode: 3928 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007325627\n",
      "Episode: 3929 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000729755\n",
      "Episode: 3930 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007267253\n",
      "Episode: 3931 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007243023\n",
      "Episode: 3932 \tReward: 19.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007205313\n",
      "Episode: 3933 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000717583\n",
      "Episode: 3934 \tReward: 6.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000715906\n",
      "Episode: 3935 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007129055\n",
      "Episode: 3936 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007106136\n",
      "Episode: 3937 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000707423\n",
      "Episode: 3938 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000007043453\n",
      "Episode: 3939 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000701758\n",
      "Episode: 3940 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000699334\n",
      "Episode: 3941 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000696598\n",
      "Episode: 3942 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006942475\n",
      "Episode: 3943 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006911996\n",
      "Episode: 3944 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000689129\n",
      "Episode: 3945 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000681754\n",
      "Episode: 3946 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006796845\n",
      "Episode: 3947 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006717786\n",
      "Episode: 3948 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000668241\n",
      "Episode: 3949 \tReward: 7.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006660794\n",
      "Episode: 3950 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006642434\n",
      "Episode: 3951 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000662373\n",
      "Episode: 3952 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006603093\n",
      "Episode: 3953 \tReward: 15.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006550743\n",
      "Episode: 3954 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006522505\n",
      "Episode: 3955 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000649608\n",
      "Episode: 3956 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006473898\n",
      "Episode: 3957 \tReward: 15.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000644496\n",
      "Episode: 3958 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006419234\n",
      "Episode: 3959 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006398722\n",
      "Episode: 3960 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000637165\n",
      "Episode: 3961 \tReward: 17.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000623687\n",
      "Episode: 3962 \tReward: 6.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000622254\n",
      "Episode: 3963 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006201793\n",
      "Episode: 3964 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006173576\n",
      "Episode: 3965 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006147947\n",
      "Episode: 3966 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006126714\n",
      "Episode: 3967 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006111417\n",
      "Episode: 3968 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006093352\n",
      "Episode: 3969 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006062963\n",
      "Episode: 3970 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000006029587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3971 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000594802\n",
      "Episode: 3972 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005930916\n",
      "Episode: 3973 \tReward: 8.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000591374\n",
      "Episode: 3974 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005889897\n",
      "Episode: 3975 \tReward: 6.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000587672\n",
      "Episode: 3976 \tReward: 14.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000585279\n",
      "Episode: 3977 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000582686\n",
      "Episode: 3978 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000580267\n",
      "Episode: 3979 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000578182\n",
      "Episode: 3980 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005734833\n",
      "Episode: 3981 \tReward: 4.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000572429\n",
      "Episode: 3982 \tReward: 7.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005709884\n",
      "Episode: 3983 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005690844\n",
      "Episode: 3984 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005665066\n",
      "Episode: 3985 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005632415\n",
      "Episode: 3986 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005607463\n",
      "Episode: 3987 \tReward: 4.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005597155\n",
      "Episode: 3988 \tReward: 10.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005578826\n",
      "Episode: 3989 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005557222\n",
      "Episode: 3990 \tReward: 15.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005532273\n",
      "Episode: 3991 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005446748\n",
      "Episode: 3992 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005431735\n",
      "Episode: 3993 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000054027\n",
      "Episode: 3994 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005386192\n",
      "Episode: 3995 \tReward: 16.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005360292\n",
      "Episode: 3996 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000534509\n",
      "Episode: 3997 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000532652\n",
      "Episode: 3998 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000530908\n",
      "Episode: 3999 \tReward: 5.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000529826\n",
      "Episode: 4000 \tReward: 10.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005280592\n",
      "Episode: 4001 \tReward: 10.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005179864\n",
      "Episode: 4002 \tReward: 5.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005168998\n",
      "Episode: 4003 \tReward: 8.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005153822\n",
      "Episode: 4004 \tReward: 10.0 \tMean: 9.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000513715\n",
      "Episode: 4005 \tReward: 15.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005113677\n",
      "Episode: 4006 \tReward: 14.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000508024\n",
      "Episode: 4007 \tReward: 14.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005058645\n",
      "Episode: 4008 \tReward: 17.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005035528\n",
      "Episode: 4009 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000005022753\n",
      "Episode: 4010 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000500631\n",
      "Episode: 4011 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004990214\n",
      "Episode: 4012 \tReward: 6.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004965223\n",
      "Episode: 4013 \tReward: 21.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000491897\n",
      "Episode: 4014 \tReward: 6.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004907176\n",
      "Episode: 4015 \tReward: 5.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000489649\n",
      "Episode: 4016 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004878407\n",
      "Episode: 4017 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000483528\n",
      "Episode: 4018 \tReward: 10.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004812123\n",
      "Episode: 4019 \tReward: 8.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004799245\n",
      "Episode: 4020 \tReward: 9.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004784867\n",
      "Episode: 4021 \tReward: 8.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004771586\n",
      "Episode: 4022 \tReward: 9.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004758815\n",
      "Episode: 4023 \tReward: 10.0 \tMean: 8.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004742283\n",
      "Episode: 4024 \tReward: 8.0 \tMean: 8.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000472893\n",
      "Episode: 4025 \tReward: 15.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000047012\n",
      "Episode: 4026 \tReward: 12.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004683747\n",
      "Episode: 4027 \tReward: 14.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000466393\n",
      "Episode: 4028 \tReward: 13.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004644105\n",
      "Episode: 4029 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004621404\n",
      "Episode: 4030 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004607745\n",
      "Episode: 4031 \tReward: 16.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000458522\n",
      "Episode: 4032 \tReward: 16.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004548414\n",
      "Episode: 4033 \tReward: 7.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004528444\n",
      "Episode: 4034 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004510098\n",
      "Episode: 4035 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004478904\n",
      "Episode: 4036 \tReward: 8.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004464773\n",
      "Episode: 4037 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004449976\n",
      "Episode: 4038 \tReward: 6.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004438953\n",
      "Episode: 4039 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004417078\n",
      "Episode: 4040 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000438548\n",
      "Episode: 4041 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004364214\n",
      "Episode: 4042 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004351665\n",
      "Episode: 4043 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004334554\n",
      "Episode: 4044 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004317682\n",
      "Episode: 4045 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000426874\n",
      "Episode: 4046 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000425493\n",
      "Episode: 4047 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000042299\n",
      "Episode: 4048 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000421234\n",
      "Episode: 4049 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000418999\n",
      "Episode: 4050 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000417602\n",
      "Episode: 4051 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004155773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4052 \tReward: 19.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004131657\n",
      "Episode: 4053 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000411656\n",
      "Episode: 4054 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000410218\n",
      "Episode: 4055 \tReward: 5.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004094392\n",
      "Episode: 4056 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004048144\n",
      "Episode: 4057 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000004030856\n",
      "Episode: 4058 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003999697\n",
      "Episode: 4059 \tReward: 17.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003979668\n",
      "Episode: 4060 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003964655\n",
      "Episode: 4061 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000394567\n",
      "Episode: 4062 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000393377\n",
      "Episode: 4063 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003917048\n",
      "Episode: 4064 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003898916\n",
      "Episode: 4065 \tReward: 11.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003830894\n",
      "Episode: 4066 \tReward: 11.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000381019\n",
      "Episode: 4067 \tReward: 14.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000379452\n",
      "Episode: 4068 \tReward: 5.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003786184\n",
      "Episode: 4069 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003774086\n",
      "Episode: 4070 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003760374\n",
      "Episode: 4071 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003748134\n",
      "Episode: 4072 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003733174\n",
      "Episode: 4073 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003717006\n",
      "Episode: 4074 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003703205\n",
      "Episode: 4075 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003689306\n",
      "Episode: 4076 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003679873\n",
      "Episode: 4077 \tReward: 8.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003669218\n",
      "Episode: 4078 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000365552\n",
      "Episode: 4079 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003639544\n",
      "Episode: 4080 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000036248\n",
      "Episode: 4081 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003613\n",
      "Episode: 4082 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003598938\n",
      "Episode: 4083 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003582992\n",
      "Episode: 4084 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000357512\n",
      "Episode: 4085 \tReward: 17.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003555864\n",
      "Episode: 4086 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003541175\n",
      "Episode: 4087 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000352732\n",
      "Episode: 4088 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003512958\n",
      "Episode: 4089 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003496346\n",
      "Episode: 4090 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003479047\n",
      "Episode: 4091 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000344767\n",
      "Episode: 4092 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003406137\n",
      "Episode: 4093 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003395187\n",
      "Episode: 4094 \tReward: 18.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000337778\n",
      "Episode: 4095 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003367997\n",
      "Episode: 4096 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000335838\n",
      "Episode: 4097 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003344037\n",
      "Episode: 4098 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003331752\n",
      "Episode: 4099 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003324164\n",
      "Episode: 4100 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003311424\n",
      "Episode: 4101 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003298404\n",
      "Episode: 4102 \tReward: 5.0 \tMean: 9.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000329155\n",
      "Episode: 4103 \tReward: 5.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003284252\n",
      "Episode: 4104 \tReward: 13.0 \tMean: 8.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003268785\n",
      "Episode: 4105 \tReward: 11.0 \tMean: 9.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003251573\n",
      "Episode: 4106 \tReward: 13.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003234774\n",
      "Episode: 4107 \tReward: 14.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003219026\n",
      "Episode: 4108 \tReward: 14.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000320598\n",
      "Episode: 4109 \tReward: 8.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003195996\n",
      "Episode: 4110 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003185785\n",
      "Episode: 4111 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003175162\n",
      "Episode: 4112 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000316103\n",
      "Episode: 4113 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000315024\n",
      "Episode: 4114 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000313459\n",
      "Episode: 4115 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003107126\n",
      "Episode: 4116 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000309615\n",
      "Episode: 4117 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000308126\n",
      "Episode: 4118 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000307025\n",
      "Episode: 4119 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003059033\n",
      "Episode: 4120 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003050234\n",
      "Episode: 4121 \tReward: 16.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000303654\n",
      "Episode: 4122 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003021757\n",
      "Episode: 4123 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000003009093\n",
      "Episode: 4124 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000299768\n",
      "Episode: 4125 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002990913\n",
      "Episode: 4126 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000297778\n",
      "Episode: 4127 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002964233\n",
      "Episode: 4128 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002955237\n",
      "Episode: 4129 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002943615\n",
      "Episode: 4130 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002935444\n",
      "Episode: 4131 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000029287\n",
      "Episode: 4132 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002911064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4133 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002896718\n",
      "Episode: 4134 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000028881\n",
      "Episode: 4135 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000288037\n",
      "Episode: 4136 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002871166\n",
      "Episode: 4137 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002844246\n",
      "Episode: 4138 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002834084\n",
      "Episode: 4139 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002824182\n",
      "Episode: 4140 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002813413\n",
      "Episode: 4141 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000280011\n",
      "Episode: 4142 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002787927\n",
      "Episode: 4143 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002777022\n",
      "Episode: 4144 \tReward: 18.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002762232\n",
      "Episode: 4145 \tReward: 16.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000274961\n",
      "Episode: 4146 \tReward: 16.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002736714\n",
      "Episode: 4147 \tReward: 15.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002713552\n",
      "Episode: 4148 \tReward: 12.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000270299\n",
      "Episode: 4149 \tReward: 15.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002691122\n",
      "Episode: 4150 \tReward: 8.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002683652\n",
      "Episode: 4151 \tReward: 6.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002676845\n",
      "Episode: 4152 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002662107\n",
      "Episode: 4153 \tReward: 17.0 \tMean: 13.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002649416\n",
      "Episode: 4154 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002637255\n",
      "Episode: 4155 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002625678\n",
      "Episode: 4156 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000261488\n",
      "Episode: 4157 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000260413\n",
      "Episode: 4158 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002595292\n",
      "Episode: 4159 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000258483\n",
      "Episode: 4160 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002573376\n",
      "Episode: 4161 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000255972\n",
      "Episode: 4162 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000254884\n",
      "Episode: 4163 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002532124\n",
      "Episode: 4164 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002523277\n",
      "Episode: 4165 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002507932\n",
      "Episode: 4166 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002494876\n",
      "Episode: 4167 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002481935\n",
      "Episode: 4168 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000247371\n",
      "Episode: 4169 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002463637\n",
      "Episode: 4170 \tReward: 8.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002456945\n",
      "Episode: 4171 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000244753\n",
      "Episode: 4172 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002439074\n",
      "Episode: 4173 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002431913\n",
      "Episode: 4174 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002421723\n",
      "Episode: 4175 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002411766\n",
      "Episode: 4176 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002403144\n",
      "Episode: 4177 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000239135\n",
      "Episode: 4178 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000238352\n",
      "Episode: 4179 \tReward: 18.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000237002\n",
      "Episode: 4180 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000235938\n",
      "Episode: 4181 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002349538\n",
      "Episode: 4182 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002341235\n",
      "Episode: 4183 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000023338\n",
      "Episode: 4184 \tReward: 17.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002322393\n",
      "Episode: 4185 \tReward: 8.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002315946\n",
      "Episode: 4186 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000230781\n",
      "Episode: 4187 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002300573\n",
      "Episode: 4188 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002276773\n",
      "Episode: 4189 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002255425\n",
      "Episode: 4190 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000224831\n",
      "Episode: 4191 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002241978\n",
      "Episode: 4192 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000022362\n",
      "Episode: 4193 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000222625\n",
      "Episode: 4194 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000220423\n",
      "Episode: 4195 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002197628\n",
      "Episode: 4196 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002189162\n",
      "Episode: 4197 \tReward: 6.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002184\n",
      "Episode: 4198 \tReward: 17.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000217311\n",
      "Episode: 4199 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000216478\n",
      "Episode: 4200 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002158423\n",
      "Episode: 4201 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000214783\n",
      "Episode: 4202 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002140198\n",
      "Episode: 4203 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000213127\n",
      "Episode: 4204 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002121956\n",
      "Episode: 4205 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002114587\n",
      "Episode: 4206 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000210492\n",
      "Episode: 4207 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002094256\n",
      "Episode: 4208 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002087147\n",
      "Episode: 4209 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002081644\n",
      "Episode: 4210 \tReward: 3.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002075493\n",
      "Episode: 4211 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002066504\n",
      "Episode: 4212 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002042956\n",
      "Episode: 4213 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002038793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4214 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002031997\n",
      "Episode: 4215 \tReward: 5.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000202741\n",
      "Episode: 4216 \tReward: 17.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000002014514\n",
      "Episode: 4217 \tReward: 11.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000200796\n",
      "Episode: 4218 \tReward: 12.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001998662\n",
      "Episode: 4219 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001993236\n",
      "Episode: 4220 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001985038\n",
      "Episode: 4221 \tReward: 16.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000197502\n",
      "Episode: 4222 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001942388\n",
      "Episode: 4223 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001933978\n",
      "Episode: 4224 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001925446\n",
      "Episode: 4225 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001918223\n",
      "Episode: 4226 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001912516\n",
      "Episode: 4227 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001903318\n",
      "Episode: 4228 \tReward: 5.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000189921\n",
      "Episode: 4229 \tReward: 6.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001890495\n",
      "Episode: 4230 \tReward: 7.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001885437\n",
      "Episode: 4231 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001877384\n",
      "Episode: 4232 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001870338\n",
      "Episode: 4233 \tReward: 5.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001866525\n",
      "Episode: 4234 \tReward: 7.0 \tMean: 9.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000186179\n",
      "Episode: 4235 \tReward: 13.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000185332\n",
      "Episode: 4236 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000184548\n",
      "Episode: 4237 \tReward: 11.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001825034\n",
      "Episode: 4238 \tReward: 10.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000181975\n",
      "Episode: 4239 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000181477\n",
      "Episode: 4240 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001808068\n",
      "Episode: 4241 \tReward: 13.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000180067\n",
      "Episode: 4242 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000179144\n",
      "Episode: 4243 \tReward: 8.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001786537\n",
      "Episode: 4244 \tReward: 5.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000178236\n",
      "Episode: 4245 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001776274\n",
      "Episode: 4246 \tReward: 12.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000176876\n",
      "Episode: 4247 \tReward: 12.0 \tMean: 10.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000176131\n",
      "Episode: 4248 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000175551\n",
      "Episode: 4249 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001747977\n",
      "Episode: 4250 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000174295\n",
      "Episode: 4251 \tReward: 19.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000170888\n",
      "Episode: 4252 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001703454\n",
      "Episode: 4253 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001692723\n",
      "Episode: 4254 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000168836\n",
      "Episode: 4255 \tReward: 20.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001678297\n",
      "Episode: 4256 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001671864\n",
      "Episode: 4257 \tReward: 15.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001664756\n",
      "Episode: 4258 \tReward: 15.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001649247\n",
      "Episode: 4259 \tReward: 6.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001645687\n",
      "Episode: 4260 \tReward: 17.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000162827\n",
      "Episode: 4261 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001620798\n",
      "Episode: 4262 \tReward: 11.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001615295\n",
      "Episode: 4263 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001608367\n",
      "Episode: 4264 \tReward: 19.0 \tMean: 14.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001598586\n",
      "Episode: 4265 \tReward: 12.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001592553\n",
      "Episode: 4266 \tReward: 8.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001587658\n",
      "Episode: 4267 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000158198\n",
      "Episode: 4268 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001577086\n",
      "Episode: 4269 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001569724\n",
      "Episode: 4270 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001560676\n",
      "Episode: 4271 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001555315\n",
      "Episode: 4272 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000155004\n",
      "Episode: 4273 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001543294\n",
      "Episode: 4274 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001536455\n",
      "Episode: 4275 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000153124\n",
      "Episode: 4276 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001526044\n",
      "Episode: 4277 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000151816\n",
      "Episode: 4278 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001514067\n",
      "Episode: 4279 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001508745\n",
      "Episode: 4280 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001502753\n",
      "Episode: 4281 \tReward: 5.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000149942\n",
      "Episode: 4282 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001494718\n",
      "Episode: 4283 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000148929\n",
      "Episode: 4284 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001483373\n",
      "Episode: 4285 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001477954\n",
      "Episode: 4286 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001472465\n",
      "Episode: 4287 \tReward: 18.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001457845\n",
      "Episode: 4288 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001453216\n",
      "Episode: 4289 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001448484\n",
      "Episode: 4290 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001443193\n",
      "Episode: 4291 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001437174\n",
      "Episode: 4292 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001432382\n",
      "Episode: 4293 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000142632\n",
      "Episode: 4294 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001422675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4295 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000141932\n",
      "Episode: 4296 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000141439\n",
      "Episode: 4297 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000140928\n",
      "Episode: 4298 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000140441\n",
      "Episode: 4299 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000139945\n",
      "Episode: 4300 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000139375\n",
      "Episode: 4301 \tReward: 15.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000138716\n",
      "Episode: 4302 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001381347\n",
      "Episode: 4303 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001375667\n",
      "Episode: 4304 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000136938\n",
      "Episode: 4305 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001363014\n",
      "Episode: 4306 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000135866\n",
      "Episode: 4307 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001353532\n",
      "Episode: 4308 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001349424\n",
      "Episode: 4309 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000013442\n",
      "Episode: 4310 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001339047\n",
      "Episode: 4311 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001331678\n",
      "Episode: 4312 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001328698\n",
      "Episode: 4313 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001323074\n",
      "Episode: 4314 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000131848\n",
      "Episode: 4315 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001313977\n",
      "Episode: 4316 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001308967\n",
      "Episode: 4317 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001304526\n",
      "Episode: 4318 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001298486\n",
      "Episode: 4319 \tReward: 20.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000129149\n",
      "Episode: 4320 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001286492\n",
      "Episode: 4321 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001280254\n",
      "Episode: 4322 \tReward: 17.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000012741\n",
      "Episode: 4323 \tReward: 8.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001270713\n",
      "Episode: 4324 \tReward: 8.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000126729\n",
      "Episode: 4325 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001263063\n",
      "Episode: 4326 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001258147\n",
      "Episode: 4327 \tReward: 7.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000125488\n",
      "Episode: 4328 \tReward: 5.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000125227\n",
      "Episode: 4329 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001247274\n",
      "Episode: 4330 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001241622\n",
      "Episode: 4331 \tReward: 6.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000123877\n",
      "Episode: 4332 \tReward: 10.0 \tMean: 9.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001234714\n",
      "Episode: 4333 \tReward: 12.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001219986\n",
      "Episode: 4334 \tReward: 16.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001214314\n",
      "Episode: 4335 \tReward: 16.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001208256\n",
      "Episode: 4336 \tReward: 5.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000120589\n",
      "Episode: 4337 \tReward: 18.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001199662\n",
      "Episode: 4338 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000119583\n",
      "Episode: 4339 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001191173\n",
      "Episode: 4340 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001187488\n",
      "Episode: 4341 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000118272\n",
      "Episode: 4342 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001174873\n",
      "Episode: 4343 \tReward: 8.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001171327\n",
      "Episode: 4344 \tReward: 18.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000116502\n",
      "Episode: 4345 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001159767\n",
      "Episode: 4346 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000115581\n",
      "Episode: 4347 \tReward: 5.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000115306\n",
      "Episode: 4348 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001148616\n",
      "Episode: 4349 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001144765\n",
      "Episode: 4350 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001141563\n",
      "Episode: 4351 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000113787\n",
      "Episode: 4352 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001134395\n",
      "Episode: 4353 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001130815\n",
      "Episode: 4354 \tReward: 8.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001126055\n",
      "Episode: 4355 \tReward: 13.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001121492\n",
      "Episode: 4356 \tReward: 20.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000111445\n",
      "Episode: 4357 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000111022\n",
      "Episode: 4358 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000110592\n",
      "Episode: 4359 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001101793\n",
      "Episode: 4360 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001097966\n",
      "Episode: 4361 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001093473\n",
      "Episode: 4362 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001088543\n",
      "Episode: 4363 \tReward: 17.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001072677\n",
      "Episode: 4364 \tReward: 20.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001062345\n",
      "Episode: 4365 \tReward: 5.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000106018\n",
      "Episode: 4366 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001056877\n",
      "Episode: 4367 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001052322\n",
      "Episode: 4368 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001048266\n",
      "Episode: 4369 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000104429\n",
      "Episode: 4370 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001036612\n",
      "Episode: 4371 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000103303\n",
      "Episode: 4372 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000102922\n",
      "Episode: 4373 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001026752\n",
      "Episode: 4374 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001020056\n",
      "Episode: 4375 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001016045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4376 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001012416\n",
      "Episode: 4377 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000010091\n",
      "Episode: 4378 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000001004912\n",
      "Episode: 4379 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000100062\n",
      "Episode: 4380 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000099764\n",
      "Episode: 4381 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000993678\n",
      "Episode: 4382 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000009892\n",
      "Episode: 4383 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000098523\n",
      "Episode: 4384 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000981788\n",
      "Episode: 4385 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000977673\n",
      "Episode: 4386 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000974547\n",
      "Episode: 4387 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000971376\n",
      "Episode: 4388 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000967768\n",
      "Episode: 4389 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000096489\n",
      "Episode: 4390 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000096148\n",
      "Episode: 4391 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000095768\n",
      "Episode: 4392 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000954126\n",
      "Episode: 4393 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000951076\n",
      "Episode: 4394 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000947243\n",
      "Episode: 4395 \tReward: 18.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000094248\n",
      "Episode: 4396 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000093806\n",
      "Episode: 4397 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000934128\n",
      "Episode: 4398 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000928466\n",
      "Episode: 4399 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000092515\n",
      "Episode: 4400 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000922027\n",
      "Episode: 4401 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000917298\n",
      "Episode: 4402 \tReward: 5.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000915376\n",
      "Episode: 4403 \tReward: 6.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000913055\n",
      "Episode: 4404 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000910793\n",
      "Episode: 4405 \tReward: 8.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000009081\n",
      "Episode: 4406 \tReward: 12.0 \tMean: 9.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000090442\n",
      "Episode: 4407 \tReward: 10.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000901477\n",
      "Episode: 4408 \tReward: 10.0 \tMean: 9.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000089847\n",
      "Episode: 4409 \tReward: 12.0 \tMean: 9.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000895333\n",
      "Episode: 4410 \tReward: 7.0 \tMean: 9.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000892776\n",
      "Episode: 4411 \tReward: 8.0 \tMean: 8.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000890385\n",
      "Episode: 4412 \tReward: 10.0 \tMean: 9.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000887592\n",
      "Episode: 4413 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000883908\n",
      "Episode: 4414 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000879554\n",
      "Episode: 4415 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000876515\n",
      "Episode: 4416 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000872948\n",
      "Episode: 4417 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000868403\n",
      "Episode: 4418 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000865072\n",
      "Episode: 4419 \tReward: 5.0 \tMean: 10.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000863345\n",
      "Episode: 4420 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000085997\n",
      "Episode: 4421 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000854976\n",
      "Episode: 4422 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000085148\n",
      "Episode: 4423 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000008484\n",
      "Episode: 4424 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000084481\n",
      "Episode: 4425 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000840564\n",
      "Episode: 4426 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000837494\n",
      "Episode: 4427 \tReward: 17.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000083375\n",
      "Episode: 4428 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000830756\n",
      "Episode: 4429 \tReward: 14.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000827092\n",
      "Episode: 4430 \tReward: 16.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000822703\n",
      "Episode: 4431 \tReward: 12.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000819647\n",
      "Episode: 4432 \tReward: 9.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000008169\n",
      "Episode: 4433 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000813686\n",
      "Episode: 4434 \tReward: 18.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000809384\n",
      "Episode: 4435 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000079893\n",
      "Episode: 4436 \tReward: 19.0 \tMean: 13.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000793786\n",
      "Episode: 4437 \tReward: 7.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000791805\n",
      "Episode: 4438 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000788897\n",
      "Episode: 4439 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000786188\n",
      "Episode: 4440 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000783596\n",
      "Episode: 4441 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000781094\n",
      "Episode: 4442 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000007776\n",
      "Episode: 4443 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000775956\n",
      "Episode: 4444 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000077093\n",
      "Episode: 4445 \tReward: 19.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000766776\n",
      "Episode: 4446 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000763806\n",
      "Episode: 4447 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000760864\n",
      "Episode: 4448 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000075801\n",
      "Episode: 4449 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000755948\n",
      "Episode: 4450 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000753082\n",
      "Episode: 4451 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000749654\n",
      "Episode: 4452 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000746334\n",
      "Episode: 4453 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000074276\n",
      "Episode: 4454 \tReward: 8.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000740537\n",
      "Episode: 4455 \tReward: 15.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000007373\n",
      "Episode: 4456 \tReward: 7.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000735357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4457 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000733476\n",
      "Episode: 4458 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000073084\n",
      "Episode: 4459 \tReward: 6.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000729087\n",
      "Episode: 4460 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000072696\n",
      "Episode: 4461 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000072358\n",
      "Episode: 4462 \tReward: 14.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000720435\n",
      "Episode: 4463 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000717284\n",
      "Episode: 4464 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000714693\n",
      "Episode: 4465 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000711414\n",
      "Episode: 4466 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000706057\n",
      "Episode: 4467 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000703743\n",
      "Episode: 4468 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000701564\n",
      "Episode: 4469 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000069973\n",
      "Episode: 4470 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000695767\n",
      "Episode: 4471 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000692436\n",
      "Episode: 4472 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000689393\n",
      "Episode: 4473 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000068516\n",
      "Episode: 4474 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000068311\n",
      "Episode: 4475 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000068071\n",
      "Episode: 4476 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000678086\n",
      "Episode: 4477 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000675137\n",
      "Episode: 4478 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000673087\n",
      "Episode: 4479 \tReward: 19.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000669663\n",
      "Episode: 4480 \tReward: 6.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000066794\n",
      "Episode: 4481 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000006649\n",
      "Episode: 4482 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000066218\n",
      "Episode: 4483 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000660392\n",
      "Episode: 4484 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000065785\n",
      "Episode: 4485 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000656153\n",
      "Episode: 4486 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000065399\n",
      "Episode: 4487 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000065172\n",
      "Episode: 4488 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000648728\n",
      "Episode: 4489 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000064593\n",
      "Episode: 4490 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000643947\n",
      "Episode: 4491 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000641567\n",
      "Episode: 4492 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000638726\n",
      "Episode: 4493 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000063639\n",
      "Episode: 4494 \tReward: 7.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000634663\n",
      "Episode: 4495 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000632307\n",
      "Episode: 4496 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000629983\n",
      "Episode: 4497 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000062747\n",
      "Episode: 4498 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000006251\n",
      "Episode: 4499 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000622943\n",
      "Episode: 4500 \tReward: 17.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000617274\n",
      "Episode: 4501 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000061587\n",
      "Episode: 4502 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000061347\n",
      "Episode: 4503 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000061122\n",
      "Episode: 4504 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000006088\n",
      "Episode: 4505 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000060744\n",
      "Episode: 4506 \tReward: 4.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000606383\n",
      "Episode: 4507 \tReward: 15.0 \tMean: 10.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000060348\n",
      "Episode: 4508 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000601145\n",
      "Episode: 4509 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000059932\n",
      "Episode: 4510 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000597117\n",
      "Episode: 4511 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000594664\n",
      "Episode: 4512 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000593\n",
      "Episode: 4513 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000590868\n",
      "Episode: 4514 \tReward: 18.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000586805\n",
      "Episode: 4515 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000584568\n",
      "Episode: 4516 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000582212\n",
      "Episode: 4517 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000579853\n",
      "Episode: 4518 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000578232\n",
      "Episode: 4519 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000057681\n",
      "Episode: 4520 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000574152\n",
      "Episode: 4521 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000571564\n",
      "Episode: 4522 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000569895\n",
      "Episode: 4523 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000567328\n",
      "Episode: 4524 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000565763\n",
      "Episode: 4525 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000563595\n",
      "Episode: 4526 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000056165\n",
      "Episode: 4527 \tReward: 17.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000558814\n",
      "Episode: 4528 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000556916\n",
      "Episode: 4529 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000554814\n",
      "Episode: 4530 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000552954\n",
      "Episode: 4531 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000550966\n",
      "Episode: 4532 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000548756\n",
      "Episode: 4533 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000546542\n",
      "Episode: 4534 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000541876\n",
      "Episode: 4535 \tReward: 18.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000053927\n",
      "Episode: 4536 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000537428\n",
      "Episode: 4537 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000535346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4538 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000531124\n",
      "Episode: 4539 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000528474\n",
      "Episode: 4540 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000526416\n",
      "Episode: 4541 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000524515\n",
      "Episode: 4542 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000522725\n",
      "Episode: 4543 \tReward: 20.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000519703\n",
      "Episode: 4544 \tReward: 16.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000517357\n",
      "Episode: 4545 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000051587\n",
      "Episode: 4546 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000513832\n",
      "Episode: 4547 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000051039\n",
      "Episode: 4548 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000050615\n",
      "Episode: 4549 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000050319\n",
      "Episode: 4550 \tReward: 9.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000501384\n",
      "Episode: 4551 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000499753\n",
      "Episode: 4552 \tReward: 17.0 \tMean: 13.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000491614\n",
      "Episode: 4553 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000048972\n",
      "Episode: 4554 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000048836\n",
      "Episode: 4555 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000048683\n",
      "Episode: 4556 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000484595\n",
      "Episode: 4557 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000048237\n",
      "Episode: 4558 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000048035\n",
      "Episode: 4559 \tReward: 18.0 \tMean: 12.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000047615\n",
      "Episode: 4560 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000474583\n",
      "Episode: 4561 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000472667\n",
      "Episode: 4562 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000470895\n",
      "Episode: 4563 \tReward: 19.0 \tMean: 13.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000468452\n",
      "Episode: 4564 \tReward: 15.0 \tMean: 13.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000466416\n",
      "Episode: 4565 \tReward: 12.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000046446\n",
      "Episode: 4566 \tReward: 20.0 \tMean: 14.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000045781\n",
      "Episode: 4567 \tReward: 14.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000004556\n",
      "Episode: 4568 \tReward: 11.0 \tMean: 14.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000045411\n",
      "Episode: 4569 \tReward: 9.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000452694\n",
      "Episode: 4570 \tReward: 13.0 \tMean: 13.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000448808\n",
      "Episode: 4571 \tReward: 10.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000447184\n",
      "Episode: 4572 \tReward: 11.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000004449\n",
      "Episode: 4573 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000443205\n",
      "Episode: 4574 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000441612\n",
      "Episode: 4575 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000439937\n",
      "Episode: 4576 \tReward: 6.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000438927\n",
      "Episode: 4577 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000043756\n",
      "Episode: 4578 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000043596\n",
      "Episode: 4579 \tReward: 15.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000434056\n",
      "Episode: 4580 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000432106\n",
      "Episode: 4581 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000430295\n",
      "Episode: 4582 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000042864\n",
      "Episode: 4583 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000427037\n",
      "Episode: 4584 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000424942\n",
      "Episode: 4585 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000423304\n",
      "Episode: 4586 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000042154\n",
      "Episode: 4587 \tReward: 5.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000416945\n",
      "Episode: 4588 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000415713\n",
      "Episode: 4589 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000414044\n",
      "Episode: 4590 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000041225\n",
      "Episode: 4591 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000410655\n",
      "Episode: 4592 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000408778\n",
      "Episode: 4593 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000407758\n",
      "Episode: 4594 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000406033\n",
      "Episode: 4595 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000404354\n",
      "Episode: 4596 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000402404\n",
      "Episode: 4597 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000040089\n",
      "Episode: 4598 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000399542\n",
      "Episode: 4599 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000039855\n",
      "Episode: 4600 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000039695\n",
      "Episode: 4601 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000039593\n",
      "Episode: 4602 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000393474\n",
      "Episode: 4603 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000039238\n",
      "Episode: 4604 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000389054\n",
      "Episode: 4605 \tReward: 18.0 \tMean: 11.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000038704\n",
      "Episode: 4606 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000385668\n",
      "Episode: 4607 \tReward: 4.0 \tMean: 10.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000384988\n",
      "Episode: 4608 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000038264\n",
      "Episode: 4609 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000038103\n",
      "Episode: 4610 \tReward: 8.0 \tMean: 9.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000379894\n",
      "Episode: 4611 \tReward: 18.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000375415\n",
      "Episode: 4612 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000373806\n",
      "Episode: 4613 \tReward: 18.0 \tMean: 11.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000371828\n",
      "Episode: 4614 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000003705\n",
      "Episode: 4615 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000036939\n",
      "Episode: 4616 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000367033\n",
      "Episode: 4617 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000036527\n",
      "Episode: 4618 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.0200000000003642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4619 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000036274\n",
      "Episode: 4620 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000361482\n",
      "Episode: 4621 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000360098\n",
      "Episode: 4622 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000035858\n",
      "Episode: 4623 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000357343\n",
      "Episode: 4624 \tReward: 18.0 \tMean: 11.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000355445\n",
      "Episode: 4625 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000354175\n",
      "Episode: 4626 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000352975\n",
      "Episode: 4627 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000351494\n",
      "Episode: 4628 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000350168\n",
      "Episode: 4629 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000348694\n",
      "Episode: 4630 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000346234\n",
      "Episode: 4631 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000345217\n",
      "Episode: 4632 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000034361\n",
      "Episode: 4633 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000342077\n",
      "Episode: 4634 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.02000000000034078\n",
      "Episode: 4635 \tReward: 22.0 \tMean: 13.4 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000338417\n",
      "Episode: 4636 \tReward: 15.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000336936\n",
      "Episode: 4637 \tReward: 15.0 \tMean: 14.1 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000335395\n",
      "Episode: 4638 \tReward: 14.0 \tMean: 14.2 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000333997\n",
      "Episode: 4639 \tReward: 13.0 \tMean: 14.0 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000332672\n",
      "Episode: 4640 \tReward: 20.0 \tMean: 14.6 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000330583\n",
      "Episode: 4641 \tReward: 18.0 \tMean: 15.5 \tBestMean: 15.2 \tTRAIN START: True \tEpsi: 0.020000000000328474\n",
      "Episode: 4642 \tReward: 8.0 \tMean: 14.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000327568\n",
      "Episode: 4643 \tReward: 10.0 \tMean: 14.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000032645\n",
      "Episode: 4644 \tReward: 12.0 \tMean: 14.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000325178\n",
      "Episode: 4645 \tReward: 13.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000323887\n",
      "Episode: 4646 \tReward: 11.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000322583\n",
      "Episode: 4647 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000321337\n",
      "Episode: 4648 \tReward: 14.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000003178\n",
      "Episode: 4649 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000316123\n",
      "Episode: 4650 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000313958\n",
      "Episode: 4651 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000003127\n",
      "Episode: 4652 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000031159\n",
      "Episode: 4653 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000031005\n",
      "Episode: 4654 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000308535\n",
      "Episode: 4655 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000307504\n",
      "Episode: 4656 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000306377\n",
      "Episode: 4657 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000305128\n",
      "Episode: 4658 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000303778\n",
      "Episode: 4659 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000030294\n",
      "Episode: 4660 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000301617\n",
      "Episode: 4661 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000298616\n",
      "Episode: 4662 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000029778\n",
      "Episode: 4663 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000295264\n",
      "Episode: 4664 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000029408\n",
      "Episode: 4665 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000292794\n",
      "Episode: 4666 \tReward: 17.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000029144\n",
      "Episode: 4667 \tReward: 17.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000290022\n",
      "Episode: 4668 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000028849\n",
      "Episode: 4669 \tReward: 11.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000287482\n",
      "Episode: 4670 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000028637\n",
      "Episode: 4671 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000028518\n",
      "Episode: 4672 \tReward: 15.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000283763\n",
      "Episode: 4673 \tReward: 12.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000028268\n",
      "Episode: 4674 \tReward: 17.0 \tMean: 14.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000281185\n",
      "Episode: 4675 \tReward: 9.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000028026\n",
      "Episode: 4676 \tReward: 13.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000279135\n",
      "Episode: 4677 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000027623\n",
      "Episode: 4678 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000275502\n",
      "Episode: 4679 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000027466\n",
      "Episode: 4680 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000027356\n",
      "Episode: 4681 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000272286\n",
      "Episode: 4682 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000027154\n",
      "Episode: 4683 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000270548\n",
      "Episode: 4684 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000269164\n",
      "Episode: 4685 \tReward: 5.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000026861\n",
      "Episode: 4686 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000267488\n",
      "Episode: 4687 \tReward: 8.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000266683\n",
      "Episode: 4688 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000265257\n",
      "Episode: 4689 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000264213\n",
      "Episode: 4690 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000263373\n",
      "Episode: 4691 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000262384\n",
      "Episode: 4692 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000261444\n",
      "Episode: 4693 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000260587\n",
      "Episode: 4694 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000259748\n",
      "Episode: 4695 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000025781\n",
      "Episode: 4696 \tReward: 16.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000256604\n",
      "Episode: 4697 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000255605\n",
      "Episode: 4698 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000025462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4699 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000253388\n",
      "Episode: 4700 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000252167\n",
      "Episode: 4701 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000251372\n",
      "Episode: 4702 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000249953\n",
      "Episode: 4703 \tReward: 20.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000248604\n",
      "Episode: 4704 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000247698\n",
      "Episode: 4705 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000024687\n",
      "Episode: 4706 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000245852\n",
      "Episode: 4707 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000245096\n",
      "Episode: 4708 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000024444\n",
      "Episode: 4709 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000243618\n",
      "Episode: 4710 \tReward: 21.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000024214\n",
      "Episode: 4711 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000241443\n",
      "Episode: 4712 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000240697\n",
      "Episode: 4713 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000239777\n",
      "Episode: 4714 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000023892\n",
      "Episode: 4715 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000237696\n",
      "Episode: 4716 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000023683\n",
      "Episode: 4717 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000235826\n",
      "Episode: 4718 \tReward: 16.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000234684\n",
      "Episode: 4719 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000234042\n",
      "Episode: 4720 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000233133\n",
      "Episode: 4721 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000002322\n",
      "Episode: 4722 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000023136\n",
      "Episode: 4723 \tReward: 20.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000023007\n",
      "Episode: 4724 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000229178\n",
      "Episode: 4725 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000228117\n",
      "Episode: 4726 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000227145\n",
      "Episode: 4727 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000226205\n",
      "Episode: 4728 \tReward: 17.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000022511\n",
      "Episode: 4729 \tReward: 17.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000022395\n",
      "Episode: 4730 \tReward: 16.0 \tMean: 14.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000222833\n",
      "Episode: 4731 \tReward: 17.0 \tMean: 14.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000221743\n",
      "Episode: 4732 \tReward: 10.0 \tMean: 14.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000022096\n",
      "Episode: 4733 \tReward: 13.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000220113\n",
      "Episode: 4734 \tReward: 4.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000219703\n",
      "Episode: 4735 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000219013\n",
      "Episode: 4736 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000218305\n",
      "Episode: 4737 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000217778\n",
      "Episode: 4738 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000217056\n",
      "Episode: 4739 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000021609\n",
      "Episode: 4740 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000021517\n",
      "Episode: 4741 \tReward: 14.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000021319\n",
      "Episode: 4742 \tReward: 17.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000212115\n",
      "Episode: 4743 \tReward: 17.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000211078\n",
      "Episode: 4744 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000210343\n",
      "Episode: 4745 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000209257\n",
      "Episode: 4746 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000020844\n",
      "Episode: 4747 \tReward: 13.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000020754\n",
      "Episode: 4748 \tReward: 14.0 \tMean: 14.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000206644\n",
      "Episode: 4749 \tReward: 10.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000205874\n",
      "Episode: 4750 \tReward: 17.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000020478\n",
      "Episode: 4751 \tReward: 13.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000203938\n",
      "Episode: 4752 \tReward: 17.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000203005\n",
      "Episode: 4753 \tReward: 5.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000020257\n",
      "Episode: 4754 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000020186\n",
      "Episode: 4755 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000201093\n",
      "Episode: 4756 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000200416\n",
      "Episode: 4757 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000001995\n",
      "Episode: 4758 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000019869\n",
      "Episode: 4759 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000019799\n",
      "Episode: 4760 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000197214\n",
      "Episode: 4761 \tReward: 4.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000196853\n",
      "Episode: 4762 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000019617\n",
      "Episode: 4763 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000195632\n",
      "Episode: 4764 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000194983\n",
      "Episode: 4765 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000194335\n",
      "Episode: 4766 \tReward: 17.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000019317\n",
      "Episode: 4767 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000192503\n",
      "Episode: 4768 \tReward: 19.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000019134\n",
      "Episode: 4769 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000189384\n",
      "Episode: 4770 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000188776\n",
      "Episode: 4771 \tReward: 19.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000187777\n",
      "Episode: 4772 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000018683\n",
      "Episode: 4773 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000001855\n",
      "Episode: 4774 \tReward: 8.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000018488\n",
      "Episode: 4775 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000184186\n",
      "Episode: 4776 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000018347\n",
      "Episode: 4777 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000018296\n",
      "Episode: 4778 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000182178\n",
      "Episode: 4779 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000001814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4780 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000180762\n",
      "Episode: 4781 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000180134\n",
      "Episode: 4782 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000017833\n",
      "Episode: 4783 \tReward: 18.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000177355\n",
      "Episode: 4784 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000175922\n",
      "Episode: 4785 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000175395\n",
      "Episode: 4786 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000001747\n",
      "Episode: 4787 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000174253\n",
      "Episode: 4788 \tReward: 8.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000173792\n",
      "Episode: 4789 \tReward: 5.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000173445\n",
      "Episode: 4790 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000017215\n",
      "Episode: 4791 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000017154\n",
      "Episode: 4792 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000170888\n",
      "Episode: 4793 \tReward: 9.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000170305\n",
      "Episode: 4794 \tReward: 10.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000016974\n",
      "Episode: 4795 \tReward: 19.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000168817\n",
      "Episode: 4796 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000168064\n",
      "Episode: 4797 \tReward: 5.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000167717\n",
      "Episode: 4798 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000167165\n",
      "Episode: 4799 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000166593\n",
      "Episode: 4800 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000165757\n",
      "Episode: 4801 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000165167\n",
      "Episode: 4802 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000164404\n",
      "Episode: 4803 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000163626\n",
      "Episode: 4804 \tReward: 15.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000016251\n",
      "Episode: 4805 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000016201\n",
      "Episode: 4806 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000161357\n",
      "Episode: 4807 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000016084\n",
      "Episode: 4808 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000160233\n",
      "Episode: 4809 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000159657\n",
      "Episode: 4810 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000159005\n",
      "Episode: 4811 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000015833\n",
      "Episode: 4812 \tReward: 23.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000015737\n",
      "Episode: 4813 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000015676\n",
      "Episode: 4814 \tReward: 17.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000154453\n",
      "Episode: 4815 \tReward: 9.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000153645\n",
      "Episode: 4816 \tReward: 12.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000015309\n",
      "Episode: 4817 \tReward: 8.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000151834\n",
      "Episode: 4818 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000151306\n",
      "Episode: 4819 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000149714\n",
      "Episode: 4820 \tReward: 18.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000148257\n",
      "Episode: 4821 \tReward: 12.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000147716\n",
      "Episode: 4822 \tReward: 17.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000146994\n",
      "Episode: 4823 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000146557\n",
      "Episode: 4824 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000144156\n",
      "Episode: 4825 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000014371\n",
      "Episode: 4826 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000014315\n",
      "Episode: 4827 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000142668\n",
      "Episode: 4828 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000014209\n",
      "Episode: 4829 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000141533\n",
      "Episode: 4830 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000140256\n",
      "Episode: 4831 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000139486\n",
      "Episode: 4832 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000013876\n",
      "Episode: 4833 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000138202\n",
      "Episode: 4834 \tReward: 8.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000013783\n",
      "Episode: 4835 \tReward: 17.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000013717\n",
      "Episode: 4836 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000001366\n",
      "Episode: 4837 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000136242\n",
      "Episode: 4838 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000135625\n",
      "Episode: 4839 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000134834\n",
      "Episode: 4840 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000134393\n",
      "Episode: 4841 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000133803\n",
      "Episode: 4842 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000133394\n",
      "Episode: 4843 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000132953\n",
      "Episode: 4844 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000013231\n",
      "Episode: 4845 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000132027\n",
      "Episode: 4846 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000131406\n",
      "Episode: 4847 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000013075\n",
      "Episode: 4848 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000130413\n",
      "Episode: 4849 \tReward: 16.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000129796\n",
      "Episode: 4850 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000129373\n",
      "Episode: 4851 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012886\n",
      "Episode: 4852 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000128287\n",
      "Episode: 4853 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000127922\n",
      "Episode: 4854 \tReward: 7.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000127565\n",
      "Episode: 4855 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012715\n",
      "Episode: 4856 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000126642\n",
      "Episode: 4857 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000126146\n",
      "Episode: 4858 \tReward: 4.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012591\n",
      "Episode: 4859 \tReward: 14.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000123336\n",
      "Episode: 4860 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4861 \tReward: 6.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000121747\n",
      "Episode: 4862 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012123\n",
      "Episode: 4863 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012089\n",
      "Episode: 4864 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000012043\n",
      "Episode: 4865 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000119922\n",
      "Episode: 4866 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000119485\n",
      "Episode: 4867 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000119027\n",
      "Episode: 4868 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000011848\n",
      "Episode: 4869 \tReward: 5.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000118257\n",
      "Episode: 4870 \tReward: 14.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000117726\n",
      "Episode: 4871 \tReward: 16.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000116896\n",
      "Episode: 4872 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000116428\n",
      "Episode: 4873 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000115894\n",
      "Episode: 4874 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000115502\n",
      "Episode: 4875 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000115117\n",
      "Episode: 4876 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000011469\n",
      "Episode: 4877 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000114246\n",
      "Episode: 4878 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000113788\n",
      "Episode: 4879 \tReward: 1.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000011367\n",
      "Episode: 4880 \tReward: 7.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000113396\n",
      "Episode: 4881 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000112664\n",
      "Episode: 4882 \tReward: 13.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000112133\n",
      "Episode: 4883 \tReward: 8.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000111793\n",
      "Episode: 4884 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000111262\n",
      "Episode: 4885 \tReward: 10.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000110894\n",
      "Episode: 4886 \tReward: 18.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000110246\n",
      "Episode: 4887 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000010984\n",
      "Episode: 4888 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000109503\n",
      "Episode: 4889 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000010893\n",
      "Episode: 4890 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000106283\n",
      "Episode: 4891 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000105937\n",
      "Episode: 4892 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000010553\n",
      "Episode: 4893 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000105173\n",
      "Episode: 4894 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000104788\n",
      "Episode: 4895 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000010453\n",
      "Episode: 4896 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000103445\n",
      "Episode: 4897 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000103088\n",
      "Episode: 4898 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000102623\n",
      "Episode: 4899 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000100434\n",
      "Episode: 4900 \tReward: 17.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000099823\n",
      "Episode: 4901 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000099404\n",
      "Episode: 4902 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000098887\n",
      "Episode: 4903 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000098446\n",
      "Episode: 4904 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009794\n",
      "Episode: 4905 \tReward: 8.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000097662\n",
      "Episode: 4906 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009732\n",
      "Episode: 4907 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000096923\n",
      "Episode: 4908 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000096347\n",
      "Episode: 4909 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000095688\n",
      "Episode: 4910 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000095386\n",
      "Episode: 4911 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000094782\n",
      "Episode: 4912 \tReward: 3.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000094637\n",
      "Episode: 4913 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009435\n",
      "Episode: 4914 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000093963\n",
      "Episode: 4915 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000093613\n",
      "Episode: 4916 \tReward: 20.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009308\n",
      "Episode: 4917 \tReward: 17.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009265\n",
      "Episode: 4918 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000092368\n",
      "Episode: 4919 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000091864\n",
      "Episode: 4920 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009158\n",
      "Episode: 4921 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000009124\n",
      "Episode: 4922 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000090758\n",
      "Episode: 4923 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000090445\n",
      "Episode: 4924 \tReward: 7.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000090206\n",
      "Episode: 4925 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000089935\n",
      "Episode: 4926 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000089502\n",
      "Episode: 4927 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008923\n",
      "Episode: 4928 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008819\n",
      "Episode: 4929 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000087906\n",
      "Episode: 4930 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000087205\n",
      "Episode: 4931 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000086227\n",
      "Episode: 4932 \tReward: 16.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008581\n",
      "Episode: 4933 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000085515\n",
      "Episode: 4934 \tReward: 19.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000084613\n",
      "Episode: 4935 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000084263\n",
      "Episode: 4936 \tReward: 17.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000083673\n",
      "Episode: 4937 \tReward: 16.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008271\n",
      "Episode: 4938 \tReward: 10.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008243\n",
      "Episode: 4939 \tReward: 13.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000082133\n",
      "Episode: 4940 \tReward: 14.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4941 \tReward: 12.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000008123\n",
      "Episode: 4942 \tReward: 16.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000080505\n",
      "Episode: 4943 \tReward: 14.0 \tMean: 14.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000080176\n",
      "Episode: 4944 \tReward: 9.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000079964\n",
      "Episode: 4945 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000079655\n",
      "Episode: 4946 \tReward: 17.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000078604\n",
      "Episode: 4947 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007829\n",
      "Episode: 4948 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000077994\n",
      "Episode: 4949 \tReward: 16.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000076984\n",
      "Episode: 4950 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007672\n",
      "Episode: 4951 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007563\n",
      "Episode: 4952 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000075402\n",
      "Episode: 4953 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000751\n",
      "Episode: 4954 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007489\n",
      "Episode: 4955 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000074576\n",
      "Episode: 4956 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007398\n",
      "Episode: 4957 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000073757\n",
      "Episode: 4958 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000073546\n",
      "Episode: 4959 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000073327\n",
      "Episode: 4960 \tReward: 6.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000072557\n",
      "Episode: 4961 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000072325\n",
      "Episode: 4962 \tReward: 11.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000072078\n",
      "Episode: 4963 \tReward: 13.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000071776\n",
      "Episode: 4964 \tReward: 8.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000071554\n",
      "Episode: 4965 \tReward: 12.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000071277\n",
      "Episode: 4966 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000071044\n",
      "Episode: 4967 \tReward: 15.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000070725\n",
      "Episode: 4968 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000007047\n",
      "Episode: 4969 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000070222\n",
      "Episode: 4970 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000070038\n",
      "Episode: 4971 \tReward: 17.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000069677\n",
      "Episode: 4972 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000069434\n",
      "Episode: 4973 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000069157\n",
      "Episode: 4974 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000068918\n",
      "Episode: 4975 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006865\n",
      "Episode: 4976 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000068418\n",
      "Episode: 4977 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000068175\n",
      "Episode: 4978 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006782\n",
      "Episode: 4979 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006765\n",
      "Episode: 4980 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000067426\n",
      "Episode: 4981 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000067214\n",
      "Episode: 4982 \tReward: 12.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000066957\n",
      "Episode: 4983 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006668\n",
      "Episode: 4984 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006642\n",
      "Episode: 4985 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000066073\n",
      "Episode: 4986 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000065795\n",
      "Episode: 4987 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000065615\n",
      "Episode: 4988 \tReward: 6.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000065465\n",
      "Episode: 4989 \tReward: 6.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000065323\n",
      "Episode: 4990 \tReward: 17.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006458\n",
      "Episode: 4991 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006437\n",
      "Episode: 4992 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000064133\n",
      "Episode: 4993 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006393\n",
      "Episode: 4994 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000063693\n",
      "Episode: 4995 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006348\n",
      "Episode: 4996 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000063224\n",
      "Episode: 4997 \tReward: 15.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000062787\n",
      "Episode: 4998 \tReward: 17.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000062485\n",
      "Episode: 4999 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000062176\n",
      "Episode: 5000 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000061965\n",
      "Episode: 5001 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000061777\n",
      "Episode: 5002 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006157\n",
      "Episode: 5003 \tReward: 6.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006143\n",
      "Episode: 5004 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006126\n",
      "Episode: 5005 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000061083\n",
      "Episode: 5006 \tReward: 6.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000060938\n",
      "Episode: 5007 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000060747\n",
      "Episode: 5008 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000006036\n",
      "Episode: 5009 \tReward: 9.0 \tMean: 9.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000060154\n",
      "Episode: 5010 \tReward: 10.0 \tMean: 9.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005995\n",
      "Episode: 5011 \tReward: 10.0 \tMean: 9.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000059737\n",
      "Episode: 5012 \tReward: 13.0 \tMean: 9.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005946\n",
      "Episode: 5013 \tReward: 11.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005923\n",
      "Episode: 5014 \tReward: 13.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005899\n",
      "Episode: 5015 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000058787\n",
      "Episode: 5016 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000058575\n",
      "Episode: 5017 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000057836\n",
      "Episode: 5018 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000057642\n",
      "Episode: 5019 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000057413\n",
      "Episode: 5020 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000057246\n",
      "Episode: 5021 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000057007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5022 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005674\n",
      "Episode: 5023 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005656\n",
      "Episode: 5024 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000056372\n",
      "Episode: 5025 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000056157\n",
      "Episode: 5026 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005587\n",
      "Episode: 5027 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005571\n",
      "Episode: 5028 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000055466\n",
      "Episode: 5029 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000055272\n",
      "Episode: 5030 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005507\n",
      "Episode: 5031 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000054852\n",
      "Episode: 5032 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000054592\n",
      "Episode: 5033 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005432\n",
      "Episode: 5034 \tReward: 12.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000054134\n",
      "Episode: 5035 \tReward: 6.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000054002\n",
      "Episode: 5036 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005358\n",
      "Episode: 5037 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000053312\n",
      "Episode: 5038 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000053125\n",
      "Episode: 5039 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000052826\n",
      "Episode: 5040 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000052597\n",
      "Episode: 5041 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000052396\n",
      "Episode: 5042 \tReward: 20.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000052098\n",
      "Episode: 5043 \tReward: 8.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005156\n",
      "Episode: 5044 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000051345\n",
      "Episode: 5045 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000051192\n",
      "Episode: 5046 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000051005\n",
      "Episode: 5047 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000050776\n",
      "Episode: 5048 \tReward: 5.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005067\n",
      "Episode: 5049 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000050432\n",
      "Episode: 5050 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000005028\n",
      "Episode: 5051 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000049842\n",
      "Episode: 5052 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004964\n",
      "Episode: 5053 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000049433\n",
      "Episode: 5054 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000049277\n",
      "Episode: 5055 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000049107\n",
      "Episode: 5056 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004894\n",
      "Episode: 5057 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000048812\n",
      "Episode: 5058 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000048618\n",
      "Episode: 5059 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000047813\n",
      "Episode: 5060 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004767\n",
      "Episode: 5061 \tReward: 8.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004754\n",
      "Episode: 5062 \tReward: 12.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000047372\n",
      "Episode: 5063 \tReward: 13.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000047174\n",
      "Episode: 5064 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000046994\n",
      "Episode: 5065 \tReward: 19.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000046356\n",
      "Episode: 5066 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004619\n",
      "Episode: 5067 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000046043\n",
      "Episode: 5068 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004589\n",
      "Episode: 5069 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000045703\n",
      "Episode: 5070 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000045526\n",
      "Episode: 5071 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004534\n",
      "Episode: 5072 \tReward: 16.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004514\n",
      "Episode: 5073 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000044926\n",
      "Episode: 5074 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004477\n",
      "Episode: 5075 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000044618\n",
      "Episode: 5076 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000044475\n",
      "Episode: 5077 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000044323\n",
      "Episode: 5078 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004417\n",
      "Episode: 5079 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000044014\n",
      "Episode: 5080 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004378\n",
      "Episode: 5081 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000043632\n",
      "Episode: 5082 \tReward: 18.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000043403\n",
      "Episode: 5083 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000043212\n",
      "Episode: 5084 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004311\n",
      "Episode: 5085 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004295\n",
      "Episode: 5086 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004279\n",
      "Episode: 5087 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004262\n",
      "Episode: 5088 \tReward: 18.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000042376\n",
      "Episode: 5089 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000042144\n",
      "Episode: 5090 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000042005\n",
      "Episode: 5091 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000041845\n",
      "Episode: 5092 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004148\n",
      "Episode: 5093 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000041325\n",
      "Episode: 5094 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000004119\n",
      "Episode: 5095 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000041023\n",
      "Episode: 5096 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040867\n",
      "Episode: 5097 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040714\n",
      "Episode: 5098 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040548\n",
      "Episode: 5099 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040378\n",
      "Episode: 5100 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040263\n",
      "Episode: 5101 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000040118\n",
      "Episode: 5102 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000039958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5103 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000039823\n",
      "Episode: 5104 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000039674\n",
      "Episode: 5105 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000039535\n",
      "Episode: 5106 \tReward: 18.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003928\n",
      "Episode: 5107 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000039167\n",
      "Episode: 5108 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000038872\n",
      "Episode: 5109 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003851\n",
      "Episode: 5110 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000038366\n",
      "Episode: 5111 \tReward: 15.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000038192\n",
      "Episode: 5112 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003755\n",
      "Episode: 5113 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000037346\n",
      "Episode: 5114 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000037196\n",
      "Episode: 5115 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000037068\n",
      "Episode: 5116 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036957\n",
      "Episode: 5117 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036815\n",
      "Episode: 5118 \tReward: 4.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036745\n",
      "Episode: 5119 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003662\n",
      "Episode: 5120 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036516\n",
      "Episode: 5121 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036374\n",
      "Episode: 5122 \tReward: 16.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036187\n",
      "Episode: 5123 \tReward: 6.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000036114\n",
      "Episode: 5124 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000035947\n",
      "Episode: 5125 \tReward: 10.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000035822\n",
      "Episode: 5126 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003559\n",
      "Episode: 5127 \tReward: 12.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003546\n",
      "Episode: 5128 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000035302\n",
      "Episode: 5129 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000035142\n",
      "Episode: 5130 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000035028\n",
      "Episode: 5131 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000034872\n",
      "Episode: 5132 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003476\n",
      "Episode: 5133 \tReward: 8.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003466\n",
      "Episode: 5134 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000345\n",
      "Episode: 5135 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003435\n",
      "Episode: 5136 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000034223\n",
      "Episode: 5137 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000034115\n",
      "Episode: 5138 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033977\n",
      "Episode: 5139 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033862\n",
      "Episode: 5140 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033748\n",
      "Episode: 5141 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033616\n",
      "Episode: 5142 \tReward: 16.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033456\n",
      "Episode: 5143 \tReward: 10.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033255\n",
      "Episode: 5144 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000033113\n",
      "Episode: 5145 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032974\n",
      "Episode: 5146 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032835\n",
      "Episode: 5147 \tReward: 6.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032735\n",
      "Episode: 5148 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032582\n",
      "Episode: 5149 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032447\n",
      "Episode: 5150 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032315\n",
      "Episode: 5151 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000032214\n",
      "Episode: 5152 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003213\n",
      "Episode: 5153 \tReward: 18.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000031957\n",
      "Episode: 5154 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000031236\n",
      "Episode: 5155 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000031114\n",
      "Episode: 5156 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000030976\n",
      "Episode: 5157 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000030826\n",
      "Episode: 5158 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000030695\n",
      "Episode: 5159 \tReward: 12.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003058\n",
      "Episode: 5160 \tReward: 17.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003043\n",
      "Episode: 5161 \tReward: 11.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000030327\n",
      "Episode: 5162 \tReward: 11.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000003021\n",
      "Episode: 5163 \tReward: 10.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029914\n",
      "Episode: 5164 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029824\n",
      "Episode: 5165 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029695\n",
      "Episode: 5166 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029605\n",
      "Episode: 5167 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029505\n",
      "Episode: 5168 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029383\n",
      "Episode: 5169 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002929\n",
      "Episode: 5170 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029185\n",
      "Episode: 5171 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029113\n",
      "Episode: 5172 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000029005\n",
      "Episode: 5173 \tReward: 17.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028856\n",
      "Episode: 5174 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002874\n",
      "Episode: 5175 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028634\n",
      "Episode: 5176 \tReward: 4.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028585\n",
      "Episode: 5177 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028474\n",
      "Episode: 5178 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002839\n",
      "Episode: 5179 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028287\n",
      "Episode: 5180 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028183\n",
      "Episode: 5181 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000028075\n",
      "Episode: 5182 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5183 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000027912\n",
      "Episode: 5184 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000027777\n",
      "Episode: 5185 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000027433\n",
      "Episode: 5186 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000027336\n",
      "Episode: 5187 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000027256\n",
      "Episode: 5188 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002711\n",
      "Episode: 5189 \tReward: 17.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002696\n",
      "Episode: 5190 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026847\n",
      "Episode: 5191 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026764\n",
      "Episode: 5192 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026545\n",
      "Episode: 5193 \tReward: 5.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026493\n",
      "Episode: 5194 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026396\n",
      "Episode: 5195 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000026295\n",
      "Episode: 5196 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002614\n",
      "Episode: 5197 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002605\n",
      "Episode: 5198 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002597\n",
      "Episode: 5199 \tReward: 13.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002586\n",
      "Episode: 5200 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002573\n",
      "Episode: 5201 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000025636\n",
      "Episode: 5202 \tReward: 17.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000025518\n",
      "Episode: 5203 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002544\n",
      "Episode: 5204 \tReward: 19.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002514\n",
      "Episode: 5205 \tReward: 19.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024998\n",
      "Episode: 5206 \tReward: 11.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000249\n",
      "Episode: 5207 \tReward: 15.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024564\n",
      "Episode: 5208 \tReward: 16.0 \tMean: 14.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024457\n",
      "Episode: 5209 \tReward: 8.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024394\n",
      "Episode: 5210 \tReward: 14.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002429\n",
      "Episode: 5211 \tReward: 12.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024186\n",
      "Episode: 5212 \tReward: 12.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000024103\n",
      "Episode: 5213 \tReward: 10.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002393\n",
      "Episode: 5214 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023863\n",
      "Episode: 5215 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023787\n",
      "Episode: 5216 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023728\n",
      "Episode: 5217 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023655\n",
      "Episode: 5218 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023558\n",
      "Episode: 5219 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023502\n",
      "Episode: 5220 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023426\n",
      "Episode: 5221 \tReward: 14.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000023326\n",
      "Episode: 5222 \tReward: 13.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002323\n",
      "Episode: 5223 \tReward: 7.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002317\n",
      "Episode: 5224 \tReward: 14.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022992\n",
      "Episode: 5225 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022892\n",
      "Episode: 5226 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022815\n",
      "Episode: 5227 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000227\n",
      "Episode: 5228 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022625\n",
      "Episode: 5229 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022538\n",
      "Episode: 5230 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022475\n",
      "Episode: 5231 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022403\n",
      "Episode: 5232 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000223\n",
      "Episode: 5233 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000022233\n",
      "Episode: 5234 \tReward: 19.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002212\n",
      "Episode: 5235 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002204\n",
      "Episode: 5236 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000021875\n",
      "Episode: 5237 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000021792\n",
      "Episode: 5238 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000021723\n",
      "Episode: 5239 \tReward: 19.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002161\n",
      "Episode: 5240 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000021535\n",
      "Episode: 5241 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002144\n",
      "Episode: 5242 \tReward: 18.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002129\n",
      "Episode: 5243 \tReward: 15.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002117\n",
      "Episode: 5244 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002108\n",
      "Episode: 5245 \tReward: 14.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002095\n",
      "Episode: 5246 \tReward: 11.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002088\n",
      "Episode: 5247 \tReward: 16.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020782\n",
      "Episode: 5248 \tReward: 10.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020716\n",
      "Episode: 5249 \tReward: 15.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020553\n",
      "Episode: 5250 \tReward: 10.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020488\n",
      "Episode: 5251 \tReward: 11.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020415\n",
      "Episode: 5252 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020342\n",
      "Episode: 5253 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020272\n",
      "Episode: 5254 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000020193\n",
      "Episode: 5255 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000002011\n",
      "Episode: 5256 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001996\n",
      "Episode: 5257 \tReward: 22.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000019832\n",
      "Episode: 5258 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001959\n",
      "Episode: 5259 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001924\n",
      "Episode: 5260 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000019183\n",
      "Episode: 5261 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000191\n",
      "Episode: 5262 \tReward: 12.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000019034\n",
      "Episode: 5263 \tReward: 13.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5264 \tReward: 11.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001882\n",
      "Episode: 5265 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018652\n",
      "Episode: 5266 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001858\n",
      "Episode: 5267 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001849\n",
      "Episode: 5268 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018416\n",
      "Episode: 5269 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018354\n",
      "Episode: 5270 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001828\n",
      "Episode: 5271 \tReward: 6.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001824\n",
      "Episode: 5272 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018173\n",
      "Episode: 5273 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000018073\n",
      "Episode: 5274 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001802\n",
      "Episode: 5275 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001793\n",
      "Episode: 5276 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017868\n",
      "Episode: 5277 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017802\n",
      "Episode: 5278 \tReward: 15.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017573\n",
      "Episode: 5279 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001751\n",
      "Episode: 5280 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001735\n",
      "Episode: 5281 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000173\n",
      "Episode: 5282 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017237\n",
      "Episode: 5283 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017146\n",
      "Episode: 5284 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017063\n",
      "Episode: 5285 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000017015\n",
      "Episode: 5286 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001697\n",
      "Episode: 5287 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000169\n",
      "Episode: 5288 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016838\n",
      "Episode: 5289 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016754\n",
      "Episode: 5290 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001669\n",
      "Episode: 5291 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001663\n",
      "Episode: 5292 \tReward: 14.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016564\n",
      "Episode: 5293 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016466\n",
      "Episode: 5294 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016366\n",
      "Episode: 5295 \tReward: 6.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016324\n",
      "Episode: 5296 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016192\n",
      "Episode: 5297 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000016137\n",
      "Episode: 5298 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001604\n",
      "Episode: 5299 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001598\n",
      "Episode: 5300 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015863\n",
      "Episode: 5301 \tReward: 13.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015804\n",
      "Episode: 5302 \tReward: 8.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015693\n",
      "Episode: 5303 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001563\n",
      "Episode: 5304 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015374\n",
      "Episode: 5305 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015294\n",
      "Episode: 5306 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015217\n",
      "Episode: 5307 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001516\n",
      "Episode: 5308 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000151\n",
      "Episode: 5309 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000015037\n",
      "Episode: 5310 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014933\n",
      "Episode: 5311 \tReward: 5.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000149\n",
      "Episode: 5312 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014825\n",
      "Episode: 5313 \tReward: 4.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014798\n",
      "Episode: 5314 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014756\n",
      "Episode: 5315 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014718\n",
      "Episode: 5316 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014673\n",
      "Episode: 5317 \tReward: 3.0 \tMean: 9.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001465\n",
      "Episode: 5318 \tReward: 7.0 \tMean: 9.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001461\n",
      "Episode: 5319 \tReward: 20.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014527\n",
      "Episode: 5320 \tReward: 11.0 \tMean: 9.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014475\n",
      "Episode: 5321 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001443\n",
      "Episode: 5322 \tReward: 8.0 \tMean: 8.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014395\n",
      "Episode: 5323 \tReward: 16.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014295\n",
      "Episode: 5324 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014246\n",
      "Episode: 5325 \tReward: 17.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014156\n",
      "Episode: 5326 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001409\n",
      "Episode: 5327 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000014024\n",
      "Episode: 5328 \tReward: 14.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013958\n",
      "Episode: 5329 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013906\n",
      "Episode: 5330 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001384\n",
      "Episode: 5331 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001377\n",
      "Episode: 5332 \tReward: 6.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001374\n",
      "Episode: 5333 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013698\n",
      "Episode: 5334 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013635\n",
      "Episode: 5335 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013583\n",
      "Episode: 5336 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013556\n",
      "Episode: 5337 \tReward: 16.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001349\n",
      "Episode: 5338 \tReward: 5.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001346\n",
      "Episode: 5339 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013413\n",
      "Episode: 5340 \tReward: 12.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013365\n",
      "Episode: 5341 \tReward: 9.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013323\n",
      "Episode: 5342 \tReward: 14.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001326\n",
      "Episode: 5343 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000013205\n",
      "Episode: 5344 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5345 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001294\n",
      "Episode: 5346 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001289\n",
      "Episode: 5347 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012813\n",
      "Episode: 5348 \tReward: 19.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012744\n",
      "Episode: 5349 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012685\n",
      "Episode: 5350 \tReward: 12.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012633\n",
      "Episode: 5351 \tReward: 11.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012588\n",
      "Episode: 5352 \tReward: 7.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001256\n",
      "Episode: 5353 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012508\n",
      "Episode: 5354 \tReward: 11.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012463\n",
      "Episode: 5355 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001242\n",
      "Episode: 5356 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001235\n",
      "Episode: 5357 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012313\n",
      "Episode: 5358 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001227\n",
      "Episode: 5359 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001221\n",
      "Episode: 5360 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000012154\n",
      "Episode: 5361 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001211\n",
      "Episode: 5362 \tReward: 16.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001203\n",
      "Episode: 5363 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011973\n",
      "Episode: 5364 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001193\n",
      "Episode: 5365 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001189\n",
      "Episode: 5366 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011835\n",
      "Episode: 5367 \tReward: 8.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000118\n",
      "Episode: 5368 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001165\n",
      "Episode: 5369 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001161\n",
      "Episode: 5370 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011554\n",
      "Episode: 5371 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011498\n",
      "Episode: 5372 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001147\n",
      "Episode: 5373 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011422\n",
      "Episode: 5374 \tReward: 5.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011394\n",
      "Episode: 5375 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011346\n",
      "Episode: 5376 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001131\n",
      "Episode: 5377 \tReward: 7.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011283\n",
      "Episode: 5378 \tReward: 9.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001125\n",
      "Episode: 5379 \tReward: 12.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011207\n",
      "Episode: 5380 \tReward: 16.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011148\n",
      "Episode: 5381 \tReward: 13.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011103\n",
      "Episode: 5382 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011058\n",
      "Episode: 5383 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000011012\n",
      "Episode: 5384 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001096\n",
      "Episode: 5385 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010915\n",
      "Episode: 5386 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001088\n",
      "Episode: 5387 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001083\n",
      "Episode: 5388 \tReward: 13.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010783\n",
      "Episode: 5389 \tReward: 17.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001072\n",
      "Episode: 5390 \tReward: 11.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010686\n",
      "Episode: 5391 \tReward: 7.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010655\n",
      "Episode: 5392 \tReward: 4.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010638\n",
      "Episode: 5393 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010513\n",
      "Episode: 5394 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010454\n",
      "Episode: 5395 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001042\n",
      "Episode: 5396 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001039\n",
      "Episode: 5397 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010322\n",
      "Episode: 5398 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010294\n",
      "Episode: 5399 \tReward: 14.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010253\n",
      "Episode: 5400 \tReward: 16.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010197\n",
      "Episode: 5401 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001017\n",
      "Episode: 5402 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010145\n",
      "Episode: 5403 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010107\n",
      "Episode: 5404 \tReward: 7.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000001008\n",
      "Episode: 5405 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010048\n",
      "Episode: 5406 \tReward: 14.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000010006\n",
      "Episode: 5407 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009975\n",
      "Episode: 5408 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000989\n",
      "Episode: 5409 \tReward: 7.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009857\n",
      "Episode: 5410 \tReward: 15.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009798\n",
      "Episode: 5411 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000975\n",
      "Episode: 5412 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009656\n",
      "Episode: 5413 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009618\n",
      "Episode: 5414 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009566\n",
      "Episode: 5415 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009534\n",
      "Episode: 5416 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009507\n",
      "Episode: 5417 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009475\n",
      "Episode: 5418 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000944\n",
      "Episode: 5419 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009406\n",
      "Episode: 5420 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000937\n",
      "Episode: 5421 \tReward: 6.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009347\n",
      "Episode: 5422 \tReward: 4.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000933\n",
      "Episode: 5423 \tReward: 8.0 \tMean: 9.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009302\n",
      "Episode: 5424 \tReward: 11.0 \tMean: 9.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000927\n",
      "Episode: 5425 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5426 \tReward: 14.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009198\n",
      "Episode: 5427 \tReward: 8.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009167\n",
      "Episode: 5428 \tReward: 10.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000914\n",
      "Episode: 5429 \tReward: 7.0 \tMean: 9.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009115\n",
      "Episode: 5430 \tReward: 10.0 \tMean: 9.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000908\n",
      "Episode: 5431 \tReward: 12.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000009045\n",
      "Episode: 5432 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000901\n",
      "Episode: 5433 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008986\n",
      "Episode: 5434 \tReward: 16.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000894\n",
      "Episode: 5435 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008913\n",
      "Episode: 5436 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000888\n",
      "Episode: 5437 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008844\n",
      "Episode: 5438 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000881\n",
      "Episode: 5439 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000878\n",
      "Episode: 5440 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008747\n",
      "Episode: 5441 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008684\n",
      "Episode: 5442 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000865\n",
      "Episode: 5443 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008625\n",
      "Episode: 5444 \tReward: 18.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008584\n",
      "Episode: 5445 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000855\n",
      "Episode: 5446 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008514\n",
      "Episode: 5447 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000848\n",
      "Episode: 5448 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008452\n",
      "Episode: 5449 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000842\n",
      "Episode: 5450 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008383\n",
      "Episode: 5451 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008362\n",
      "Episode: 5452 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008324\n",
      "Episode: 5453 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008292\n",
      "Episode: 5454 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008258\n",
      "Episode: 5455 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008213\n",
      "Episode: 5456 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008185\n",
      "Episode: 5457 \tReward: 18.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008143\n",
      "Episode: 5458 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000812\n",
      "Episode: 5459 \tReward: 17.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008077\n",
      "Episode: 5460 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000008043\n",
      "Episode: 5461 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007966\n",
      "Episode: 5462 \tReward: 10.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000794\n",
      "Episode: 5463 \tReward: 11.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000783\n",
      "Episode: 5464 \tReward: 7.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007814\n",
      "Episode: 5465 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000778\n",
      "Episode: 5466 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000775\n",
      "Episode: 5467 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000769\n",
      "Episode: 5468 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000767\n",
      "Episode: 5469 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000762\n",
      "Episode: 5470 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007588\n",
      "Episode: 5471 \tReward: 5.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000757\n",
      "Episode: 5472 \tReward: 10.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007543\n",
      "Episode: 5473 \tReward: 7.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007522\n",
      "Episode: 5474 \tReward: 12.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007494\n",
      "Episode: 5475 \tReward: 9.0 \tMean: 9.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007474\n",
      "Episode: 5476 \tReward: 16.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007435\n",
      "Episode: 5477 \tReward: 6.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007415\n",
      "Episode: 5478 \tReward: 5.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007397\n",
      "Episode: 5479 \tReward: 12.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000737\n",
      "Episode: 5480 \tReward: 11.0 \tMean: 9.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007342\n",
      "Episode: 5481 \tReward: 10.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007317\n",
      "Episode: 5482 \tReward: 14.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000724\n",
      "Episode: 5483 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007213\n",
      "Episode: 5484 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000716\n",
      "Episode: 5485 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007134\n",
      "Episode: 5486 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007106\n",
      "Episode: 5487 \tReward: 19.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007043\n",
      "Episode: 5488 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000007012\n",
      "Episode: 5489 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006984\n",
      "Episode: 5490 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006953\n",
      "Episode: 5491 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000693\n",
      "Episode: 5492 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006908\n",
      "Episode: 5493 \tReward: 8.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006887\n",
      "Episode: 5494 \tReward: 13.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000686\n",
      "Episode: 5495 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006832\n",
      "Episode: 5496 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006807\n",
      "Episode: 5497 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006783\n",
      "Episode: 5498 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006755\n",
      "Episode: 5499 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000672\n",
      "Episode: 5500 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000067\n",
      "Episode: 5501 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006683\n",
      "Episode: 5502 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000666\n",
      "Episode: 5503 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000662\n",
      "Episode: 5504 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006603\n",
      "Episode: 5505 \tReward: 5.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006585\n",
      "Episode: 5506 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5507 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000065\n",
      "Episode: 5508 \tReward: 17.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006467\n",
      "Episode: 5509 \tReward: 16.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006433\n",
      "Episode: 5510 \tReward: 19.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006398\n",
      "Episode: 5511 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006377\n",
      "Episode: 5512 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000635\n",
      "Episode: 5513 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006294\n",
      "Episode: 5514 \tReward: 13.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006114\n",
      "Episode: 5515 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006093\n",
      "Episode: 5516 \tReward: 15.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000006065\n",
      "Episode: 5517 \tReward: 12.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000604\n",
      "Episode: 5518 \tReward: 10.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000602\n",
      "Episode: 5519 \tReward: 16.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005992\n",
      "Episode: 5520 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005975\n",
      "Episode: 5521 \tReward: 6.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000596\n",
      "Episode: 5522 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005937\n",
      "Episode: 5523 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000592\n",
      "Episode: 5524 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005895\n",
      "Episode: 5525 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000587\n",
      "Episode: 5526 \tReward: 8.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005853\n",
      "Episode: 5527 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000583\n",
      "Episode: 5528 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005805\n",
      "Episode: 5529 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005787\n",
      "Episode: 5530 \tReward: 8.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000577\n",
      "Episode: 5531 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005753\n",
      "Episode: 5532 \tReward: 14.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000573\n",
      "Episode: 5533 \tReward: 21.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005694\n",
      "Episode: 5534 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005676\n",
      "Episode: 5535 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005663\n",
      "Episode: 5536 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005642\n",
      "Episode: 5537 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005607\n",
      "Episode: 5538 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005583\n",
      "Episode: 5539 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000557\n",
      "Episode: 5540 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000554\n",
      "Episode: 5541 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005527\n",
      "Episode: 5542 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005506\n",
      "Episode: 5543 \tReward: 15.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000547\n",
      "Episode: 5544 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000545\n",
      "Episode: 5545 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005416\n",
      "Episode: 5546 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005392\n",
      "Episode: 5547 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000537\n",
      "Episode: 5548 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005354\n",
      "Episode: 5549 \tReward: 11.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005333\n",
      "Episode: 5550 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005312\n",
      "Episode: 5551 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005295\n",
      "Episode: 5552 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000527\n",
      "Episode: 5553 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005246\n",
      "Episode: 5554 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005222\n",
      "Episode: 5555 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000052\n",
      "Episode: 5556 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005184\n",
      "Episode: 5557 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005166\n",
      "Episode: 5558 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005146\n",
      "Episode: 5559 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005128\n",
      "Episode: 5560 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000511\n",
      "Episode: 5561 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005094\n",
      "Episode: 5562 \tReward: 16.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005073\n",
      "Episode: 5563 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000506\n",
      "Episode: 5564 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005024\n",
      "Episode: 5565 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000005003\n",
      "Episode: 5566 \tReward: 15.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000498\n",
      "Episode: 5567 \tReward: 17.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004958\n",
      "Episode: 5568 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004937\n",
      "Episode: 5569 \tReward: 17.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004913\n",
      "Episode: 5570 \tReward: 8.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000049\n",
      "Episode: 5571 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004885\n",
      "Episode: 5572 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004865\n",
      "Episode: 5573 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004844\n",
      "Episode: 5574 \tReward: 11.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004826\n",
      "Episode: 5575 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000481\n",
      "Episode: 5576 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000479\n",
      "Episode: 5577 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004774\n",
      "Episode: 5578 \tReward: 6.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004764\n",
      "Episode: 5579 \tReward: 13.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004747\n",
      "Episode: 5580 \tReward: 13.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004726\n",
      "Episode: 5581 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004712\n",
      "Episode: 5582 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004695\n",
      "Episode: 5583 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004674\n",
      "Episode: 5584 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004653\n",
      "Episode: 5585 \tReward: 7.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000464\n",
      "Episode: 5586 \tReward: 16.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004618\n",
      "Episode: 5587 \tReward: 13.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5588 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004584\n",
      "Episode: 5589 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004566\n",
      "Episode: 5590 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000455\n",
      "Episode: 5591 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000453\n",
      "Episode: 5592 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004518\n",
      "Episode: 5593 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000045\n",
      "Episode: 5594 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000448\n",
      "Episode: 5595 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004462\n",
      "Episode: 5596 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004445\n",
      "Episode: 5597 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004427\n",
      "Episode: 5598 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004403\n",
      "Episode: 5599 \tReward: 8.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000439\n",
      "Episode: 5600 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004375\n",
      "Episode: 5601 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000436\n",
      "Episode: 5602 \tReward: 13.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004344\n",
      "Episode: 5603 \tReward: 8.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004334\n",
      "Episode: 5604 \tReward: 16.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004313\n",
      "Episode: 5605 \tReward: 10.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000043\n",
      "Episode: 5606 \tReward: 15.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004275\n",
      "Episode: 5607 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004257\n",
      "Episode: 5608 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004244\n",
      "Episode: 5609 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004226\n",
      "Episode: 5610 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000421\n",
      "Episode: 5611 \tReward: 20.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004185\n",
      "Episode: 5612 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000417\n",
      "Episode: 5613 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000415\n",
      "Episode: 5614 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004136\n",
      "Episode: 5615 \tReward: 15.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000411\n",
      "Episode: 5616 \tReward: 12.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004098\n",
      "Episode: 5617 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004084\n",
      "Episode: 5618 \tReward: 13.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004067\n",
      "Episode: 5619 \tReward: 17.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000405\n",
      "Episode: 5620 \tReward: 16.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000403\n",
      "Episode: 5621 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000004015\n",
      "Episode: 5622 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003976\n",
      "Episode: 5623 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000396\n",
      "Episode: 5624 \tReward: 18.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003938\n",
      "Episode: 5625 \tReward: 10.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003924\n",
      "Episode: 5626 \tReward: 15.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000391\n",
      "Episode: 5627 \tReward: 6.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000039\n",
      "Episode: 5628 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003886\n",
      "Episode: 5629 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000387\n",
      "Episode: 5630 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000385\n",
      "Episode: 5631 \tReward: 14.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003838\n",
      "Episode: 5632 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003817\n",
      "Episode: 5633 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003806\n",
      "Episode: 5634 \tReward: 18.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003786\n",
      "Episode: 5635 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003758\n",
      "Episode: 5636 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003744\n",
      "Episode: 5637 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000373\n",
      "Episode: 5638 \tReward: 13.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003716\n",
      "Episode: 5639 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003702\n",
      "Episode: 5640 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000369\n",
      "Episode: 5641 \tReward: 13.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000367\n",
      "Episode: 5642 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003636\n",
      "Episode: 5643 \tReward: 14.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003623\n",
      "Episode: 5644 \tReward: 6.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000361\n",
      "Episode: 5645 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003584\n",
      "Episode: 5646 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000357\n",
      "Episode: 5647 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000356\n",
      "Episode: 5648 \tReward: 15.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003543\n",
      "Episode: 5649 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000353\n",
      "Episode: 5650 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003505\n",
      "Episode: 5651 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003487\n",
      "Episode: 5652 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003477\n",
      "Episode: 5653 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003466\n",
      "Episode: 5654 \tReward: 8.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003456\n",
      "Episode: 5655 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003446\n",
      "Episode: 5656 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003435\n",
      "Episode: 5657 \tReward: 14.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000342\n",
      "Episode: 5658 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000341\n",
      "Episode: 5659 \tReward: 13.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003397\n",
      "Episode: 5660 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003387\n",
      "Episode: 5661 \tReward: 11.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000337\n",
      "Episode: 5662 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003355\n",
      "Episode: 5663 \tReward: 18.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003338\n",
      "Episode: 5664 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003328\n",
      "Episode: 5665 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000331\n",
      "Episode: 5666 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003296\n",
      "Episode: 5667 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003283\n",
      "Episode: 5668 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5669 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003248\n",
      "Episode: 5670 \tReward: 16.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000323\n",
      "Episode: 5671 \tReward: 14.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000318\n",
      "Episode: 5672 \tReward: 6.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003168\n",
      "Episode: 5673 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003154\n",
      "Episode: 5674 \tReward: 6.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003147\n",
      "Episode: 5675 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003126\n",
      "Episode: 5676 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003116\n",
      "Episode: 5677 \tReward: 15.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003102\n",
      "Episode: 5678 \tReward: 16.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003085\n",
      "Episode: 5679 \tReward: 9.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003078\n",
      "Episode: 5680 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003067\n",
      "Episode: 5681 \tReward: 10.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003057\n",
      "Episode: 5682 \tReward: 4.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000305\n",
      "Episode: 5683 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003036\n",
      "Episode: 5684 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003022\n",
      "Episode: 5685 \tReward: 7.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003012\n",
      "Episode: 5686 \tReward: 6.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000003005\n",
      "Episode: 5687 \tReward: 13.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002995\n",
      "Episode: 5688 \tReward: 13.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000298\n",
      "Episode: 5689 \tReward: 9.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000297\n",
      "Episode: 5690 \tReward: 11.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000296\n",
      "Episode: 5691 \tReward: 16.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002946\n",
      "Episode: 5692 \tReward: 15.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002932\n",
      "Episode: 5693 \tReward: 11.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000292\n",
      "Episode: 5694 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000291\n",
      "Episode: 5695 \tReward: 16.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002897\n",
      "Episode: 5696 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002884\n",
      "Episode: 5697 \tReward: 10.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002877\n",
      "Episode: 5698 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002852\n",
      "Episode: 5699 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002845\n",
      "Episode: 5700 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002835\n",
      "Episode: 5701 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000282\n",
      "Episode: 5702 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002807\n",
      "Episode: 5703 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000028\n",
      "Episode: 5704 \tReward: 15.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002783\n",
      "Episode: 5705 \tReward: 18.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002766\n",
      "Episode: 5706 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002748\n",
      "Episode: 5707 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002738\n",
      "Episode: 5708 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002727\n",
      "Episode: 5709 \tReward: 14.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000027\n",
      "Episode: 5710 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000269\n",
      "Episode: 5711 \tReward: 10.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000268\n",
      "Episode: 5712 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000267\n",
      "Episode: 5713 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002658\n",
      "Episode: 5714 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000265\n",
      "Episode: 5715 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000264\n",
      "Episode: 5716 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002616\n",
      "Episode: 5717 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000261\n",
      "Episode: 5718 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000026\n",
      "Episode: 5719 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000259\n",
      "Episode: 5720 \tReward: 15.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002578\n",
      "Episode: 5721 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002526\n",
      "Episode: 5722 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002516\n",
      "Episode: 5723 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002505\n",
      "Episode: 5724 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002495\n",
      "Episode: 5725 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002488\n",
      "Episode: 5726 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000248\n",
      "Episode: 5727 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000247\n",
      "Episode: 5728 \tReward: 6.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002464\n",
      "Episode: 5729 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002453\n",
      "Episode: 5730 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002446\n",
      "Episode: 5731 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000244\n",
      "Episode: 5732 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000243\n",
      "Episode: 5733 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002422\n",
      "Episode: 5734 \tReward: 13.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000241\n",
      "Episode: 5735 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000024\n",
      "Episode: 5736 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002394\n",
      "Episode: 5737 \tReward: 7.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002387\n",
      "Episode: 5738 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002377\n",
      "Episode: 5739 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000237\n",
      "Episode: 5740 \tReward: 11.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002363\n",
      "Episode: 5741 \tReward: 15.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000235\n",
      "Episode: 5742 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000234\n",
      "Episode: 5743 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002332\n",
      "Episode: 5744 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000232\n",
      "Episode: 5745 \tReward: 8.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002315\n",
      "Episode: 5746 \tReward: 18.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000229\n",
      "Episode: 5747 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002283\n",
      "Episode: 5748 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002273\n",
      "Episode: 5749 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5750 \tReward: 16.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002256\n",
      "Episode: 5751 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002245\n",
      "Episode: 5752 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002238\n",
      "Episode: 5753 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000223\n",
      "Episode: 5754 \tReward: 9.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002224\n",
      "Episode: 5755 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002217\n",
      "Episode: 5756 \tReward: 17.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002204\n",
      "Episode: 5757 \tReward: 20.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000219\n",
      "Episode: 5758 \tReward: 20.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002165\n",
      "Episode: 5759 \tReward: 17.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000215\n",
      "Episode: 5760 \tReward: 14.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000214\n",
      "Episode: 5761 \tReward: 17.0 \tMean: 14.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000213\n",
      "Episode: 5762 \tReward: 11.0 \tMean: 14.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002124\n",
      "Episode: 5763 \tReward: 4.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000212\n",
      "Episode: 5764 \tReward: 11.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002113\n",
      "Episode: 5765 \tReward: 7.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002106\n",
      "Episode: 5766 \tReward: 10.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000021\n",
      "Episode: 5767 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000209\n",
      "Episode: 5768 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002086\n",
      "Episode: 5769 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002075\n",
      "Episode: 5770 \tReward: 16.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002068\n",
      "Episode: 5771 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000206\n",
      "Episode: 5772 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002054\n",
      "Episode: 5773 \tReward: 10.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002044\n",
      "Episode: 5774 \tReward: 14.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002037\n",
      "Episode: 5775 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000203\n",
      "Episode: 5776 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002013\n",
      "Episode: 5777 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000002002\n",
      "Episode: 5778 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001992\n",
      "Episode: 5779 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001985\n",
      "Episode: 5780 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001975\n",
      "Episode: 5781 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001968\n",
      "Episode: 5782 \tReward: 18.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001957\n",
      "Episode: 5783 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000195\n",
      "Episode: 5784 \tReward: 7.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001947\n",
      "Episode: 5785 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000194\n",
      "Episode: 5786 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001933\n",
      "Episode: 5787 \tReward: 17.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001922\n",
      "Episode: 5788 \tReward: 6.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000192\n",
      "Episode: 5789 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001912\n",
      "Episode: 5790 \tReward: 16.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001905\n",
      "Episode: 5791 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001898\n",
      "Episode: 5792 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000189\n",
      "Episode: 5793 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001884\n",
      "Episode: 5794 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001874\n",
      "Episode: 5795 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001864\n",
      "Episode: 5796 \tReward: 7.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000186\n",
      "Episode: 5797 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001853\n",
      "Episode: 5798 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001846\n",
      "Episode: 5799 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001836\n",
      "Episode: 5800 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000183\n",
      "Episode: 5801 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001822\n",
      "Episode: 5802 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001815\n",
      "Episode: 5803 \tReward: 14.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000178\n",
      "Episode: 5804 \tReward: 15.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001766\n",
      "Episode: 5805 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001752\n",
      "Episode: 5806 \tReward: 11.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000175\n",
      "Episode: 5807 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000174\n",
      "Episode: 5808 \tReward: 9.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001735\n",
      "Episode: 5809 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001728\n",
      "Episode: 5810 \tReward: 13.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000172\n",
      "Episode: 5811 \tReward: 9.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001714\n",
      "Episode: 5812 \tReward: 15.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001707\n",
      "Episode: 5813 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000017\n",
      "Episode: 5814 \tReward: 17.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001694\n",
      "Episode: 5815 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001687\n",
      "Episode: 5816 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000168\n",
      "Episode: 5817 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001673\n",
      "Episode: 5818 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001662\n",
      "Episode: 5819 \tReward: 8.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000166\n",
      "Episode: 5820 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001655\n",
      "Episode: 5821 \tReward: 17.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001638\n",
      "Episode: 5822 \tReward: 14.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000163\n",
      "Episode: 5823 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001628\n",
      "Episode: 5824 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000162\n",
      "Episode: 5825 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001614\n",
      "Episode: 5826 \tReward: 12.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001607\n",
      "Episode: 5827 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000016\n",
      "Episode: 5828 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001593\n",
      "Episode: 5829 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000159\n",
      "Episode: 5830 \tReward: 8.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5831 \tReward: 9.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001582\n",
      "Episode: 5832 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001576\n",
      "Episode: 5833 \tReward: 6.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001572\n",
      "Episode: 5834 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001565\n",
      "Episode: 5835 \tReward: 18.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001558\n",
      "Episode: 5836 \tReward: 18.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001548\n",
      "Episode: 5837 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000154\n",
      "Episode: 5838 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001534\n",
      "Episode: 5839 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000153\n",
      "Episode: 5840 \tReward: 10.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000152\n",
      "Episode: 5841 \tReward: 10.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001513\n",
      "Episode: 5842 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001506\n",
      "Episode: 5843 \tReward: 10.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001503\n",
      "Episode: 5844 \tReward: 11.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001496\n",
      "Episode: 5845 \tReward: 13.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000149\n",
      "Episode: 5846 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001482\n",
      "Episode: 5847 \tReward: 8.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000148\n",
      "Episode: 5848 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000147\n",
      "Episode: 5849 \tReward: 15.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000146\n",
      "Episode: 5850 \tReward: 9.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001454\n",
      "Episode: 5851 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001444\n",
      "Episode: 5852 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000144\n",
      "Episode: 5853 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001437\n",
      "Episode: 5854 \tReward: 8.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001433\n",
      "Episode: 5855 \tReward: 10.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001426\n",
      "Episode: 5856 \tReward: 14.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000142\n",
      "Episode: 5857 \tReward: 17.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001412\n",
      "Episode: 5858 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001406\n",
      "Episode: 5859 \tReward: 7.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001402\n",
      "Episode: 5860 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000014\n",
      "Episode: 5861 \tReward: 6.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001395\n",
      "Episode: 5862 \tReward: 11.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000138\n",
      "Episode: 5863 \tReward: 9.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001378\n",
      "Episode: 5864 \tReward: 11.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001374\n",
      "Episode: 5865 \tReward: 7.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001364\n",
      "Episode: 5866 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001357\n",
      "Episode: 5867 \tReward: 12.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001354\n",
      "Episode: 5868 \tReward: 13.0 \tMean: 9.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001347\n",
      "Episode: 5869 \tReward: 6.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001343\n",
      "Episode: 5870 \tReward: 13.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001333\n",
      "Episode: 5871 \tReward: 19.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001326\n",
      "Episode: 5872 \tReward: 8.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001322\n",
      "Episode: 5873 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001315\n",
      "Episode: 5874 \tReward: 6.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001312\n",
      "Episode: 5875 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001305\n",
      "Episode: 5876 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000013\n",
      "Episode: 5877 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001298\n",
      "Episode: 5878 \tReward: 12.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000129\n",
      "Episode: 5879 \tReward: 9.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001288\n",
      "Episode: 5880 \tReward: 13.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001284\n",
      "Episode: 5881 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001277\n",
      "Episode: 5882 \tReward: 4.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001277\n",
      "Episode: 5883 \tReward: 8.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001274\n",
      "Episode: 5884 \tReward: 16.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001267\n",
      "Episode: 5885 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001263\n",
      "Episode: 5886 \tReward: 6.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000126\n",
      "Episode: 5887 \tReward: 11.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000124\n",
      "Episode: 5888 \tReward: 11.0 \tMean: 10.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001236\n",
      "Episode: 5889 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001232\n",
      "Episode: 5890 \tReward: 8.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001225\n",
      "Episode: 5891 \tReward: 9.0 \tMean: 9.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000122\n",
      "Episode: 5892 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001218\n",
      "Episode: 5893 \tReward: 9.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001215\n",
      "Episode: 5894 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000121\n",
      "Episode: 5895 \tReward: 12.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001204\n",
      "Episode: 5896 \tReward: 11.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000012\n",
      "Episode: 5897 \tReward: 17.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001194\n",
      "Episode: 5898 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000119\n",
      "Episode: 5899 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001187\n",
      "Episode: 5900 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000118\n",
      "Episode: 5901 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001177\n",
      "Episode: 5902 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001173\n",
      "Episode: 5903 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000117\n",
      "Episode: 5904 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001163\n",
      "Episode: 5905 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000116\n",
      "Episode: 5906 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001156\n",
      "Episode: 5907 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001152\n",
      "Episode: 5908 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000115\n",
      "Episode: 5909 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001145\n",
      "Episode: 5910 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001142\n",
      "Episode: 5911 \tReward: 8.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5912 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001128\n",
      "Episode: 5913 \tReward: 14.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000112\n",
      "Episode: 5914 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001118\n",
      "Episode: 5915 \tReward: 9.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001114\n",
      "Episode: 5916 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000111\n",
      "Episode: 5917 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001107\n",
      "Episode: 5918 \tReward: 6.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001104\n",
      "Episode: 5919 \tReward: 8.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000011\n",
      "Episode: 5920 \tReward: 7.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001097\n",
      "Episode: 5921 \tReward: 10.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001093\n",
      "Episode: 5922 \tReward: 11.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000109\n",
      "Episode: 5923 \tReward: 15.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001083\n",
      "Episode: 5924 \tReward: 8.0 \tMean: 9.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000108\n",
      "Episode: 5925 \tReward: 17.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001076\n",
      "Episode: 5926 \tReward: 17.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000107\n",
      "Episode: 5927 \tReward: 10.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001066\n",
      "Episode: 5928 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001062\n",
      "Episode: 5929 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000106\n",
      "Episode: 5930 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001055\n",
      "Episode: 5931 \tReward: 13.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000105\n",
      "Episode: 5932 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001045\n",
      "Episode: 5933 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000104\n",
      "Episode: 5934 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001034\n",
      "Episode: 5935 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000103\n",
      "Episode: 5936 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001024\n",
      "Episode: 5937 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000102\n",
      "Episode: 5938 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001013\n",
      "Episode: 5939 \tReward: 6.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001013\n",
      "Episode: 5940 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000101\n",
      "Episode: 5941 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001007\n",
      "Episode: 5942 \tReward: 16.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000001\n",
      "Episode: 5943 \tReward: 18.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000099\n",
      "Episode: 5944 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000986\n",
      "Episode: 5945 \tReward: 16.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000975\n",
      "Episode: 5946 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000972\n",
      "Episode: 5947 \tReward: 12.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000097\n",
      "Episode: 5948 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000965\n",
      "Episode: 5949 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000096\n",
      "Episode: 5950 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000958\n",
      "Episode: 5951 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000955\n",
      "Episode: 5952 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000095\n",
      "Episode: 5953 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000094\n",
      "Episode: 5954 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000937\n",
      "Episode: 5955 \tReward: 15.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000934\n",
      "Episode: 5956 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000093\n",
      "Episode: 5957 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000927\n",
      "Episode: 5958 \tReward: 9.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000923\n",
      "Episode: 5959 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000092\n",
      "Episode: 5960 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000916\n",
      "Episode: 5961 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000913\n",
      "Episode: 5962 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000091\n",
      "Episode: 5963 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000906\n",
      "Episode: 5964 \tReward: 10.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000902\n",
      "Episode: 5965 \tReward: 12.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000009\n",
      "Episode: 5966 \tReward: 12.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000896\n",
      "Episode: 5967 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000892\n",
      "Episode: 5968 \tReward: 10.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000089\n",
      "Episode: 5969 \tReward: 9.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000885\n",
      "Episode: 5970 \tReward: 14.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000088\n",
      "Episode: 5971 \tReward: 10.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000878\n",
      "Episode: 5972 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000875\n",
      "Episode: 5973 \tReward: 7.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000087\n",
      "Episode: 5974 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000868\n",
      "Episode: 5975 \tReward: 21.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000086\n",
      "Episode: 5976 \tReward: 18.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000857\n",
      "Episode: 5977 \tReward: 16.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000854\n",
      "Episode: 5978 \tReward: 16.0 \tMean: 13.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000085\n",
      "Episode: 5979 \tReward: 15.0 \tMean: 14.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000843\n",
      "Episode: 5980 \tReward: 12.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000084\n",
      "Episode: 5981 \tReward: 9.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000084\n",
      "Episode: 5982 \tReward: 11.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000837\n",
      "Episode: 5983 \tReward: 16.0 \tMean: 14.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000833\n",
      "Episode: 5984 \tReward: 12.0 \tMean: 14.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000083\n",
      "Episode: 5985 \tReward: 16.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000823\n",
      "Episode: 5986 \tReward: 9.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000823\n",
      "Episode: 5987 \tReward: 15.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000082\n",
      "Episode: 5988 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000816\n",
      "Episode: 5989 \tReward: 12.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000812\n",
      "Episode: 5990 \tReward: 16.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000081\n",
      "Episode: 5991 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000805\n",
      "Episode: 5992 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5993 \tReward: 8.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000008\n",
      "Episode: 5994 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000795\n",
      "Episode: 5995 \tReward: 12.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000795\n",
      "Episode: 5996 \tReward: 14.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000079\n",
      "Episode: 5997 \tReward: 18.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000788\n",
      "Episode: 5998 \tReward: 14.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000078\n",
      "Episode: 5999 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000778\n",
      "Episode: 6000 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000774\n",
      "Episode: 6001 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000767\n",
      "Episode: 6002 \tReward: 10.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000764\n",
      "Episode: 6003 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000076\n",
      "Episode: 6004 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000076\n",
      "Episode: 6005 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000757\n",
      "Episode: 6006 \tReward: 11.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000753\n",
      "Episode: 6007 \tReward: 18.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000075\n",
      "Episode: 6008 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000743\n",
      "Episode: 6009 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000743\n",
      "Episode: 6010 \tReward: 8.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000074\n",
      "Episode: 6011 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000736\n",
      "Episode: 6012 \tReward: 17.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000732\n",
      "Episode: 6013 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000073\n",
      "Episode: 6014 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000726\n",
      "Episode: 6015 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000722\n",
      "Episode: 6016 \tReward: 10.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000072\n",
      "Episode: 6017 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000715\n",
      "Episode: 6018 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000071\n",
      "Episode: 6019 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000708\n",
      "Episode: 6020 \tReward: 14.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000705\n",
      "Episode: 6021 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000007\n",
      "Episode: 6022 \tReward: 17.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000698\n",
      "Episode: 6023 \tReward: 12.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000698\n",
      "Episode: 6024 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000694\n",
      "Episode: 6025 \tReward: 17.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000069\n",
      "Episode: 6026 \tReward: 14.0 \tMean: 14.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000687\n",
      "Episode: 6027 \tReward: 8.0 \tMean: 14.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000684\n",
      "Episode: 6028 \tReward: 11.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000068\n",
      "Episode: 6029 \tReward: 13.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000068\n",
      "Episode: 6030 \tReward: 14.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000677\n",
      "Episode: 6031 \tReward: 10.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000673\n",
      "Episode: 6032 \tReward: 10.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000067\n",
      "Episode: 6033 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000067\n",
      "Episode: 6034 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000667\n",
      "Episode: 6035 \tReward: 23.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000663\n",
      "Episode: 6036 \tReward: 15.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000066\n",
      "Episode: 6037 \tReward: 13.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000656\n",
      "Episode: 6038 \tReward: 12.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000653\n",
      "Episode: 6039 \tReward: 12.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000065\n",
      "Episode: 6040 \tReward: 16.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000646\n",
      "Episode: 6041 \tReward: 9.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000642\n",
      "Episode: 6042 \tReward: 14.0 \tMean: 13.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000064\n",
      "Episode: 6043 \tReward: 14.0 \tMean: 14.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000635\n",
      "Episode: 6044 \tReward: 17.0 \tMean: 14.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000632\n",
      "Episode: 6045 \tReward: 10.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000063\n",
      "Episode: 6046 \tReward: 15.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000625\n",
      "Episode: 6047 \tReward: 7.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000625\n",
      "Episode: 6048 \tReward: 11.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000062\n",
      "Episode: 6049 \tReward: 16.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000618\n",
      "Episode: 6050 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000615\n",
      "Episode: 6051 \tReward: 11.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000615\n",
      "Episode: 6052 \tReward: 5.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000061\n",
      "Episode: 6053 \tReward: 14.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000608\n",
      "Episode: 6054 \tReward: 12.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000604\n",
      "Episode: 6055 \tReward: 13.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000006\n",
      "Episode: 6056 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000006\n",
      "Episode: 6057 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000597\n",
      "Episode: 6058 \tReward: 11.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000594\n",
      "Episode: 6059 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000059\n",
      "Episode: 6060 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000059\n",
      "Episode: 6061 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000587\n",
      "Episode: 6062 \tReward: 8.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000587\n",
      "Episode: 6063 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000583\n",
      "Episode: 6064 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000058\n",
      "Episode: 6065 \tReward: 14.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000576\n",
      "Episode: 6066 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000573\n",
      "Episode: 6067 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000573\n",
      "Episode: 6068 \tReward: 13.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000057\n",
      "Episode: 6069 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000057\n",
      "Episode: 6070 \tReward: 12.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000566\n",
      "Episode: 6071 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000566\n",
      "Episode: 6072 \tReward: 9.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6073 \tReward: 13.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000556\n",
      "Episode: 6074 \tReward: 15.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000552\n",
      "Episode: 6075 \tReward: 15.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000055\n",
      "Episode: 6076 \tReward: 13.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000055\n",
      "Episode: 6077 \tReward: 13.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000545\n",
      "Episode: 6078 \tReward: 10.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000054\n",
      "Episode: 6079 \tReward: 12.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000535\n",
      "Episode: 6080 \tReward: 5.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000535\n",
      "Episode: 6081 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000053\n",
      "Episode: 6082 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000528\n",
      "Episode: 6083 \tReward: 8.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000524\n",
      "Episode: 6084 \tReward: 12.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000524\n",
      "Episode: 6085 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000052\n",
      "Episode: 6086 \tReward: 5.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000052\n",
      "Episode: 6087 \tReward: 6.0 \tMean: 9.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000517\n",
      "Episode: 6088 \tReward: 12.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000517\n",
      "Episode: 6089 \tReward: 10.0 \tMean: 9.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000514\n",
      "Episode: 6090 \tReward: 15.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000051\n",
      "Episode: 6091 \tReward: 6.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000507\n",
      "Episode: 6092 \tReward: 13.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000507\n",
      "Episode: 6093 \tReward: 8.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000503\n",
      "Episode: 6094 \tReward: 19.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000503\n",
      "Episode: 6095 \tReward: 10.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000497\n",
      "Episode: 6096 \tReward: 7.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000497\n",
      "Episode: 6097 \tReward: 15.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000493\n",
      "Episode: 6098 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000049\n",
      "Episode: 6099 \tReward: 9.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000049\n",
      "Episode: 6100 \tReward: 10.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000049\n",
      "Episode: 6101 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000486\n",
      "Episode: 6102 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000483\n",
      "Episode: 6103 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000483\n",
      "Episode: 6104 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000048\n",
      "Episode: 6105 \tReward: 9.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000048\n",
      "Episode: 6106 \tReward: 11.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000476\n",
      "Episode: 6107 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000476\n",
      "Episode: 6108 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000472\n",
      "Episode: 6109 \tReward: 12.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000047\n",
      "Episode: 6110 \tReward: 13.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000047\n",
      "Episode: 6111 \tReward: 17.0 \tMean: 12.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000465\n",
      "Episode: 6112 \tReward: 9.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000465\n",
      "Episode: 6113 \tReward: 15.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000462\n",
      "Episode: 6114 \tReward: 12.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000462\n",
      "Episode: 6115 \tReward: 12.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000046\n",
      "Episode: 6116 \tReward: 16.0 \tMean: 13.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000455\n",
      "Episode: 6117 \tReward: 11.0 \tMean: 13.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000045\n",
      "Episode: 6118 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000045\n",
      "Episode: 6119 \tReward: 7.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000448\n",
      "Episode: 6120 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000445\n",
      "Episode: 6121 \tReward: 14.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000445\n",
      "Episode: 6122 \tReward: 7.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000044\n",
      "Episode: 6123 \tReward: 9.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000044\n",
      "Episode: 6124 \tReward: 12.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000438\n",
      "Episode: 6125 \tReward: 10.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000438\n",
      "Episode: 6126 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000434\n",
      "Episode: 6127 \tReward: 15.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000434\n",
      "Episode: 6128 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000043\n",
      "Episode: 6129 \tReward: 8.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000043\n",
      "Episode: 6130 \tReward: 5.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000043\n",
      "Episode: 6131 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000427\n",
      "Episode: 6132 \tReward: 24.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000424\n",
      "Episode: 6133 \tReward: 15.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000042\n",
      "Episode: 6134 \tReward: 5.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000042\n",
      "Episode: 6135 \tReward: 17.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000417\n",
      "Episode: 6136 \tReward: 7.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000417\n",
      "Episode: 6137 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000413\n",
      "Episode: 6138 \tReward: 11.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000413\n",
      "Episode: 6139 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000041\n",
      "Episode: 6140 \tReward: 14.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000041\n",
      "Episode: 6141 \tReward: 9.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000406\n",
      "Episode: 6142 \tReward: 14.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000406\n",
      "Episode: 6143 \tReward: 13.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000403\n",
      "Episode: 6144 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000403\n",
      "Episode: 6145 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000004\n",
      "Episode: 6146 \tReward: 11.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000004\n",
      "Episode: 6147 \tReward: 12.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000396\n",
      "Episode: 6148 \tReward: 6.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000396\n",
      "Episode: 6149 \tReward: 15.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000392\n",
      "Episode: 6150 \tReward: 12.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000039\n",
      "Episode: 6151 \tReward: 14.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000039\n",
      "Episode: 6152 \tReward: 11.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000386\n",
      "Episode: 6153 \tReward: 11.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6154 \tReward: 14.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000386\n",
      "Episode: 6155 \tReward: 10.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000382\n",
      "Episode: 6156 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000382\n",
      "Episode: 6157 \tReward: 16.0 \tMean: 12.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000038\n",
      "Episode: 6158 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000038\n",
      "Episode: 6159 \tReward: 7.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000038\n",
      "Episode: 6160 \tReward: 14.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000375\n",
      "Episode: 6161 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000375\n",
      "Episode: 6162 \tReward: 9.0 \tMean: 10.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000375\n",
      "Episode: 6163 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000037\n",
      "Episode: 6164 \tReward: 5.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000037\n",
      "Episode: 6165 \tReward: 10.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000037\n",
      "Episode: 6166 \tReward: 11.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000368\n",
      "Episode: 6167 \tReward: 11.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000368\n",
      "Episode: 6168 \tReward: 13.0 \tMean: 9.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000365\n",
      "Episode: 6169 \tReward: 9.0 \tMean: 9.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000365\n",
      "Episode: 6170 \tReward: 9.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000036\n",
      "Episode: 6171 \tReward: 11.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000036\n",
      "Episode: 6172 \tReward: 9.0 \tMean: 9.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000036\n",
      "Episode: 6173 \tReward: 6.0 \tMean: 9.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000358\n",
      "Episode: 6174 \tReward: 13.0 \tMean: 10.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000358\n",
      "Episode: 6175 \tReward: 15.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000358\n",
      "Episode: 6176 \tReward: 15.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000354\n",
      "Episode: 6177 \tReward: 11.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000035\n",
      "Episode: 6178 \tReward: 10.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000035\n",
      "Episode: 6179 \tReward: 12.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000347\n",
      "Episode: 6180 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000347\n",
      "Episode: 6181 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000347\n",
      "Episode: 6182 \tReward: 7.0 \tMean: 11.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000344\n",
      "Episode: 6183 \tReward: 14.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000344\n",
      "Episode: 6184 \tReward: 6.0 \tMean: 11.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000344\n",
      "Episode: 6185 \tReward: 9.0 \tMean: 10.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000034\n",
      "Episode: 6186 \tReward: 12.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000034\n",
      "Episode: 6187 \tReward: 11.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000034\n",
      "Episode: 6188 \tReward: 10.0 \tMean: 10.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000337\n",
      "Episode: 6189 \tReward: 10.0 \tMean: 10.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000337\n",
      "Episode: 6190 \tReward: 15.0 \tMean: 10.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000333\n",
      "Episode: 6191 \tReward: 16.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000333\n",
      "Episode: 6192 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000033\n",
      "Episode: 6193 \tReward: 17.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000033\n",
      "Episode: 6194 \tReward: 16.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000327\n",
      "Episode: 6195 \tReward: 10.0 \tMean: 12.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000327\n",
      "Episode: 6196 \tReward: 9.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000327\n",
      "Episode: 6197 \tReward: 17.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000323\n",
      "Episode: 6198 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000323\n",
      "Episode: 6199 \tReward: 17.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000323\n",
      "Episode: 6200 \tReward: 13.0 \tMean: 13.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000032\n",
      "Episode: 6201 \tReward: 18.0 \tMean: 13.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000032\n",
      "Episode: 6202 \tReward: 13.0 \tMean: 13.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000316\n",
      "Episode: 6203 \tReward: 13.0 \tMean: 13.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000316\n",
      "Episode: 6204 \tReward: 9.0 \tMean: 12.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000316\n",
      "Episode: 6205 \tReward: 13.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000313\n",
      "Episode: 6206 \tReward: 9.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000313\n",
      "Episode: 6207 \tReward: 10.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000313\n",
      "Episode: 6208 \tReward: 17.0 \tMean: 13.2 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000031\n",
      "Episode: 6209 \tReward: 11.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000306\n",
      "Episode: 6210 \tReward: 8.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000306\n",
      "Episode: 6211 \tReward: 12.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000306\n",
      "Episode: 6212 \tReward: 16.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000302\n",
      "Episode: 6213 \tReward: 12.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000302\n",
      "Episode: 6214 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000003\n",
      "Episode: 6215 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000003\n",
      "Episode: 6216 \tReward: 17.0 \tMean: 12.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.0200000000000003\n",
      "Episode: 6217 \tReward: 8.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000295\n",
      "Episode: 6218 \tReward: 7.0 \tMean: 11.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000295\n",
      "Episode: 6219 \tReward: 15.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000295\n",
      "Episode: 6220 \tReward: 10.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000292\n",
      "Episode: 6221 \tReward: 12.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000292\n",
      "Episode: 6222 \tReward: 11.0 \tMean: 11.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000292\n",
      "Episode: 6223 \tReward: 9.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000029\n",
      "Episode: 6224 \tReward: 13.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000029\n",
      "Episode: 6225 \tReward: 11.0 \tMean: 11.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000285\n",
      "Episode: 6226 \tReward: 11.0 \tMean: 10.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000285\n",
      "Episode: 6227 \tReward: 15.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000285\n",
      "Episode: 6228 \tReward: 17.0 \tMean: 12.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000028\n",
      "Episode: 6229 \tReward: 9.0 \tMean: 11.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000028\n",
      "Episode: 6230 \tReward: 13.0 \tMean: 12.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000028\n",
      "Episode: 6231 \tReward: 17.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000278\n",
      "Episode: 6232 \tReward: 8.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000278\n",
      "Episode: 6233 \tReward: 9.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000278\n",
      "Episode: 6234 \tReward: 13.0 \tMean: 12.3 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6235 \tReward: 14.0 \tMean: 12.6 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000275\n",
      "Episode: 6236 \tReward: 16.0 \tMean: 13.1 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000275\n",
      "Episode: 6237 \tReward: 9.0 \tMean: 12.5 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000027\n",
      "Episode: 6238 \tReward: 11.0 \tMean: 11.9 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000027\n",
      "Episode: 6239 \tReward: 7.0 \tMean: 11.7 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000027\n",
      "Episode: 6240 \tReward: 10.0 \tMean: 11.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.02000000000000027\n",
      "Episode: 6241 \tReward: 7.0 \tMean: 10.4 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000268\n",
      "Episode: 6242 \tReward: 12.0 \tMean: 10.8 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000268\n",
      "Episode: 6243 \tReward: 11.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000268\n",
      "Episode: 6244 \tReward: 13.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000264\n",
      "Episode: 6245 \tReward: 14.0 \tMean: 11.0 \tBestMean: 15.5 \tTRAIN START: True \tEpsi: 0.020000000000000264\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "#start_time = datetime.now()\n",
    "\n",
    "EPISODES = 12185#15000\n",
    "#REWARD_LIST = []\n",
    "#MEAN_LIST = []\n",
    "#BEST_MEAN_REWARD = INITIAL_MEAN_REWARD\n",
    "#EPSILON_LIST = []\n",
    "#STEPS = 0\n",
    "#SYNC = 1000 #10000\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    EPISODE_REWARD = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Transition im MEMORY BUFFER speichern\n",
    "        save_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Experience Replay, falls genügend Transitionen gespeichert\n",
    "        if len(MEMORY_BUFFER) > TRAIN_START:\n",
    "            replay()\n",
    "            \n",
    "        # Synchronisation zwischen Target Networks und Deep Q-Network (alle 1000 Updates - Algorithm 1)\n",
    "        if STEPS % SYNC == 0:\n",
    "            TARGET.set_weights(DQN.get_weights())\n",
    "\n",
    "        # Reward einer Aktion zum gesamten Reward der Episode addieren\n",
    "        EPISODE_REWARD += reward\n",
    "        \n",
    "        # State aktualisieren\n",
    "        state = next_state\n",
    "        STEPS += 1\n",
    "        \n",
    "        # EPSILON verringern\n",
    "        if EPSILON > EPSILON_MIN:\n",
    "            EPSILON = epsilon_decay(\"exponential\", EPSILON, EPSILON_DECAY, EPSILON_MIN, STEPS)\n",
    "\n",
    "        if done:\n",
    "            REWARD_LIST.append(EPISODE_REWARD)\n",
    "            current_mean_reward = np.mean(REWARD_LIST[-min(len(REWARD_LIST), 10):])\n",
    "            MEAN_LIST.append(np.mean(REWARD_LIST))\n",
    "            \n",
    "            EPSILON_LIST.append(EPSILON)\n",
    "            print(\"Episode:\", episode+1, \"\\tReward:\", EPISODE_REWARD, \"\\tMean:\", round(current_mean_reward, 2),\"\\tBestMean:\", BEST_MEAN_REWARD, \"\\tTRAIN START:\", (len(MEMORY_BUFFER)>TRAIN_START), \"\\tEpsi:\", EPSILON)\n",
    "\n",
    "            # Übernahme des höchsteb Mean Rewards\n",
    "            if current_mean_reward > BEST_MEAN_REWARD:\n",
    "                BEST_MEAN_REWARD = current_mean_reward\n",
    "        \n",
    "                # Trainierte Gewichte speichern\n",
    "                if EPSILON < 0.3:\n",
    "                    import os\n",
    "                    PATH = \"WEIGHTS\"\n",
    "                    try:\n",
    "                        os.makedirs(PATH)\n",
    "                    except FileExistsError:\n",
    "                        # Pfad existiert bereits\n",
    "                        pass\n",
    "                    DQN.save_weights(PATH +\"/\" + game + \"_DQN\"+ \"_Ep_\"+ str(episode+1)+ \".h5\")\n",
    "                    #TARGET.save_weights(PATH+\"/\" + game + \"_TARGET\" + \"_Ep_\"+ str(episode+1)+ \".h5\")\n",
    "                    \n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(REWARD_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(REWARD_LIST, MEAN_LIST, EPSILON_LIST)), \n",
    "               columns =['Rewards', 'Mean Reward', \"Epsilon\"]) \n",
    "df.to_csv(\"DQN_\" + game + \"_Auswertung.csv\",mode=\"w\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN.save_weights(PATH +\"/\" + game + \"_DQN\"+ \"_End.h5\")\n",
    "#TARGET.save_weights(PATH+\"/\" + game + \"_TARGET\" + \"_End.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXt-2mKVOFBw"
   },
   "source": [
    "# **Auswertung des Trainings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "sICat9voOJKZ",
    "outputId": "7cf16408-586a-4c56-bd10-a33044d9d385",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "plt.plot(REWARD_LIST, label=\"erhaltene Rewards\")\n",
    "plt.plot(MEAN_LIST, label=\"durchschnittler Reward\")\n",
    "plt.title(\"Rewards während des Trainings\", fontsize=25)\n",
    "plt.xlabel(\"Episoden\", fontsize=20)\n",
    "plt.ylabel(\"Rewards\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCZYOdYaPGPP"
   },
   "source": [
    "# **Trainierten Agenten spielen lassen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakout-v0_DQN_End.h5\t    Breakout-v0_DQN_Ep_1984.h5\r\n",
      "Breakout-v0_DQN_Ep_1139.h5  Breakout-v0_DQN_Ep_1985.h5\r\n",
      "Breakout-v0_DQN_Ep_1512.h5  Breakout-v0_DQN_Ep_2810.h5\r\n",
      "Breakout-v0_DQN_Ep_1728.h5  Breakout-v0_DQN_Ep_4641.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"WEIGHTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n02s15IFPNVl"
   },
   "outputs": [],
   "source": [
    "# Gewichte laden\n",
    "WEIGHTS_PATH = \"WEIGHTS/Pong-v0_DQN_Ep_14840.h5\"\n",
    "DQN.load_weights(filepath=WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdkuM1BjXkah"
   },
   "source": [
    "## Rendering a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "RkdjLEfgUPcf",
    "outputId": "3fd6bf95-1fc3-422a-820e-ab7fb8187b5f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = np.argmax(DQN.predict(state))\n",
    "        state, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPQlMVu90wgzQaUbux1p9Bf",
   "collapsed_sections": [],
   "name": "Deep_Q-Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
