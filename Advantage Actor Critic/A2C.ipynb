{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOafjdahyQ4x"
   },
   "source": [
    "# TODO:\n",
    "* Wrapper for reward clipping to [-1, 1] (same reason like image normalization)\n",
    "* checking hyperparameters from paper\n",
    "* checking used parameters\n",
    "* * Adding results to a Dataframe and save to hard drive (to compare with other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6s7lP8w_qT-g"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isafSyFJqqbC"
   },
   "source": [
    "# Auswahl des Spiels\n",
    "\n",
    "[Hier](https://gym.openai.com/envs/#atari) ist eine vollständige Liste der verfügbaren Spiele zu finden. Um ein Environment zu erstellen muss der vollständige Name des Spiels als String übergeben werden.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "```python\n",
    "game = \"MsPacman-v0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9oFwznyfqtY8"
   },
   "outputs": [],
   "source": [
    "# Hier kann das Spiel übergeben werden\n",
    "game = \"Breakout-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZFpCCiUqxec"
   },
   "source": [
    "# **Preprocessing**\n",
    "[Stable Baselines](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K56-9gA8q2cM"
   },
   "source": [
    "## Fire Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7xfJ9C1q47O"
   },
   "outputs": [],
   "source": [
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env) \n",
    "        self.env.reset()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        observation, _, _, _ = self.env.step(env.unwrapped.get_action_meanings().index('FIRE'))\n",
    "\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max And Skip Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noop Reset Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Float Frame Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic Life Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
    "            # so it's important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Reward Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukAIUaihrUBd"
   },
   "source": [
    "## Resize & Grayscale Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IFE3KyHWrN-1"
   },
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import cv2\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        :param env: (Gym Environment) the environment\n",
    "        \"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1),\n",
    "                                            dtype=env.observation_space.dtype)\n",
    "        \n",
    "    def observation(self, frame):\n",
    "        \"\"\"\n",
    "        returns the current observation from a frame\n",
    "        :param frame: ([int] or [float]) environment frame\n",
    "        :return: ([int] or [float]) the observation\n",
    "        \"\"\"\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "kb1LXTXKs6qH",
    "outputId": "77e5d9bf-5428-4c85-e81f-9bedb73fe478"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def WarpFrameEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    return env\n",
    "\n",
    "normal_env = gym.make(game)\n",
    "wrapped_env = WarpFrameEnv(game)\n",
    "\n",
    "normal_env.reset()\n",
    "wrapped_env.reset()\n",
    "action = normal_env.action_space.sample()\n",
    "\n",
    "normal_state, _, _, _ = normal_env.step(action)\n",
    "wrapped_state, _, _, _ = wrapped_env.step(action)\n",
    "\n",
    "wrapped_state = wrapped_state[: , :, 0]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.suptitle('Warp Frame', fontsize=20)\n",
    "axs[0].imshow(normal_state)\n",
    "axs[0].set_title(\"Normal\", fontsize=16)\n",
    "axs[1].imshow(wrapped_state, cmap=\"gray\")\n",
    "axs[1].set_title(\"Warp Frame\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjZQ6BOPq90B"
   },
   "source": [
    "## Frame Stack Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qYTs63ANrFyb"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.frames = deque(maxlen=4)\n",
    "        low = np.repeat(self.observation_space.low[np.newaxis, ...], repeats=4, axis=0)\n",
    "        high = np.repeat(self.observation_space.high[np.newaxis, ...], repeats=4, axis=0)\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=self.observation_space.dtype)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        for _ in range(4):\n",
    "            self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "BFsMn2h-s04j",
    "outputId": "1b951e75-af6d-41d4-ab34-911969d424b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAEmCAYAAADm0OiFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7hcdX3v8feXBIIElUswIHgEy+2APoBNRQv1BshFK7ReqaeNGg+lWuvtUcFbK6VVrEdFj9WmoOIBUS4iSEWEiCha0SCxcpW7JCXARlAQDAS+54+1Nkw2e2fPnj1r5jcz79fzzDMz6zLrO4v9YfKd31prIjORJEmSJPXXBv0uQJIkSZJkcyZJkiRJRbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkgoREcdGREbEvv2uRZLUezZnkjQE6n/Qr+/2+n7X2C8RsW1EHB8RV0fE/RHxQET8KiK+VzdDz5iw/CURsbZf9UqSRtfcfhcgSeqqD08xfUVPqyhEROwBXARsDvwc+BJwN/AUYG/g/cD1wI19KlGSpEfZnEnSEMnMf+h3DYU5nqox+0Bm/tPEmRGxIzCn51VJkjQJD2uUpBETESfXhzr+j4h4W0T8oj7U78J6/ryIeGtEnBcRt0TEmoj4dURcEBEHTvGaKyPi+oh4Un0I4cr6NS+PiJfXy8yNiA9GxHUR8ft6+b9ZT50H1zXcVddwQ0R8LCKeNIO3+7z6/tOTzczM6zPz2np7O0ZEAvsAcyYcFnphS137RcQJ9WGSv60Plbyifm/zpngvcyPizRHxo4j4Tb3OdRHx7xHxB9O9iYjYvt7emog4fAbvX5I0QBw5k6TR9VlgX+BbwH8AD9bTtwI+BfwIuAC4E9gGeDlwXkS8MTO/NMnrzQMuBJ4EfKN+fjjw9YjYH3gH8GzgPOAh4FXAv0bEHZl5ZusLRcQxwAeBu4Bv1jXsAbwbOCgi/jgz72vjPf4a2BrYCfhZG8t+GHgjsB1wTMu81sMejwaeAfy4rm0TqobuGOAFEXFgZj7c8l7mUe3jFwO3AKcA9wLbA38OXAzcMFVREbFXvf4TgIMy86Jp3ockaUBFZva7BknSLNUjPjD5OWc3tzZTEXEy8DpgJbBvZt4y4bU2BrbMzFUTpm8G/CewANguM9e0zFsJbAucDbxmfF5EvAj4LtV5Xr8EDszM39TzdgKuAlZk5h+1vNYBwHeAS4CXjS9fz3sT8O/AxzPz3W3sl08BbwNWA/8KfK/e3r3rWecS4LmZOekXmPUFRG7KCR+gEfER4Cjgla3NZkR8jKqp/Ea9bx5smTcPeGJmjtXPj6U6D+5PMvOSiHgJcCbwG+DgzPzFdO9ZkjS4bM4kaQi0NGeTuTgzX9iy7Hhz9reZ+dkZbuc9wHHAPpn5o5bp483Z9pM0e78Cnga8IDO/P2HeD4DnABuPNzsR8U3gZcCu44ccTljnF1TN41PbqHdjqhHCxTx2blkC11KN4H06M2+esM56m7P1bOspwO3Av2fmEfW0DalG/zYAdszM1dO8xqPNGbAjVSN6LdWI2cqZ1CNJGjwe1ihJQyQzYwaL/2SqGRHxLKrRnn2Bp1Idothq20lWG5vYmNX+m6o5m+ywwlXARlRXT7y9nvY8YA1weMSkb2cusE1EPLl1VG0ymfl7YElEvB84iKoR/MP6tivw1xHxisz89vpep1VEbAq8HTgM2BnYFGgttHXf7AY8EfjhdI3ZBO+qX/9i4LDMvGcG60qSBpTNmSSNrkmbhYjYh+rcsQ2AZVSHKt4LPEJ1ztif8vhmDapD7yazFnh4inPExn9PbMOWaVtQNTt/P039m65nm+uoG6Mv1TciYkvgX4A3AF+MiKdl5rS/bRYRG1EdGvmHwC+Ar1KdD/cQ1f76IOvum83q+3UOEW3D8+v7C23MJGl02JxJ0uia6lDIDwIbU5/31DojIj5I1Zw16bfAg5n5lKY2kJl31eevHUg1Mrgb8F9trPrnVI3ZiZn5ptYZEfE0qn3XaryxmmykcX1eX7/WP0bEBpl5zDTLS5KGgJfSlyRNtCNwx8TGrPaCHmz/x8BWEbFLkxvJzEeA39VPWw9LfBiImPyYyh3r+zMnmTfZvrmKatRxz4jYegbl3Q3sT3XFzA9HxD/PYF1J0oCyOZMkTXQzVXO0e+vEiPhrYL8ebP8T9f0JEbHNxJkRsWlE7N3OC0XEhyPi6VPMew3VJfbvomqixo1fwGO7SVa7ub5/4YTX+gPgIxMXzsyHgM8B84HP1YdFtq43LyIWTFZfZv4WeAlwEXB0RHxisuUkScPDwxolSRN9kqoJ+1FEnEZ1mOFzqC7UcSbwiiY3npnfiYgPAP8IXBcR5wE3UZ1jtj3VCNVFVFd0nM67gA9GxOXAcmAMeDKwCNib6py3I+omatwy4M+Ab0TEt4EHqC6dfwrV+Xc3Ae+JiD2AnwNPr2s5F3jNJDX8PdX+Owz4ZUScC9xHdZGUA6kuLnLyFPvidxHxUuAs4B31pff/duJl/CVJw8HmTJK0jsz8j4g4lOqS7q+lamB+QjVatCsNN2d1Df9UX2b/76h+4PlQqot/rAQ+T/VDzu04hOoqjc+vHy+kunjHrVSXqf90Zl4xYZ1/o2qcXgO8h+qzchlwSmbeGxEvBD5KtT9eQPUD1f8AfIZJmrPM/H39e2V/A/wl1UVIoLpIyJlUhy5OKTMfqP97nAa8GZgXEUfUh2VKkoaIv3MmSZIkSQXwnDNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnkiRJklQAmzNJkiRJKoDNmSRJkiQVwOZMkiRJkgpgcyZJkiRJBbA5kyRJkqQC2JxJkiRJUgFsziRJkiSpADZnDYiI10dETnHbv9/1dUNEvCEizoyIW+r3dUK/a9LoGfasRcS2EXFcRFwWEb+JiDsj4sKI2LfftWl0DHvOACLiyxFxTUTcW99+HhFviYg5/a5No2MUstYqIv4kIh6JiOx3LSWZ2+8ChtyrgJUTpl3Vj0Ia8JfA5sB3gNf2uRZpWLP2R8ArgS8CPwY2Bt4CXBwRL8vM8/pZnEbOsOYMqmwdD9xQPz8Y+L/AM4B39asojaxhzhoAEbER8G/A7cDWfS6nKDZnzVqRmde3u3BEzMvMNU0W1EX7Z+YjABHxp/0uRiNvWLN2MbBLZq4dnxAR5wNXA+8GbM7US8OaMzLz1RMmfScitgPeiM2Zem9os9biKOAh4CTgvX2upSge1tgnEbF/PUx9WER8ISLGgFX1vJ0j4uSIuDkiHoiIGyLisxGx2YTXGF9m74j4z3rZayLi4Hr+u+vDDn8TEWdFxIIJ68+NiPdHxLURsSYiVkXEv0TEvOnqH2/MpNINctYy8+7Wxqye9hDwc2DbLuweqSsGOWfrcRewdtqlpB4ahqxFxM5UzdnfYMYex5GzZs2JiNZ9nJn58IRlPgv8B/A6qsMqoPpH1y3A6cDdwI7A+4A9gInnmmxOdcjTvwC3AR8CzoyIz1MdjvFmquHiTwGfBv6iZd1TqQ7d+CjVIVO7A8cA/wN4TUfvWOqPkcla/eH3XOCnM1lP6oKhzllEBDAH2BQ4gOrw/WOnW09qwFBnDfg8cGpm/igiDmlj+dGSmd66fANeD+Qkt0taltm/nnZ6G683F3hhvfyzWqafXE/745Zpz66nXQls0DL908Ca8WnAi+rl/mLCthbX0585g/e7Gjih3/vd2+jdRi1r9XofAx4Gntfv/e9tNG6jkjPgsJb39ghwTL/3vbfRuo1C1ur3OAZsWT8/lqr57Pv+L+XmyFmz/ox1T+i8d5Jlzpo4of5m/N3A/wKezmPfiADsAvyi5flvM/NHLc+vqe8vzHUPPbwG2Ah4ClUzdRDwe+CsCd/OfKe+fz5wxeRvSyrOSGQtIv6qrvdDmfmf7awjddGw5+x7VBfheTLVyNnREZGZ+ffTrCd121BmrT488uPAUZl512TLyMMam3ZFTn9C522TTPsY1XG4/0A1XHwvVchOZ92gQTVs3erBaaaPr/+U+vH9U9S15fqKlgoz9FmLiMOAE4HPZ+Y/trOO1GVDnbPMvAdYXj9dFhFrgfdHxOcyc/V060tdNKxZ+2fgV1SHT46fBzcPoH7+YGZO9bojw+as/yb7bYfXAl/IzH8enzDxZM4uuAv4HdVw92T+u8vbk/ptYLMWES8Bvkb1AfuWrlUmdd/A5mwSy6nOQdueasRAKskgZm03YC/g15PMuxs4k+rnY0aazVmZnkB1edFWb+jyNr5NdXng+Zl5cZdfWxoUxWctqh+cPgs4H/ir9EqpGjzF52wKL6D6B/BNXXo9qWmlZ+2tVIcNt1pCdRjmi4A7Z1/e4LM5K9P5wBsj4iqqH8R8FfCcbm4gMy+MiNOpjhn+BPCTetb2wCHAuzLzhqnWj4jdgf9ZP50HbB8R4992XOSxxBoQRWctInYDzqX6kc7/AyyqLig3/tJ5aTdrlRpSes4OpfrH4blUh1w9EXgp8L+Bz2bm7d2sVWpQ0VnLzMsnTouI/et53+tmnYPM5qxMb6a6ROpHqL61O5fqUqk/7vJ2Dgf+jupblQ9QneB5M1W4p/v24nDg/S3P96tvAH8CXNLNQqWGlJ61P6b6lvHJVBcraPUw/j9cg6H0nF1HlaV/ArYC7gF+Wdf4tS7XKDWp9KypDVFfxlKSJEmS1Ecb9LsASZIkSZLNmSRJkiQVYVbNWUQcFBHXRsT1EXFUt4qStC6zJjXPnEnNM2fS+nV8zllEzKE6YfYAql8x/ylweGZe1b3yJJk1qXnmTGqeOZOmN5uRs+cA12fmjZn5IPBV4NDulCWphVmTmmfOpOaZM2kas7kM87bArS3PVwJ7r2+FiPDSkBpGY5m5VYOvP6OsmTMNqaJyBmZNwykzY/qlOmbOpMqUn2mN/0ZORBwBHNH0dqQ+uqXfBZgzjYC+5wzMmtQL5kwjYMrPtNk0Z6uAp7U8366eto7MXAosBb/9kDo0bdbMmTRrfqZJzTNn0jRmc87ZT4GdImKHiNgIeC1wTnfKktTCrEnNM2dS88yZNI2OR84yc21E/C1wPjAH+EJmXtm1ynps6623BuCGG25YZ/qKFSset+zuu+8OwIYbbgjAPvvss86yp59++qPLHnLIIQDcemt1iPVdd921zvbG77/whS88us5b3/pWAA4++GAAzjjjDADuv/9+AH75y18CMGfOnEfXedaznrVOjfPnz1/Pu+3c0UcfDcAHPvAB4LH3M/7+JnPNNdcAsGTJkkZqmugzn/kMAG984xsBOPbYYwH4yEc+0pPtd9swZc2ctcec9d4w5QzMWrvMWm+ZM3MG5mw6szrnLDO/BXyrS7VImoJZk5pnzqTmmTNp/Rq/IMigG/9mo9X4NyTj31y047jjjgPgi1/8IvD4bxHaMf6tx3hNrduf+K1Nr4x/s3HqqadOuczY2FivytGAMmfrZ87ULWZt/cyausGcrZ85W7/ZnHMmSZIkSeoSmzNJkiRJKoCHNWpGzjvvPABWr1496fxnPvOZABx55JGPThs/2fWb3/xmw9VJw8GcSb1h1qTmmbOZceRMkiRJkgrgyNk0fvjDHz5u2pZbbjnj13nve98LwJve9CZgZieEjtt5553Xqan1cqi9stdeewGPvY+JnvSkJ/WyHA0Jc7Yuc6ammLV1mTU1wZyty5zNjCNnkiRJklSAyMyebWyTTTbJXXbZpWfbk3phxYoVl2Xmon7XMc6caRiVljMwaxo+1157Lffff3/0u45W5kzDaH2faY6cSZIkSVIBenrO2a677soll1zSy01KjZs/f36/S1iHOdMwKi1nYNY0fPbdd99+l/A45kzDaH2faY6cSZIkSVIBbM4kSZIkqQA2Z5IkSZJUgGmbs4j4QkTcERFXtEzbIiIuiIjr6vvNmy1TGn5mTWqeOZOaZ86kzrUzcvYl4KAJ044ClmXmTsCy+rmk2fkSZk1q2pcwZ1LTvoQ5kzoybXOWmd8Hfj1h8qHASfXjk4DDulyXNHLMmtQ8cyY1z5xJnev0nLOFmXlb/Xg1sLBL9Uhal1mTmmfOpOaZM6kNs74gSGYmkFPNj4gjImJ5RCwfGxub7eakkbW+rJkzqTv8TJOaZ86kqXXanN0eEdsA1Pd3TLVgZi7NzEWZuWjBggUdbk4aWW1lzZxJs+JnmtQ8cya1odPm7Bxgcf14MXB2d8qRNIFZk5pnzqTmmTOpDXOnWyAiTgVeCCyIiJXA3wMfBU6LiCXALcCru1XQNddcA8Dvf//7br2kNGMbb7wxALvuumvPttnLrJkzlWDYcwZmTWXoddbMmUZRt3I2bXOWmYdPMWu/WW1Z0jrMmtQ8cyY1z5xJnZu2Oeu1JUuWALBixYo+V6JRtueeewLwwx/+sM+VNMOcqQTDnjMwayrDsGfNnKkE3crZrK/WKEmSJEmaPZszSZIkSSqAzZkkSZIkFcDmTJIkSZIKYHMmSZIkSQWwOZMkSZKkAticSZIkSVIBbM4kSZIkqQA2Z5IkSZJUAJszSZIkSSqAzZkkSZIkFcDmTJIkSZIKMG1zFhFPi4iLIuKqiLgyIt5WT98iIi6IiOvq+82bL1caTuZM6g2zJjXPnEmda2fkbC3wrszcDXgu8JaI2A04CliWmTsBy+rnkjpjzqTeMGtS88yZ1KFpm7PMvC0zf1Y/vhe4GtgWOBQ4qV7sJOCwpoqUhp05k3rDrEnNM2dS52Z0zllEbA/sBVwKLMzM2+pZq4GFU6xzREQsj4jlY2NjsyhVGg3mTOoNsyY1z5xJM9N2cxYRmwJnAm/PzN+2zsvMBHKy9TJzaWYuysxFCxYsmFWx0rAzZ1JvmDWpeeZMmrm2mrOI2JAqXKdk5tfrybdHxDb1/G2AO5opURoN5kzqDbMmNc+cSZ1p52qNAZwIXJ2Zn2iZdQ6wuH68GDi7++VJo8GcSb1h1qTmmTOpc3PbWGYf4C+BX0TEinra+4CPAqdFxBLgFuDV3Sjo6U9/OgD3339/N15O6sj432EPmTONnD7kDMyaRpCfaVLzupWzaZuzzLwEiClm79eVKqQRZ86k3jBrUvPMmdS5dkbOeuroo48G/PZD/bXJJpv0u4RGmTOVYNhzBmZNZRj2rJkzlaBbOZvRpfQlSZIkSc2wOZMkSZKkAticSZIkSVIBijvnbOHC6sfi16xZ0+dKNMrmzZvX7xIaZc5UgmHPGZg1lWHYs2bOVIJu5cyRM0mSJEkqQHEjZ3PnFleSRtCw/x0O+/vTYBiFv8NReI8q37D/HQ77+9Ng6NbfoSNnkiRJklSAYr9qiJjqtwsldYs5k3rDrEnNM2caBo6cSZIkSVIBbM4kSZIkqQDFHdY4Z84cADKzz5VolI3/HQ4rc6YSDHvOwKypDMOeNXOmEnQrZ9OOnEXExhHxk4j4eURcGREfrqfvEBGXRsT1EfG1iNioKxVJI8icSb1h1qTmmTOpc+0c1rgGeHFm7gHsCRwUEc8FjgM+mZk7AncDS5orUxp65kzqDbMmNc+cSR2atjnLyn310w3rWwIvBs6op58EHNZIhdIIMGdSb5g1qXnmTOpcW+ecRcQc4DJgR+CzwA3APZm5tl5kJbBtNwraeuutx7fZjZeTOjJ+3PoDDzzQs22aM42afuQMzJpGj59pUvO6lbO2rtaYmQ9n5p7AdsBzgF3b3UBEHBERyyNi+djYWIdlSsPPnEm9Ydak5pkzqTMzupR+Zt4DXAQ8D9gsIsZH3rYDVk2xztLMXJSZixYsWDCrYqVRYM6k3jBrUvPMmTQz7VytcauI2Kx+/ATgAOBqqqC9sl5sMXB2U0VKw86cSb1h1qTmmTOpc+2cc7YNcFJ97PAGwGmZeW5EXAV8NSKOBS4HTuxGQXfeeScAjzzySDdeTurIBhtU31tsuummvdqkOdPI6UPOwKxpBPmZJjWvWzmbtjnLzP8C9ppk+o1UxxBLmiVzJvWGWZOaZ86kzrV1tcZeuu++6sqra9as6XMlGmXz5s0Dev6Nfs+YM5Vg2HMGZk1lGPasmTOVoFs5m9EFQSRJkiRJzbA5kyRJkqQCFHtYY69/lFRq9YQnPKHfJTTKnKkEw54zMGsqw7BnzZypBN3KmSNnkiRJklSA4kbOrrzySgDuuuuuPleiUbblllsCsOOOO/a5kmaYM5Vg2HMGZk1lGPasmTOVoFs5c+RMkiRJkgpgcyZJkiRJBbA5kyRJkqQCFHfO2Ze//GXgseOHpX7YfffdATj00EP7XEkzzJlKMOw5A7OmMgx71syZStCtnDlyJkmSJEkFKG7kbPXq1QDceuutfa5Eo2z8ijvDypypBMOeMzBrKsOwZ82cqQTdypkjZ5IkSZJUgLabs4iYExGXR8S59fMdIuLSiLg+Ir4WERs1V6Y0GsyZ1DxzJvWGWZNmbiYjZ28Drm55fhzwyczcEbgbWNLNwqQRZc6k5pkzqTfMmjRDbTVnEbEd8FLghPp5AC8GzqgXOQk4rIkCpVFhzqTmmTOpN8ya1Jl2R84+BbwHeKR+viVwT2aurZ+vBLbtcm3SqDFnUvPMmdQbZk3qwLTNWUS8DLgjMy/rZAMRcURELI+I5WNjY528hDT0zJnUvNnmrH4NsyZNw880qXPtjJztA7w8Im4Gvko1JH08sFlEjF+Kfztg1WQrZ+bSzFyUmYsWLFjQhZKloWTOpObNKmdg1qQ2+ZkmdWja5iwzj87M7TJze+C1wHcz83XARcAr68UWA2c3VqU05MyZ1DxzJvWGWZM6N5vfOXsv8M6IuJ7qOOITu1OSpBbmTGqeOZN6w6xJ05g7/SKPyczvAd+rH98IPKf7JUmjzZxJzTNnUm+YNWlmZjNyJkmSJEnqEpszSZIkSSqAzZkkSZIkFcDmTJIkSZIKYHMmSZIkSQWwOZMkSZKkAticSZIkSVIBbM4kSZIkqQA2Z5IkSZJUAJszSZIkSSqAzZkkSZIkFcDmTJIkSZIKYHMmSZIkSQWY285CEXEzcC/wMLA2MxdFxBbA14DtgZuBV2fm3c2UKQ0/cyb1hlmTmmfOpM7MZOTsRZm5Z2Yuqp8fBSzLzJ2AZfVzSbNjzqTeMGtS88yZNENtjZxN4VDghfXjk4DvAe+dZT1qw+abbw7Aq171qkenLV26tF/lqFnmTOoNsyY1z5xJ02h35CyB70TEZRFxRD1tYWbeVj9eDSycbMWIOCIilkfE8rGxsVmWKw01cyb1hlmTmmfOpA60O3K2b2auioinABdExDWtMzMzIyInWzEzlwJLAZ797GdPuoxmZpNNNgHggAMOeHSaI2dDwZxJvWHWpOaZM6kDbY2cZeaq+v4O4CzgOcDtEbENQH1/R1NFSqPAnEm9Ydak5pkzqTPTNmcRMT8injj+GHgJcAVwDrC4XmwxcHZTRUrDzpxJvWHWpOaZM6lz7RzWuBA4KyLGl/9KZn47In4KnBYRS4BbgFc3V6ZarVq1Clj3giAaeOasz/bcc08AjjzyyHXuNXTMmtQ8cyZ1aNrmLDNvBPaYZPpdwH5NFCWNGnMm9YZZk5pnzqTOzeZS+pI0NO68804AfvCDH/S5Emk4fehDHwLg5JNPBuDGG2/sZzmSVKSZ/Ai1JEmSJKkhjpxJEo+dy3nKKaf0uRJJkmbmK1/5CgDve9/7ALj55pv7WI1mw5EzSZIkSSqAI2eSJKlxxxxzTL9LkIbWd7/7XQDuu+++Plei2XLkTJIkSZIK4MiZJEmSNMBOOOGEfpegLnHkTJIkSZIKYHMmSZIkSQWwOZMkSZKkAticSZIkSVIBbM4kSZIkqQBtNWcRsVlEnBER10TE1RHxvIjYIiIuiIjr6vvNmy5WGmbmTOoNsyY1z5xJnWl35Ox44NuZuSuwB3A1cBSwLDN3ApbVzyV1zpxJvWHWpOaZM6kD0zZnEfFk4PnAiQCZ+WBm3gMcCpxUL3YScFhTRUrDzpxJvWHWpOaZM6lz7Yyc7QDcCXwxIi6PiBMiYj6wMDNvq5dZDSxsqkhpBJgzqTfMmtQ8cyZ1qJ3mbC7wbOBzmbkX8DsmDENnZgI52coRcURELI+I5WNjY7OtVxpW5kzqDbMmNc+cSR1qpzlbCazMzEvr52dQBe72iNgGoL6/Y7KVM3NpZi7KzEULFizoRs3SMDJnUm+YNal55kzq0LTNWWauBm6NiF3qSfsBVwHnAIvraYuBsxupUBoB5kzqDbMmNc+cSZ2b2+ZybwVOiYiNgBuBN1A1dqdFxBLgFuDVzZQojQxzJvWGWZOaZ86kDrTVnGXmCmDRJLP262450ugyZ1JvmDWpeeZM6ky7v3MmSZIkSWqQzZkkSZIkFcDmTJIkSZIKYHMmSZIkSQWwOZMkSZKkAticSZIkSVIBbM4kSZIkqQA2Z5IkSZJUAJszSZIkSSqAzZkkSZIkFcDmTJIkSZIKYHMmSZIkSQWwOZMkSZKkAkzbnEXELhGxouX224h4e0RsEREXRMR19f3mvShYGkbmTOoNsyY1z5xJnZu2OcvMazNzz8zcE/hD4H7gLOAoYFlm7gQsq59L6oA5k3rDrEnNM2dS52Z6WON+wA2ZeQtwKHBSPf0k4LBuFiaNMHMm9YZZk5pnzqQZmGlz9lrg1Prxwsy8rX68GljYtaqk0WbOpN4wa1LzzJk0A203ZxGxEfBy4PSJ8zIzgZxivSMiYnlELB8bG+u4UGkUmDOpN8ya1DxzJs3cTEbODgZ+lpm3189vj4htAOr7OyZbKTOXZuaizFy0YCNJCrwAAAjJSURBVMGC2VUrDT9zJvWGWZOaZ86kGZpJc3Y4jw1LA5wDLK4fLwbO7lZR0ggzZ1JvmDWpeeZMmqG2mrOImA8cAHy9ZfJHgQMi4jpg//q5pA6ZM6k3zJrUPHMmdWZuOwtl5u+ALSdMu4vqCjySusCcSb1h1qTmmTOpMzO9WqMkSZIkqQE2Z5IkSZJUAJszSZIkSSqAzZkkSZIkFaCtC4J0yyOPPML9998/7TIqS0Q8+vilL33prF/v8ssvB2DVqlWzfq2mrF27FoA77pj0J1iKZs76b+utt3708aJFi2b9eueffz4ADz300KxfqySDnDMwa7O19957A7DVVlt1/Bq33Xbbo48vu+yyWdc0rNrN2vhyJTFnj/07rJv/BoOy/x02iLr1mebImSRJkiQVwOZMkiRJkgrQ08MaH374Ye65555pl1FZ5s597M/kne9856xf76MfrX5zsuTh9AcffBCAm266qc+VzJw567+dd9750cfdyMzFF18MDN9hjYOcMzBrs/WKV7wCmN2hv9///vcffexhjVNrN2tr1qzpRTkzYs4e+3dYN/8NBmX/O2wQdeszzZEzSZIkSSpAT0fONJhaTxA+8sgjZ/16rSdwS8PoZz/72aOPu5GZ6U6GlwbR8ccfD8D8+fM7fo177723W+VIxRr/d5j/BhsNjpxJkiRJUgEiM3u2sS222CIPPPDA9S4zfsnou+++uxclSd1wWWbO/nrpXWLONKSKyhmYNQ2nzIzpl+odc6YhNeVnWlsjZxHxjoi4MiKuiIhTI2LjiNghIi6NiOsj4msRsVF3a5ZGizmTesOsSc0zZ1Jnph05i4htgUuA3TLzgYg4DfgWcAjw9cz8akR8Hvh5Zn5umtfq3TCd1Duz/kbfnEnT6srImVmT1q8bI2fmTJrW7EbOqC4c8oSImAtsAtwGvBg4o55/EnDYbKuURpw5k3rDrEnNM2dSB6ZtzjJzFfBx4FdUwfoNcBlwT2aOX8ZvJbBtU0VKw86cSb1h1qTmmTOpc9M2ZxGxOXAosAPwVGA+cFC7G4iIIyJieUQs77hKaciZM6k3zJrUPHMmda6d3znbH7gpM+8EiIivA/sAm0XE3PobkO2ASX9mPDOXAkvrdT1uWJqcOZN6w6xJzTNnUofaOefsV8BzI2KTiAhgP+Aq4CLglfUyi4GzmylRGgnmTOoNsyY1z5xJHWrnnLNLqU7e/Bnwi3qdpcB7gXdGxPXAlsCJDdYpDTVzJvWGWZOaZ86kzvX0R6gdmtaQKurHcc2ZhlRROQOzpuFU2o9QmzMNqVlfSl+SJEmS1CCbM0mSJEkqgM2ZJEmSJBWgnUvpd9MY8Lv6fhAsYHBqhcGqd5hqfXqvCmnToOUMhuvvoSSDVCusv97ScgaDl7VB+nsYpFphsOo1Z80apL8FGKx6h6nWKbPW0wuCAETE8tJO6p7KINUKg1WvtTZr0GoepHqttTmDVi8MVs3W2pxBqneQah03SDUPUq0wWPWOSq0e1ihJkiRJBbA5kyRJkqQC9KM5W9qHbXZqkGqFwarXWps1aDUPUr3W2pxBqxcGq2Zrbc4g1TtItY4bpJoHqVYYrHpHotaen3MmSZIkSXo8D2uUJEmSpAL0rDmLiIMi4tqIuD4ijurVdtsVEU+LiIsi4qqIuDIi3lZP3yIiLoiI6+r7zftd67iImBMRl0fEufXzHSLi0noffy0iNup3jQARsVlEnBER10TE1RHxvML36zvqv4ErIuLUiNi41H07mZKzZs6aNUhZM2fNMWfNMme9U3LOwKw1aZByBt3NWk+as4iYA3wWOBjYDTg8InbrxbZnYC3wrszcDXgu8Ja6xqOAZZm5E7Csfl6KtwFXtzw/DvhkZu4I3A0s6UtVj3c88O3M3BXYg6rmIvdrRGwL/B2wKDOfCcwBXku5+3YdA5A1c9asgciaOWucOWuWOeuBAcgZmLUmDUTOoIGsZWbjN+B5wPktz48Gju7FtmdR89nAAcC1wDb1tG2Aa/tdW13LdlR/mC8GzgWC6sfu5k62z/tY55OBm6jPb2yZXup+3Ra4FdiC6kfazwUOLHHfTlH/QGXNnHW11oHJmjnreb3mrHu1mrPe1T9QOatrNGvdqXNgclbX0tWs9eqwxvGix62spxUpIrYH9gIuBRZm5m31rNXAwj6VNdGngPcAj9TPtwTuycy19fNS9vEOwJ3AF+th9BMiYj6F7tfMXAV8HPgVcBvwG+Ayyty3kxmYrJmzrhuYrJmz3jFnXWfOemdgcgZmrcsGJmfQ/ax5QZAJImJT4Ezg7Zn529Z5WbW+fb+8ZUS8DLgjMy/rdy1tmAs8G/hcZu4F/I4Jw9Cl7FeA+vjlQ6n+x/BUYD5wUF+LGkLmrBEDkzVz1hvmrBHmTI9j1rpuYHIG3c9ar5qzVcDTWp5vV08rSkRsSBWuUzLz6/Xk2yNim3r+NsAd/aqvxT7AyyPiZuCrVMPTxwObRcTceplS9vFKYGVmXlo/P4MqcCXuV4D9gZsy887MfAj4OtX+LnHfTqb4rJmzxgxS1sxZw8xZY8xZ7xSfMzBrDRmknEGXs9ar5uynwE71VUs2ojpJ7pwebbstERHAicDVmfmJllnnAIvrx4upjifuq8w8OjO3y8ztqfbldzPzdcBFwCvrxUqpdTVwa0TsUk/aD7iKAvdr7VfAcyNik/pvYrze4vbtFIrOmjlrzoBlzZw1yJw1x5z1VNE5A7PWlAHLGXQ7az08We4Q4JfADcD7e7XdGdS3L9Xw6H8BK+rbIVTH4y4DrgMuBLbod60T6n4hcG79+BnAT4DrgdOBef2ur65rT2B5vW+/AWxe8n4FPgxcA1wB/D9gXqn7dor6i82aOWu8zoHJmjlrtDZz1myd5qx39Rebs7o+s9ZcjQOTs7rermUt6heUJEmSJPWRFwSRJEmSpALYnEmSJElSAWzOJEmSJKkANmeSJEmSVACbM0mSJEkqgM2ZJEmSJBXA5kySJEmSCmBzJkmSJEkF+P990zmIcN2IuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def FrameStackEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = FrameStackEnv(game)\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1, 5):\n",
    "  # Führe eine zufällige Aktion aus\n",
    "  state, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Stack umformen, damit das Plotten der vier Bilder gelingt\n",
    "state = state.reshape(84, 84,4)\n",
    "\n",
    "# Frame Stack plotten\n",
    "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
    "fig.suptitle('Frame Stack', fontsize=20)\n",
    "for i in range(state.shape[2]):\n",
    "    axs[i].imshow(state[:, :, i], cmap=\"gray\")\n",
    "    axs[i].set_title(\"Frame \"+str(i+1), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1hORw-SrRKu"
   },
   "source": [
    "## Erstellen des Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uyVNp_0hrOPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTS/Breakout-v0/NoEpisodicLife_NoClipReward/\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    #env = EpisodicLifeEnv(env)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    env = NoopResetEnv(env)\n",
    "    #env = ClipRewardEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = make_env(game)\n",
    "\n",
    "\"\"\" saving the properties for csv \"\"\"\n",
    "\n",
    "MODE = \"NoEpisodicLife_NoClipReward\"\n",
    "PATH = \"WEIGHTS/\" + game + \"/\" + MODE + \"/\"\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uAIJ4QYrja0"
   },
   "source": [
    "# Actor Network und Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGNNFrCgr0MM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Network Parameter\n",
    "INPUT_SHAPE = (84, 84, 4) # (Höhe, Breite, Frames)\n",
    "ACTOR_OUTPUT = env.action_space.n # Anzahl der möglichen Aktionen\n",
    "CRITIC_OUTPUT = 1 # Bewertung der gewählten Aktion\n",
    "ACTOR_LEARNING_RATE = 0.0000004\n",
    "CRITIC_LEARNING_RATE = 0.0000004\n",
    "\n",
    "# neuronales Netz\n",
    "net_input = Input(shape=INPUT_SHAPE)\n",
    "x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)-\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "'''Aufspalten des Netzes in Actor und Critic'''\n",
    "\n",
    "# Actor - wählt eine Aktion\n",
    "actor_x = Dense(ACTOR_OUTPUT)(x)\n",
    "actor_output = Activation(\"softmax\")(actor_x)\n",
    "\n",
    "ACTOR = Model(inputs=net_input, outputs=actor_output)\n",
    "ACTOR.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=ACTOR_LEARNING_RATE))\n",
    "\n",
    "# Critic - bewertet gewählte Aktion\n",
    "critic_x = Dense(CRITIC_OUTPUT)(x)\n",
    "critic_output = Activation(\"linear\")(critic_x)\n",
    "\n",
    "CRITIC = Model(inputs=net_input, outputs=critic_output)\n",
    "CRITIC.compile(loss=\"mse\", optimizer=Adam(lr=CRITIC_LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aktion wählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state):\n",
    "    policy = ACTOR.predict(state)[0]\n",
    "    action = np.random.choice(env.action_space_n, p=policy) # Aktionen, welche Wahrscheinlichkeit zu Aktion\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "\n",
    "def update_policy(state, action, reward, next_state, done):\n",
    "    values = np.zeros(shape=(1, CRITIC_OUTPUT))\n",
    "    advantages = np.zeros(shape=(1, ACTOR_OUTPUT))\n",
    "    \n",
    "    # State bewerten\n",
    "    value = CRITIC.predict(state)[0]\n",
    "    next_value = CRTITIC.predict(next_state)[0]\n",
    "    \n",
    "    if done:\n",
    "        advantages[0][action] = reward - value\n",
    "        values[0][0] = reward\n",
    "    else:\n",
    "        advantages[0][action] = (reward + GAMMA * next_value) - value\n",
    "        values[0][0] = reward + GAMMA * next_value\n",
    "        \n",
    "    # Trainieren der Netze\n",
    "    ACTOR.fit(state, advantages)\n",
    "    CRITIC.fit(state, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training /Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Mean Reward -> Mean Reward kann nich auf 0 gesetzt werden (Pong -21)\n",
    "INITIAL_MEAN_REWARD = 0.0\n",
    "env.reset()\n",
    "while True:\n",
    "    _, reward, done, _ = env.step(env.action_space.sample())\n",
    "    INITIAL_MEAN_REWARD += reward\n",
    "    if done:\n",
    "        break\n",
    "INITIAL_MEAN_REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 15000\n",
    "REWARD_LIST = []\n",
    "MEAN_LIST = []\n",
    "BEST_MEAN_REWARD = INITIAL_MEAN_REWARD\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    EPISODE_REWARD = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Transition im MEMORY BUFFER speichern\n",
    "        update_policy(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Reward einer Aktion zum gesamten Reward der Episode addieren\n",
    "        EPISODE_REWARD += reward\n",
    "        \n",
    "        # State aktualisieren\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            REWARD_LIST.append(EPISODE_REWARD)\n",
    "            current_mean_reward = np.mean(REWARD_LIST[-min(len(REWARD_LIST), 10):])\n",
    "            MEAN_LIST.append(np.mean(REWARD_LIST))\n",
    "            \n",
    "            print(\"Episode:\", episode+1, \"\\tReward:\", EPISODE_REWARD, \"\\tMean:\", round(current_mean_reward, 2),\"\\tBestMean:\", BEST_MEAN_REWARD)\n",
    "\n",
    "            # Übernahme des höchsteb Mean Rewards\n",
    "            if current_mean_reward > BEST_MEAN_REWARD:\n",
    "                BEST_MEAN_REWARD = current_mean_reward\n",
    "        \n",
    "                # Trainierte Gewichte speichern\n",
    "                if EPSILON < 0.3:\n",
    "                    import os\n",
    "                    try:\n",
    "                        os.makedirs(PATH)\n",
    "                    except FileExistsError:\n",
    "                        # Pfad existiert bereits\n",
    "                        pass\n",
    "                    ACTOR.save_weights(PATH + \"Ep_\" + str(episode+1) + \"_ACTOR.h5\")\n",
    "                    CRITIC.save_weights(PATH + \"Ep_\" + str(episode+1) + \"_CRITIC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "date = datetime.now().date()\n",
    "\n",
    "df = pd.DataFrame(list(zip(REWARD_LIST, MEAN_LIST)), \n",
    "               columns =['Rewards', 'Mean Reward']) \n",
    "df.to_csv(PATH + game + \"_\" + str(date) + \"_\"+ MODE + \".csv\", mode=\"w\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR.save_weights(PATH + \"_End.h5\")\n",
    "CRITIC.save_weights(PATH + \"_End.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "plt.plot(REWARD_LIST, label=\"erhaltene Rewards\")\n",
    "plt.plot(MEAN_LIST, label=\"durchschnittler Reward\")\n",
    "plt.title(\"Rewards während des Trainings\", fontsize=25)\n",
    "plt.xlabel(\"Episoden\", fontsize=20)\n",
    "plt.ylabel(\"Rewards\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "\n",
    "for i in range(1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = np.argmax(DQN.predict(state))\n",
    "        state, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDGR1zCBmbYW1JLGGFeyLF",
   "collapsed_sections": [],
   "name": "A2C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
