{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Kopie von A2C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOafjdahyQ4x"
      },
      "source": [
        "# TODO:\n",
        "* Wrapper for reward clipping to [-1, 1] (same reason like image normalization)\n",
        "* checking hyperparameters from paper\n",
        "* checking used parameters\n",
        "* * Adding results to a Dataframe and save to hard drive (to compare with other models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s7lP8w_qT-g"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMmeQkfjMtNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1002bc-8948-488b-f875-77d938bc4816"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 24 08:27:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    35W / 250W |    843MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isafSyFJqqbC"
      },
      "source": [
        "# Auswahl des Spiels\n",
        "\n",
        "[Hier](https://gym.openai.com/envs/#atari) ist eine vollständige Liste der verfügbaren Spiele zu finden. Um ein Environment zu erstellen muss der vollständige Name des Spiels als String übergeben werden.\n",
        "\n",
        "Beispiel:\n",
        "\n",
        "```python\n",
        "game = \"MsPacman-v0\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oFwznyfqtY8"
      },
      "source": [
        "# Hier kann das Spiel übergeben werden\n",
        "game = \"Breakout-v0\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZFpCCiUqxec"
      },
      "source": [
        "# **Preprocessing**\n",
        "[Stable Baselines](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K56-9gA8q2cM"
      },
      "source": [
        "## Fire Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7xfJ9C1q47O"
      },
      "source": [
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.Wrapper.__init__(self, env) \n",
        "        self.env.reset()\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        observation, _, _, _ = self.env.step(env.unwrapped.get_action_meanings().index('FIRE'))\n",
        "\n",
        "        return observation"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUX3_jS2MtNx"
      },
      "source": [
        "## Max And Skip Env Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGNoWqC6MtNy"
      },
      "source": [
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
        "        self._skip       = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
        "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        # Note that the observation on the done=True frame\n",
        "        # doesn't matter\n",
        "        max_frame = self._obs_buffer.max(axis=0)\n",
        "\n",
        "        return max_frame, total_reward, done, info\n",
        "    \n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzhr2UTyMtNz"
      },
      "source": [
        "## Noop Reset Env Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHDVQS_nMtN0"
      },
      "source": [
        "class NoopResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env, noop_max=30):\n",
        "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
        "        No-op is assumed to be action 0.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.noop_max = noop_max\n",
        "        self.override_num_noops = None\n",
        "        self.noop_action = 0\n",
        "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
        "        self.env.reset(**kwargs)\n",
        "        if self.override_num_noops is not None:\n",
        "            noops = self.override_num_noops\n",
        "        else:\n",
        "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
        "        assert noops > 0\n",
        "        obs = None\n",
        "        for _ in range(noops):\n",
        "            obs, _, done, _ = self.env.step(self.noop_action)\n",
        "            if done:\n",
        "                obs = self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Csj73MlMtN1"
      },
      "source": [
        "## Scaled Float Frame Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBYeRdvrMtN1"
      },
      "source": [
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # careful! This undoes the memory optimization, use\n",
        "        # with smaller replay buffers only.\n",
        "        return np.array(observation).astype(np.float32) / 255.0"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vd03Hv1MtN2"
      },
      "source": [
        "## Episodic Life Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3_tCT4fMtN2"
      },
      "source": [
        "class EpisodicLifeEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
        "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.lives = 0\n",
        "        self.was_real_done  = True\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        self.was_real_done = done\n",
        "        # check current lives, make loss of life terminal,\n",
        "        # then update lives to handle bonus lives\n",
        "        lives = self.env.unwrapped.ale.lives()\n",
        "        if lives < self.lives and lives > 0:\n",
        "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
        "            # so it's important to keep lives > 0, so that we only reset once\n",
        "            # the environment advertises done.\n",
        "            done = True\n",
        "        self.lives = lives\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\"Reset only when lives are exhausted.\n",
        "        This way all states are still reachable even though lives are episodic,\n",
        "        and the learner need not know about any of this behind-the-scenes.\n",
        "        \"\"\"\n",
        "        if self.was_real_done:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            # no-op step to advance from terminal/lost life state\n",
        "            obs, _, _, _ = self.env.step(0)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        return obs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_zaDmRJMtN4"
      },
      "source": [
        "## Clip Reward Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTsOOYyEMtN5"
      },
      "source": [
        "class ClipRewardEnv(gym.RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        gym.RewardWrapper.__init__(self, env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
        "        return np.sign(reward)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukAIUaihrUBd"
      },
      "source": [
        "## Resize & Grayscale Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFE3KyHWrN-1"
      },
      "source": [
        "from gym import spaces\n",
        "import cv2\n",
        "\n",
        "class WarpFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"\n",
        "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
        "        :param env: (Gym Environment) the environment\n",
        "        \"\"\"\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.width = 84\n",
        "        self.height = 84\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1),\n",
        "                                            dtype=env.observation_space.dtype)\n",
        "        \n",
        "    def observation(self, frame):\n",
        "        \"\"\"\n",
        "        returns the current observation from a frame\n",
        "        :param frame: ([int] or [float]) environment frame\n",
        "        :return: ([int] or [float]) the observation\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
        "        return frame[:, :, None]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "kb1LXTXKs6qH",
        "outputId": "df0e09e1-a2f7-4c46-8cc7-9f6d35fcd6f0"
      },
      "source": [
        "\"\"\" \n",
        "[OPTIONAL]\n",
        "\n",
        "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
        "Die Zelle hat keinen Einfluss auf den Agenten\n",
        "\"\"\"\n",
        "\n",
        "def WarpFrameEnv(env_name):\n",
        "    env = gym.make(env_name)\n",
        "    env = WarpFrame(env)\n",
        "    return env\n",
        "\n",
        "normal_env = gym.make(game)\n",
        "wrapped_env = WarpFrameEnv(game)\n",
        "\n",
        "normal_env.reset()\n",
        "wrapped_env.reset()\n",
        "action = normal_env.action_space.sample()\n",
        "\n",
        "normal_state, _, _, _ = normal_env.step(action)\n",
        "wrapped_state, _, _, _ = wrapped_env.step(action)\n",
        "\n",
        "wrapped_state = wrapped_state[: , :, 0]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "fig.suptitle('Warp Frame', fontsize=20)\n",
        "axs[0].imshow(normal_state)\n",
        "axs[0].set_title(\"Normal\", fontsize=16)\n",
        "axs[1].imshow(wrapped_state, cmap=\"gray\")\n",
        "axs[1].set_title(\"Warp Frame\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjZQ6BOPq90B"
      },
      "source": [
        "## Frame Stack Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYTs63ANrFyb"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class FrameStack(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.frames = deque(maxlen=4)\n",
        "        low = np.repeat(self.observation_space.low[np.newaxis, ...], repeats=4, axis=0)\n",
        "        high = np.repeat(self.observation_space.high[np.newaxis, ...], repeats=4, axis=0)\n",
        "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=self.observation_space.dtype)\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "        self.frames.append(obs)\n",
        "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
        "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
        "        return frame_stack, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs = self.env.reset(**kwargs)\n",
        "        for _ in range(4):\n",
        "            self.frames.append(obs)\n",
        "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
        "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
        "        return frame_stack"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "BFsMn2h-s04j",
        "outputId": "fca0dc94-9a39-4ee7-f49c-face6fa53783"
      },
      "source": [
        "\"\"\"\n",
        "[OPTIONAL]\n",
        "\n",
        "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
        "Die Zelle hat keinen Einfluss auf den Agenten\n",
        "\"\"\"\n",
        "\n",
        "def FrameStackEnv(env_name):\n",
        "    env = gym.make(env_name)\n",
        "    env = WarpFrame(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = FrameStack(env)\n",
        "    return env\n",
        "\n",
        "env = FrameStackEnv(game)\n",
        "env.reset()\n",
        "\n",
        "for _ in range(1, 5):\n",
        "  # Führe eine zufällige Aktion aus\n",
        "  state, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "# Stack umformen, damit das Plotten der vier Bilder gelingt\n",
        "state = state.reshape(84, 84,4)\n",
        "\n",
        "# Frame Stack plotten\n",
        "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
        "fig.suptitle('Frame Stack', fontsize=20)\n",
        "for i in range(state.shape[2]):\n",
        "    axs[i].imshow(state[:, :, i], cmap=\"gray\")\n",
        "    axs[i].set_title(\"Frame \"+str(i+1), fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1hORw-SrRKu"
      },
      "source": [
        "## Erstellen des Environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyVNp_0hrOPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8359ff-a4cd-476d-ebbb-11a913d9b586"
      },
      "source": [
        "def make_env(env_name):\n",
        "    env = gym.make(env_name)\n",
        "    #env = EpisodicLifeEnv(env)\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = ScaledFloatFrame(env)\n",
        "    env = NoopResetEnv(env)\n",
        "    #env = ClipRewardEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = FrameStack(env)\n",
        "    return env\n",
        "\n",
        "env = make_env(game)\n",
        "\n",
        "\"\"\" saving the properties for csv \"\"\"\n",
        "\n",
        "MODE = \"NoEpisodicLife_NoClipReward_lr_1e-3_5e-3\"\n",
        "PATH = \"WEIGHTS/\" + game + \"/\" + MODE + \"/\"\n",
        "print(PATH)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WEIGHTS/Breakout-v0/NoEpisodicLife_NoClipReward_lr_1e-3_5e-3/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uAIJ4QYrja0"
      },
      "source": [
        "# Actor Network und Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNNFrCgr0MM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Network Parameter\n",
        "INPUT_SHAPE = (84, 84, 4) # (Höhe, Breite, Frames)\n",
        "ACTOR_OUTPUT = env.action_space.n # Anzahl der möglichen Aktionen\n",
        "CRITIC_OUTPUT = 1 # Bewertung der gewählten Aktion\n",
        "ACTOR_LEARNING_RATE = 25e-6\n",
        "CRITIC_LEARNING_RATE = 25e-6\n",
        "\n",
        "# neuronales Netz\n",
        "net_input = Input(shape=INPUT_SHAPE)\n",
        "x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "'''Aufspalten des Netzes in Actor und Critic'''\n",
        "\n",
        "# Actor - wählt eine Aktion\n",
        "actor_x = Dense(ACTOR_OUTPUT)(x)\n",
        "actor_output = Activation(\"softmax\")(actor_x)\n",
        "\n",
        "ACTOR = Model(inputs=net_input, outputs=actor_output)\n",
        "ACTOR.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=ACTOR_LEARNING_RATE))\n",
        "\n",
        "# Critic - bewertet gewählte Aktion\n",
        "critic_x = Dense(CRITIC_OUTPUT)(x)\n",
        "critic_output = Activation(\"linear\")(critic_x)\n",
        "\n",
        "CRITIC = Model(inputs=net_input, outputs=critic_output)\n",
        "CRITIC.compile(loss=\"mse\", optimizer=Adam(lr=CRITIC_LEARNING_RATE))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30U2V0CMtN_"
      },
      "source": [
        "# Aktion wählen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEwfPKljMtN_"
      },
      "source": [
        "def get_action(state):\n",
        "    policy = ACTOR.predict(state)[0]\n",
        "    action = np.random.choice(env.action_space.n, p=policy) # Aktionen, welche Wahrscheinlichkeit zu Aktion\n",
        "    return action, policy"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLfgqEutNr10"
      },
      "source": [
        "def remember (state, action, reward):\n",
        "    STATES.append(state)\n",
        "    # Erstellen eines One Hot Labels für die Aktion\n",
        "    action_onehot = np.zeros([env.action_space.n])\n",
        "    action_onehot[action] = 1\n",
        "    ACTIONS.append(action_onehot)\n",
        "    REWARDS.append(reward)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRPapa6lR4-K"
      },
      "source": [
        "def discount_rewards(rewards):\n",
        "    gamma = 0.99\n",
        "    running_add = 0\n",
        "    discounted_r = np.zeros_like(rewards)\n",
        "    for i in reversed(range(0, len(rewards))):\n",
        "        if rewards[i] != 0: # Pong\n",
        "            running_add = 0\n",
        "        running_add = running_add * gamma + rewards[i]\n",
        "        discounted_r[i] = running_add\n",
        "\n",
        "    discounted_r -= np.mean(discounted_r) # normalisieren\n",
        "    discounted_r /= np.std(discounted_r) # teilen durch Standardabweichung\n",
        "\n",
        "    return discounted_r"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3SGt8rvRTPT"
      },
      "source": [
        "def replay_episode(STATES, ACTIONS, REWARDS):\n",
        "    states = np.vstack(STATES)\n",
        "    actions = np.vstack(ACTIONS)\n",
        "\n",
        "    # discount rewards\n",
        "    discounted_r = discount_rewards(REWARDS)\n",
        "\n",
        "    # Critic predictions\n",
        "    values = CRITIC.predict(states)[:, 0]\n",
        "\n",
        "    # Advantagewerte berechnen\n",
        "    advantages = discounted_r - values\n",
        "\n",
        "    # Trainieren der Netzwerke ACTOR und CRITIC\n",
        "    ACTOR.fit(states, actions, sample_weight=advantages, epochs=1, verbose=0)\n",
        "    CRITIC.fit(states, discounted_r, epochs=1, verbose=0)\n",
        "\n",
        "    # leeren des Episoden Buffers\n",
        "    STATES, ACTIONS, REWARDS = [], [], []"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwLX4bvUMtOA"
      },
      "source": [
        "# Training /Spielen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV_l4s5aMtOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dfdb8a8-f590-44df-a460-124c11c396d4"
      },
      "source": [
        "# Initial Mean Reward -> Mean Reward kann nich auf 0 gesetzt werden (Pong -21)\n",
        "INITIAL_MEAN_REWARD = 0.0\n",
        "env.reset()\n",
        "while True:\n",
        "    _, reward, done, _ = env.step(env.action_space.sample())\n",
        "    INITIAL_MEAN_REWARD += reward\n",
        "    if done:\n",
        "        break\n",
        "INITIAL_MEAN_REWARD"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHmDN4bMtOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78075f13-7208-4760-d7ca-46b75c91af46"
      },
      "source": [
        "EPISODES = 10_000\n",
        "REWARD_LIST = []\n",
        "MEAN_LIST = []\n",
        "BEST_MEAN_REWARD = INITIAL_MEAN_REWARD\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    EPISODE_REWARD = 0.0\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    # Episoden Buffer\n",
        "    STATES, ACTIONS, REWARDS = [], [], []\n",
        "    \n",
        "    while not done:\n",
        "        action, policy = get_action(state)\n",
        "        print(action)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        \n",
        "        # Transition im Episoden Buffer speichern\n",
        "        remember(state, action, reward)\n",
        "\n",
        "        # aktualisieren des States\n",
        "        state = next_state\n",
        "        \n",
        "        # Reward einer Aktion zum gesamten Reward der Episode addieren\n",
        "        EPISODE_REWARD += reward\n",
        "\n",
        "\n",
        "        if done:\n",
        "            REWARD_LIST.append(EPISODE_REWARD)\n",
        "            current_mean_reward = np.mean(REWARD_LIST[-min(len(REWARD_LIST), 10):])\n",
        "            MEAN_LIST.append(np.mean(REWARD_LIST))\n",
        "            \n",
        "            print(\"Episode:\", episode+1, \"\\tReward:\", EPISODE_REWARD, \"\\tMean:\", round(current_mean_reward, 2),\"\\tBestMean:\", BEST_MEAN_REWARD)\n",
        "\n",
        "            # Übernahme des höchsten Mean Rewards\n",
        "            if current_mean_reward > BEST_MEAN_REWARD:\n",
        "                BEST_MEAN_REWARD = current_mean_reward\n",
        "        \n",
        "                # trainierte Gewichte speichern\n",
        "                import os\n",
        "                try:\n",
        "                    os.makedirs(PATH)\n",
        "                except FileExistsError:\n",
        "                    # Pfad existiert bereits\n",
        "                    pass\n",
        "                ACTOR.save_weights(PATH + \"Best_ACTOR.h5\")\n",
        "                CRITIC.save_weights(PATH + \"Best_CRITIC.h5\")\n",
        "\n",
        "            replay_episode(STATES, ACTIONS, REWARDS)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "0\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "0\n",
            "3\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "3\n",
            "1\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "3\n",
            "3\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "3\n",
            "1\n",
            "3\n",
            "3\n",
            "3\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "3\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "3\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "0\n",
            "0\n",
            "3\n",
            "2\n",
            "1\n",
            "3\n",
            "0\n",
            "0\n",
            "3\n",
            "0\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "3\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "3\n",
            "1\n",
            "0\n",
            "2\n",
            "3\n",
            "1\n",
            "0\n",
            "3\n",
            "Episode: 1 \tReward: 4.0 \tMean: 4.0 \tBestMean: 0.0\n",
            "0\n",
            "3\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "0\n",
            "0\n",
            "3\n",
            "1\n",
            "2\n",
            "2\n",
            "3\n",
            "2\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "0\n",
            "3\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "3\n",
            "0\n",
            "3\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "1\n",
            "0\n",
            "Episode: 2 \tReward: 0.0 \tMean: 2.0 \tBestMean: 4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e5eb2ab5723a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-c48b9ff99c69>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTOR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Aktionen, welche Wahrscheinlichkeit zu Aktion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-k4snaUMtOB"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "date = datetime.now().date()\n",
        "\n",
        "df = pd.DataFrame(list(zip(REWARD_LIST, MEAN_LIST)), \n",
        "               columns =['Rewards', 'Mean Reward']) \n",
        "df.to_csv(PATH + game + \"_\" + str(date) + \"_\"+ MODE + \".csv\", mode=\"w\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1FmesqdMtOB"
      },
      "source": [
        "ACTOR.save_weights(PATH + \"End.h5\")\n",
        "CRITIC.save_weights(PATH + \"End.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKSlrmpRMtOC"
      },
      "source": [
        "# Auswertung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzDVaCvDMtOC"
      },
      "source": [
        "plt.figure(figsize=(25, 12))\n",
        "plt.plot(REWARD_LIST, label=\"erhaltene Rewards\")\n",
        "plt.plot(MEAN_LIST, label=\"durchschnittler Reward\")\n",
        "plt.title(\"Rewards während des Trainings\", fontsize=25)\n",
        "plt.xlabel(\"Episoden\", fontsize=20)\n",
        "plt.ylabel(\"Rewards\", fontsize=20)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqvMdh7kMtOC"
      },
      "source": [
        "# Spielen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s23zjIfZMtOD"
      },
      "source": [
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib\n",
        "\n",
        "for i in range(1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        img = plt.imshow(env.render(mode='rgb_array'))\n",
        "        img.set_data(env.render(mode='rgb_array'))\n",
        "        display.display(plt.gcf())\n",
        "        display.clear_output(wait=True)\n",
        "        action = np.argmax(ACTOR.predict(state))\n",
        "        state, reward, done, info = env.step(action)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}