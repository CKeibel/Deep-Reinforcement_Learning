{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOafjdahyQ4x"
   },
   "source": [
    "# TODO:\n",
    "* Wrapper for reward clipping to [-1, 1] (same reason like image normalization)\n",
    "* checking hyperparameters from paper\n",
    "* checking used parameters\n",
    "* * Adding results to a Dataframe and save to hard drive (to compare with other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6s7lP8w_qT-g"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 30 07:54:05 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 23%   28C    P8     8W / 250W |  11861MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isafSyFJqqbC"
   },
   "source": [
    "# Auswahl des Spiels\n",
    "\n",
    "[Hier](https://gym.openai.com/envs/#atari) ist eine vollständige Liste der verfügbaren Spiele zu finden. Um ein Environment zu erstellen muss der vollständige Name des Spiels als String übergeben werden.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "```python\n",
    "game = \"MsPacman-v0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9oFwznyfqtY8"
   },
   "outputs": [],
   "source": [
    "# Hier kann das Spiel übergeben werden\n",
    "game = \"Breakout-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZFpCCiUqxec"
   },
   "source": [
    "# **Preprocessing**\n",
    "[Stable Baselines](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K56-9gA8q2cM"
   },
   "source": [
    "## Fire Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7xfJ9C1q47O"
   },
   "outputs": [],
   "source": [
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env) \n",
    "        self.env.reset()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        observation, _, _, _ = self.env.step(env.unwrapped.get_action_meanings().index('FIRE'))\n",
    "\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max And Skip Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noop Reset Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Float Frame Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic Life Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
    "            # so it's important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Reward Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukAIUaihrUBd"
   },
   "source": [
    "## Resize & Grayscale Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IFE3KyHWrN-1"
   },
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import cv2\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        :param env: (Gym Environment) the environment\n",
    "        \"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1),\n",
    "                                            dtype=env.observation_space.dtype)\n",
    "        \n",
    "    def observation(self, frame):\n",
    "        \"\"\"\n",
    "        returns the current observation from a frame\n",
    "        :param frame: ([int] or [float]) environment frame\n",
    "        :return: ([int] or [float]) the observation\n",
    "        \"\"\"\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "kb1LXTXKs6qH",
    "outputId": "77e5d9bf-5428-4c85-e81f-9bedb73fe478"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def WarpFrameEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    return env\n",
    "\n",
    "normal_env = gym.make(game)\n",
    "wrapped_env = WarpFrameEnv(game)\n",
    "\n",
    "normal_env.reset()\n",
    "wrapped_env.reset()\n",
    "action = normal_env.action_space.sample()\n",
    "\n",
    "normal_state, _, _, _ = normal_env.step(action)\n",
    "wrapped_state, _, _, _ = wrapped_env.step(action)\n",
    "\n",
    "wrapped_state = wrapped_state[: , :, 0]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.suptitle('Warp Frame', fontsize=20)\n",
    "axs[0].imshow(normal_state)\n",
    "axs[0].set_title(\"Normal\", fontsize=16)\n",
    "axs[1].imshow(wrapped_state, cmap=\"gray\")\n",
    "axs[1].set_title(\"Warp Frame\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjZQ6BOPq90B"
   },
   "source": [
    "## Frame Stack Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qYTs63ANrFyb"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.frames = deque(maxlen=4)\n",
    "        low = np.repeat(self.observation_space.low[np.newaxis, ...], repeats=4, axis=0)\n",
    "        high = np.repeat(self.observation_space.high[np.newaxis, ...], repeats=4, axis=0)\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=self.observation_space.dtype)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        for _ in range(4):\n",
    "            self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "BFsMn2h-s04j",
    "outputId": "1b951e75-af6d-41d4-ab34-911969d424b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def FrameStackEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = FrameStackEnv(game)\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1, 5):\n",
    "  # Führe eine zufällige Aktion aus\n",
    "  state, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Stack umformen, damit das Plotten der vier Bilder gelingt\n",
    "state = state.reshape(84, 84,4)\n",
    "\n",
    "# Frame Stack plotten\n",
    "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
    "fig.suptitle('Frame Stack', fontsize=20)\n",
    "for i in range(state.shape[2]):\n",
    "    axs[i].imshow(state[:, :, i], cmap=\"gray\")\n",
    "    axs[i].set_title(\"Frame \"+str(i+1), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1hORw-SrRKu"
   },
   "source": [
    "## Erstellen des Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uyVNp_0hrOPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTS/Breakout-v0/NoEpisodicLife_NoClipReward/\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    #env = EpisodicLifeEnv(env)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    env = NoopResetEnv(env)\n",
    "    #env = ClipRewardEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = make_env(game)\n",
    "\n",
    "\"\"\" saving the properties for csv \"\"\"\n",
    "\n",
    "MODE = \"NoEpisodicLife_NoClipReward\"\n",
    "PATH = \"WEIGHTS/\" + game + \"/\" + MODE + \"/\"\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uAIJ4QYrja0"
   },
   "source": [
    "# Actor Network und Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGNNFrCgr0MM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Network Parameter\n",
    "INPUT_SHAPE = (84, 84, 4) # (Höhe, Breite, Frames)\n",
    "ACTOR_OUTPUT = env.action_space.n # Anzahl der möglichen Aktionen\n",
    "CRITIC_OUTPUT = 1 # Bewertung der gewählten Aktion\n",
    "ACTOR_LEARNING_RATE = 0.0000004\n",
    "CRITIC_LEARNING_RATE = 0.0000004\n",
    "\n",
    "# neuronales Netz\n",
    "net_input = Input(shape=INPUT_SHAPE)\n",
    "x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "'''Aufspalten des Netzes in Actor und Critic'''\n",
    "\n",
    "# Actor - wählt eine Aktion\n",
    "actor_x = Dense(ACTOR_OUTPUT)(x)\n",
    "actor_output = Activation(\"softmax\")(actor_x)\n",
    "\n",
    "ACTOR = Model(inputs=net_input, outputs=actor_output)\n",
    "ACTOR.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=ACTOR_LEARNING_RATE))\n",
    "\n",
    "# Critic - bewertet gewählte Aktion\n",
    "critic_x = Dense(CRITIC_OUTPUT)(x)\n",
    "critic_output = Activation(\"linear\")(critic_x)\n",
    "\n",
    "CRITIC = Model(inputs=net_input, outputs=critic_output)\n",
    "CRITIC.compile(loss=\"mse\", optimizer=Adam(lr=CRITIC_LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aktion wählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state):\n",
    "    policy = ACTOR.predict(state)[0]\n",
    "    action = np.random.choice(env.action_space.n, p=policy) # Aktionen, welche Wahrscheinlichkeit zu Aktion\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "\n",
    "def update_policy(state, action, reward, next_state, done):\n",
    "    values = np.zeros(shape=(1, CRITIC_OUTPUT))\n",
    "    advantages = np.zeros(shape=(1, ACTOR_OUTPUT))\n",
    "    \n",
    "    # State bewerten\n",
    "    value = CRITIC.predict(state)[0]\n",
    "    next_value = CRITIC.predict(next_state)[0]\n",
    "    \n",
    "    if done:\n",
    "        advantages[0][action] = reward - value\n",
    "        values[0][0] = reward\n",
    "    else:\n",
    "        advantages[0][action] = (reward + GAMMA * next_value) - value\n",
    "        values[0][0] = reward + GAMMA * next_value\n",
    "        \n",
    "    # Trainieren der Netze\n",
    "    ACTOR.fit(state, advantages, verbose=0)\n",
    "    CRITIC.fit(state, values, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training /Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Mean Reward -> Mean Reward kann nich auf 0 gesetzt werden (Pong -21)\n",
    "INITIAL_MEAN_REWARD = 0.0\n",
    "env.reset()\n",
    "while True:\n",
    "    _, reward, done, _ = env.step(env.action_space.sample())\n",
    "    INITIAL_MEAN_REWARD += reward\n",
    "    if done:\n",
    "        break\n",
    "INITIAL_MEAN_REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 15000\n",
    "REWARD_LIST = []\n",
    "MEAN_LIST = []\n",
    "BEST_MEAN_REWARD = INITIAL_MEAN_REWARD\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    EPISODE_REWARD = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Transition im MEMORY BUFFER speichern\n",
    "        update_policy(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Reward einer Aktion zum gesamten Reward der Episode addieren\n",
    "        EPISODE_REWARD += reward\n",
    "        \n",
    "        # State aktualisieren\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            REWARD_LIST.append(EPISODE_REWARD)\n",
    "            current_mean_reward = np.mean(REWARD_LIST[-min(len(REWARD_LIST), 10):])\n",
    "            MEAN_LIST.append(np.mean(REWARD_LIST))\n",
    "            \n",
    "            print(\"Episode:\", episode+1, \"\\tReward:\", EPISODE_REWARD, \"\\tMean:\", round(current_mean_reward, 2),\"\\tBestMean:\", BEST_MEAN_REWARD)\n",
    "\n",
    "            # Übernahme des höchsteb Mean Rewards\n",
    "            if current_mean_reward > BEST_MEAN_REWARD:\n",
    "                BEST_MEAN_REWARD = current_mean_reward\n",
    "        \n",
    "                # Trainierte Gewichte speichern\n",
    "                import os\n",
    "                try:\n",
    "                    os.makedirs(PATH)\n",
    "                except FileExistsError:\n",
    "                    # Pfad existiert bereits\n",
    "                    pass\n",
    "                ACTOR.save_weights(PATH + \"Best_ACTOR.h5\")\n",
    "                CRITIC.save_weights(PATH + \"Best_CRITIC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "date = datetime.now().date()\n",
    "\n",
    "df = pd.DataFrame(list(zip(REWARD_LIST, MEAN_LIST)), \n",
    "               columns =['Rewards', 'Mean Reward']) \n",
    "df.to_csv(PATH + game + \"_\" + str(date) + \"_\"+ MODE + \".csv\", mode=\"w\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR.save_weights(PATH + \"End.h5\")\n",
    "CRITIC.save_weights(PATH + \"End.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "plt.plot(REWARD_LIST, label=\"erhaltene Rewards\")\n",
    "plt.plot(MEAN_LIST, label=\"durchschnittler Reward\")\n",
    "plt.title(\"Rewards während des Trainings\", fontsize=25)\n",
    "plt.xlabel(\"Episoden\", fontsize=20)\n",
    "plt.ylabel(\"Rewards\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "\n",
    "for i in range(1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = np.argmax(DQN.predict(state))\n",
    "        state, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNDGR1zCBmbYW1JLGGFeyLF",
   "collapsed_sections": [],
   "name": "A2C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
