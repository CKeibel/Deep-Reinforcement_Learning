{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOafjdahyQ4x"
   },
   "source": [
    "# TODO:\n",
    "* Wrapper for reward clipping to [-1, 1] (same reason like image normalization)\n",
    "* checking hyperparameters from paper\n",
    "* checking used parameters\n",
    "* * Adding results to a Dataframe and save to hard drive (to compare with other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6s7lP8w_qT-g"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMmeQkfjMtNo",
    "outputId": "9b1002bc-8948-488b-f875-77d938bc4816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  8 04:56:35 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    60W / 149W |  10707MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isafSyFJqqbC"
   },
   "source": [
    "# Auswahl des Spiels\n",
    "\n",
    "[Hier](https://gym.openai.com/envs/#atari) ist eine vollständige Liste der verfügbaren Spiele zu finden. Um ein Environment zu erstellen muss der vollständige Name des Spiels als String übergeben werden.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "```python\n",
    "game = \"MsPacman-v0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9oFwznyfqtY8"
   },
   "outputs": [],
   "source": [
    "# Hier kann das Spiel übergeben werden\n",
    "game = \"Breakout-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZFpCCiUqxec"
   },
   "source": [
    "# **Preprocessing**\n",
    "[Stable Baselines](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K56-9gA8q2cM"
   },
   "source": [
    "## Fire Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H7xfJ9C1q47O"
   },
   "outputs": [],
   "source": [
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env) \n",
    "        self.env.reset()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        observation, _, _, _ = self.env.step(env.unwrapped.get_action_meanings().index('FIRE'))\n",
    "\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUX3_jS2MtNx"
   },
   "source": [
    "## Max And Skip Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KGNoWqC6MtNy"
   },
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzhr2UTyMtNz"
   },
   "source": [
    "## Noop Reset Env Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YHDVQS_nMtN0"
   },
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Csj73MlMtN1"
   },
   "source": [
    "## Scaled Float Frame Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rBYeRdvrMtN1"
   },
   "outputs": [],
   "source": [
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vd03Hv1MtN2"
   },
   "source": [
    "## Episodic Life Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K3_tCT4fMtN2"
   },
   "outputs": [],
   "source": [
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condition for a few frames\n",
    "            # so it's important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_zaDmRJMtN4"
   },
   "source": [
    "## Clip Reward Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yTsOOYyEMtN5"
   },
   "outputs": [],
   "source": [
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukAIUaihrUBd"
   },
   "source": [
    "## Resize & Grayscale Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IFE3KyHWrN-1"
   },
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import cv2\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        :param env: (Gym Environment) the environment\n",
    "        \"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1),\n",
    "                                            dtype=env.observation_space.dtype)\n",
    "        \n",
    "    def observation(self, frame):\n",
    "        \"\"\"\n",
    "        returns the current observation from a frame\n",
    "        :param frame: ([int] or [float]) environment frame\n",
    "        :return: ([int] or [float]) the observation\n",
    "        \"\"\"\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "kb1LXTXKs6qH",
    "outputId": "df0e09e1-a2f7-4c46-8cc7-9f6d35fcd6f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" \n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def WarpFrameEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    return env\n",
    "\n",
    "normal_env = gym.make(game)\n",
    "wrapped_env = WarpFrameEnv(game)\n",
    "\n",
    "normal_env.reset()\n",
    "wrapped_env.reset()\n",
    "action = normal_env.action_space.sample()\n",
    "\n",
    "normal_state, _, _, _ = normal_env.step(action)\n",
    "wrapped_state, _, _, _ = wrapped_env.step(action)\n",
    "\n",
    "wrapped_state = wrapped_state[: , :, 0]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.suptitle('Warp Frame', fontsize=20)\n",
    "axs[0].imshow(normal_state)\n",
    "axs[0].set_title(\"Normal\", fontsize=16)\n",
    "axs[1].imshow(wrapped_state, cmap=\"gray\")\n",
    "axs[1].set_title(\"Warp Frame\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjZQ6BOPq90B"
   },
   "source": [
    "## Frame Stack Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qYTs63ANrFyb"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.frames = deque(maxlen=4)\n",
    "        low = np.repeat(self.observation_space.low[np.newaxis, ...], repeats=4, axis=0)\n",
    "        high = np.repeat(self.observation_space.high[np.newaxis, ...], repeats=4, axis=0)\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=self.observation_space.dtype)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        for _ in range(4):\n",
    "            self.frames.append(obs)\n",
    "        frame_stack = np.asarray(self.frames, dtype=np.float32)\n",
    "        frame_stack = np.moveaxis(frame_stack, 0, -1).reshape(1, 84, 84, -1)\n",
    "        return frame_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "BFsMn2h-s04j",
    "outputId": "fca0dc94-9a39-4ee7-f49c-face6fa53783"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[OPTIONAL]\n",
    "\n",
    "Diese Zelle ist optional ausführbar und dient zur Visualisierung des Wrappers.\n",
    "Die Zelle hat keinen Einfluss auf den Agenten\n",
    "\"\"\"\n",
    "\n",
    "def FrameStackEnv(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = FrameStackEnv(game)\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1, 5):\n",
    "  # Führe eine zufällige Aktion aus\n",
    "  state, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# Stack umformen, damit das Plotten der vier Bilder gelingt\n",
    "state = state.reshape(84, 84,4)\n",
    "\n",
    "# Frame Stack plotten\n",
    "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
    "fig.suptitle('Frame Stack', fontsize=20)\n",
    "for i in range(state.shape[2]):\n",
    "    axs[i].imshow(state[:, :, i], cmap=\"gray\")\n",
    "    axs[i].set_title(\"Frame \"+str(i+1), fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1hORw-SrRKu"
   },
   "source": [
    "## Erstellen des Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyVNp_0hrOPK",
    "outputId": "5e8359ff-a4cd-476d-ebbb-11a913d9b586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTS/Breakout-v0/NoEpisodicLife_NoClipReward_lr_1e-3_5e-3/\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    #env = EpisodicLifeEnv(env)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    env = NoopResetEnv(env)\n",
    "    #env = ClipRewardEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = FrameStack(env)\n",
    "    return env\n",
    "\n",
    "env = make_env(game)\n",
    "\n",
    "\"\"\" saving the properties for csv \"\"\"\n",
    "\n",
    "MODE = \"NoEpisodicLife_NoClipReward_lr_1e-3_5e-3\"\n",
    "PATH = \"WEIGHTS/\" + game + \"/\" + MODE + \"/\"\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uAIJ4QYrja0"
   },
   "source": [
    "# Actor Network und Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aGNNFrCgr0MM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Network Parameter\n",
    "INPUT_SHAPE = (84, 84, 4) # (Höhe, Breite, Frames)\n",
    "ACTOR_OUTPUT = env.action_space.n # Anzahl der möglichen Aktionen\n",
    "CRITIC_OUTPUT = 1 # Bewertung der gewählten Aktion\n",
    "ACTOR_LEARNING_RATE = 25e-6\n",
    "CRITIC_LEARNING_RATE = 25e-6\n",
    "\n",
    "# neuronales Netz\n",
    "net_input = Input(shape=INPUT_SHAPE)\n",
    "x = Conv2D(filters=32, kernel_size=(8, 8), strides=(4, 4), padding=\"same\")(net_input)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "'''Aufspalten des Netzes in Actor und Critic'''\n",
    "\n",
    "# Actor - wählt eine Aktion\n",
    "actor_x = Dense(ACTOR_OUTPUT, kernel_initializer='he_uniform')(x)\n",
    "actor_output = Activation(\"softmax\")(actor_x)\n",
    "\n",
    "ACTOR = Model(inputs=net_input, outputs=actor_output)\n",
    "ACTOR.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=ACTOR_LEARNING_RATE))\n",
    "\n",
    "# Critic - bewertet gewählte Aktion\n",
    "critic_x = Dense(CRITIC_OUTPUT)(x)\n",
    "critic_output = Activation(\"linear\")(critic_x)\n",
    "\n",
    "CRITIC = Model(inputs=net_input, outputs=critic_output)\n",
    "CRITIC.compile(loss=\"mse\", optimizer=Adam(lr=CRITIC_LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s30U2V0CMtN_"
   },
   "source": [
    "# Aktion wählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fEwfPKljMtN_"
   },
   "outputs": [],
   "source": [
    "def get_action(state):\n",
    "    policy = ACTOR.predict(state)[0]\n",
    "    action = np.random.choice(env.action_space.n, p=policy) # Aktionen, welche Wahrscheinlichkeit zu Aktion\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yLfgqEutNr10"
   },
   "outputs": [],
   "source": [
    "def remember (state, action, reward):\n",
    "    STATES.append(state)\n",
    "    # Erstellen eines One Hot Labels für die Aktion\n",
    "    action_onehot = np.zeros([env.action_space.n])\n",
    "    action_onehot[action] = 1\n",
    "    ACTIONS.append(action_onehot)\n",
    "    REWARDS.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CRPapa6lR4-K"
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards):\n",
    "    gamma = 0.99\n",
    "    running_add = 0\n",
    "    discounted_r = np.zeros_like(rewards)\n",
    "    for i in reversed(range(0, len(rewards))):\n",
    "        if rewards[i] != 0: # Pong\n",
    "            running_add = 0\n",
    "        running_add = running_add * gamma + rewards[i]\n",
    "        discounted_r[i] = running_add\n",
    "\n",
    "    discounted_r -= np.mean(discounted_r) # normalisieren\n",
    "    discounted_r /= np.std(discounted_r) # teilen durch Standardabweichung\n",
    "\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "D3SGt8rvRTPT"
   },
   "outputs": [],
   "source": [
    "def replay_episode(STATES, ACTIONS, REWARDS):\n",
    "    states = np.vstack(STATES)\n",
    "    actions = np.vstack(ACTIONS)\n",
    "\n",
    "    # discount rewards\n",
    "    discounted_r = discount_rewards(REWARDS)\n",
    "\n",
    "    # Critic predictions\n",
    "    values = CRITIC.predict(states)[:, 0]\n",
    "\n",
    "    # Advantagewerte berechnen\n",
    "    advantages = discounted_r - values\n",
    "\n",
    "    # Trainieren der Netzwerke ACTOR und CRITIC\n",
    "    ACTOR.fit(states, actions, sample_weight=advantages, epochs=1, verbose=0)\n",
    "    CRITIC.fit(states, discounted_r, epochs=1, verbose=0)\n",
    "\n",
    "    # leeren des Episoden Buffers\n",
    "    STATES, ACTIONS, REWARDS = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwLX4bvUMtOA"
   },
   "source": [
    "# Training /Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fV_l4s5aMtOA",
    "outputId": "7dfdb8a8-f590-44df-a460-124c11c396d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Mean Reward -> Mean Reward kann nich auf 0 gesetzt werden (Pong -21)\n",
    "INITIAL_MEAN_REWARD = 0.0\n",
    "env.reset()\n",
    "while True:\n",
    "    _, reward, done, _ = env.step(env.action_space.sample())\n",
    "    INITIAL_MEAN_REWARD += reward\n",
    "    if done:\n",
    "        break\n",
    "INITIAL_MEAN_REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zXHmDN4bMtOA",
    "outputId": "78075f13-7208-4760-d7ca-46b75c91af46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 \tReward: 0.0 \tMean: 0.0 \tBestMean: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0608 04:56:44.443004 139903972689728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:466: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bac934d3e623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-63669ddcaebd>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTOR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Aktionen, welche Wahrscheinlichkeit zu Aktion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "EPISODES = 15_000\n",
    "REWARD_LIST = []\n",
    "MEAN_LIST = []\n",
    "BEST_MEAN_REWARD = INITIAL_MEAN_REWARD\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    EPISODE_REWARD = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # Episoden Buffer\n",
    "    STATES, ACTIONS, REWARDS = [], [], []\n",
    "    \n",
    "    while not done:\n",
    "        action = get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Transition im Episoden Buffer speichern\n",
    "        remember(state, action, reward)\n",
    "\n",
    "        # aktualisieren des States\n",
    "        state = next_state\n",
    "        \n",
    "        # Reward einer Aktion zum gesamten Reward der Episode addieren\n",
    "        EPISODE_REWARD += reward\n",
    "\n",
    "\n",
    "        if done:\n",
    "            REWARD_LIST.append(EPISODE_REWARD)\n",
    "            current_mean_reward = np.mean(REWARD_LIST[-min(len(REWARD_LIST), 10):])\n",
    "            MEAN_LIST.append(np.mean(REWARD_LIST))\n",
    "            \n",
    "            print(\"Episode:\", episode+1, \"\\tReward:\", EPISODE_REWARD, \"\\tMean:\", round(current_mean_reward, 2),\"\\tBestMean:\", BEST_MEAN_REWARD)\n",
    "\n",
    "            # Übernahme des höchsten Mean Rewards\n",
    "            if current_mean_reward > BEST_MEAN_REWARD:\n",
    "                BEST_MEAN_REWARD = current_mean_reward\n",
    "        \n",
    "                # trainierte Gewichte speichern\n",
    "                import os\n",
    "                try:\n",
    "                    os.makedirs(PATH)\n",
    "                except FileExistsError:\n",
    "                    # Pfad existiert bereits\n",
    "                    pass\n",
    "                ACTOR.save_weights(PATH + \"Best_ACTOR.h5\")\n",
    "                CRITIC.save_weights(PATH + \"Best_CRITIC.h5\")\n",
    "\n",
    "            replay_episode(STATES, ACTIONS, REWARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-k4snaUMtOB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "date = datetime.now().date()\n",
    "\n",
    "df = pd.DataFrame(list(zip(REWARD_LIST, MEAN_LIST)), \n",
    "               columns =['Rewards', 'Mean Reward']) \n",
    "df.to_csv(PATH + game + \"_\" + str(date) + \"_\"+ MODE + \".csv\", mode=\"w\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1FmesqdMtOB"
   },
   "outputs": [],
   "source": [
    "ACTOR.save_weights(PATH + \"End.h5\")\n",
    "CRITIC.save_weights(PATH + \"End.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKSlrmpRMtOC"
   },
   "source": [
    "# Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzDVaCvDMtOC"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "plt.plot(REWARD_LIST, label=\"erhaltene Rewards\")\n",
    "plt.plot(MEAN_LIST, label=\"durchschnittler Reward\")\n",
    "plt.title(\"Rewards während des Trainings\", fontsize=25)\n",
    "plt.xlabel(\"Episoden\", fontsize=20)\n",
    "plt.ylabel(\"Rewards\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqvMdh7kMtOC"
   },
   "source": [
    "# Spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s23zjIfZMtOD"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "\n",
    "for i in range(1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = np.argmax(ACTOR.predict(state))\n",
    "        state, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie von A2C.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
