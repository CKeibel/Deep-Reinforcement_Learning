{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Q-Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9xfV_VJakaI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkVT49we0eiY"
      },
      "source": [
        "# **Prepocessing**\n",
        "Stable Baselines\n",
        "\n",
        "https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxYChLgl0aQu"
      },
      "source": [
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset(**kwargs)\n",
        "        return obs\n",
        "\n",
        "    def step(self, ac):\n",
        "        return self.env.step(ac)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icOrwqqHgz7d"
      },
      "source": [
        "def make_env(env_name: string):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GAavlCWip41"
      },
      "source": [
        "TODO:\n",
        "\n",
        "\n",
        "*   finishing Wrappers\n",
        "*   create env\n",
        "* create NN and Targetnetwork\n",
        "* Replay Buffer\n",
        "* Experience Replay\n",
        "* get_action -> Epsilon Greedy\n",
        "* train loop\n",
        "* save weights\n",
        "* load weight\n",
        "* play game\n"
      ]
    }
  ]
}